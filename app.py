import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date
import json
import os

# Set page config
st.set_page_config(page_title="CPA Perfect Platform 2027", layout="wide", page_icon="üìö")

# Data Persistence
DATA_FILE = "cpa_data.json"

def load_data():
    defaults = {"scores": [], "logs": [], "xp": 0, "level": 1, "badges": []}
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                # Merge defaults for backward compatibility
                for k, v in defaults.items():
                    if k not in data:
                        data[k] = v
                return data
            except:
                return defaults
    return defaults

def save_data(data):
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Initialize Session State
if 'data' not in st.session_state:
    st.session_state.data = load_data()

if 'quiz_state' not in st.session_state:
    st.session_state.quiz_state = {
        'active': False,
        'subject': None,
        'level': None,
        'q_index': 0,
        'score': 0,
        'show_feedback': False,
        'selected_option': None
    }

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4e8cff;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
    }
    .correct-answer {
        background-color: #d1fae5;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #10b981;
        color: #065f46;
    }
    .incorrect-answer {
        background-color: #fee2e2;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ef4444;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

# Mock Data
mock_exams = [
    {'date': '2026-11-15', 'type': 'Short', 'name': 'Dec Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2026-12-13', 'type': 'Short', 'name': 'Official Dec Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-04-25', 'type': 'Short', 'name': 'May Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-05-23', 'type': 'Short', 'name': 'Official May Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-07-10', 'type': 'Essay', 'name': 'Essay Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-08-20', 'type': 'Essay', 'name': 'Official Aug Essay Exam', 'provider': 'CPAAOB', 'status': 'Target'}
]

# Vocabulary Data
def load_vocab_data():
    vocab_path = "assets/vocab.json"
    if os.path.exists(vocab_path):
        with open(vocab_path, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except:
                return {}
    return {}

vocab_data = load_vocab_data()

drill_questions = {
    'Financial': [
        {
            'level': 1,
            'q': "ÁèæÈáëÈ†êÈáë: Ë≤∏ÂÄüÂØæÁÖßË°®„ÅÆ„ÄåÁèæÈáë„Äç„Å´Âê´„Åæ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Á¥ôÂπ£ (Bank notes)", "Á°¨Ë≤® (Coins)", "ÈÉµ‰æøÂàáÊâã (Postage stamps)", "ÂΩìÂ∫ßÈ†êÈáë (Demand deposits)"],
            'correct': 2,
            'explanation': "ÈÉµ‰æøÂàáÊâã„ÅØ„ÄåË≤ØËîµÂìÅ„Äç„Åæ„Åü„ÅØ„ÄåÈÄö‰ø°Ë≤ª„Äç„Å®„Åó„Å¶Âá¶ÁêÜ„Åï„Çå„ÄÅÁèæÈáë„Å´„ÅØÂê´„Åæ„Çå„Åæ„Åõ„Çì„ÄÇÁèæÈáë„Å´„ÅØÈÄöË≤®„ÄÅÂ∞èÂàáÊâã„ÄÅÂΩìÂ∫ßÈ†êÈáë„Å™„Å©„ÅåÂê´„Åæ„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê∏õ‰æ°ÂÑüÂç¥: Ë≥áÁî£„ÅÆÂà©Áî®Èáè„Å´Âü∫„Å•„ÅÑ„Å¶Ê∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÇíË®àÁÆó„Åô„ÇãÊñπÊ≥ï„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂÆöÈ°çÊ≥ï (Straight-line)", "ÂÆöÁéáÊ≥ï (Declining-balance)", "ÁîüÁî£È´òÊØî‰æãÊ≥ï (Production-output)", "Á¥öÊï∞Ê≥ï (Sum-of-the-years'-digits)"],
            'correct': 2,
            'explanation': "ÁîüÁî£È´òÊØî‰æãÊ≥ï„ÅØ„ÄÅÁ∑èË¶ãÁ©çÁîüÁî£Èáè„Å´ÂØæ„Åô„ÇãÂΩìÊúü„ÅÆÂÆüÈöõÁîüÁî£Èáè„ÅÆÂâ≤Âêà„Å´Âü∫„Å•„ÅÑ„Å¶Ë≤ªÁî®„ÇíÈÖçÂàÜ„Åô„ÇãÊñπÊ≥ï„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê£öÂç∏Ë≥áÁî£: Áâ©‰æ°‰∏äÊòáÂ±ÄÈù¢„Å´„Åä„ÅÑ„Å¶„ÄÅÂΩìÊúüÁ¥îÂà©Áõä„ÅåÊúÄ„ÇÇÂ§ß„Åç„Åè„Å™„ÇãË©ï‰æ°ÊñπÊ≥ï„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂÖàÂÖ•ÂÖàÂá∫Ê≥ï (FIFO)", "ÂæåÂÖ•ÂÖàÂá∫Ê≥ï (LIFO)", "ÁßªÂãïÂπ≥ÂùáÊ≥ï (Weighted Average)", "ÂÄãÂà•Ê≥ï (Specific Identification)"],
            'correct': 0,
            'explanation': "ÂÖàÂÖ•ÂÖàÂá∫Ê≥ï(FIFO)„Åß„ÅØ„ÄÅÈÅéÂéª„ÅÆÔºàÂÆâ„ÅÑÔºâÂú®Â∫´„ÅåÂÖà„Å´Â£≤‰∏äÂéü‰æ°„Å®„Å™„Çä„ÄÅÊúüÊú´Âú®Â∫´„Å´Áõ¥Ëøë„ÅÆÔºàÈ´ò„ÅÑÔºâÂçò‰æ°„ÅåÊÆã„Çã„Åü„ÇÅ„ÄÅÂ£≤‰∏äÂéü‰æ°„ÅåÂ∞è„Åï„Åè„Å™„ÇäÂà©Áõä„ÅåÂ§ß„Åç„Åè„Å™„Çä„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ë≥áÁî£Èô§ÂéªÂÇµÂãô: Ë≥áÁî£Èô§ÂéªÂÇµÂãô„ÅØÂΩìÂàù‰Ωï„Çí„ÇÇ„Å£„Å¶Ê∏¨ÂÆö„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Èô§ÂéªË≤ªÁî®„ÅÆÂ∞ÜÊù•‰æ°ÂÄ§", "Èô§ÂéªË≤ªÁî®„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§", "Ë≥áÁî£„ÅÆÂèñÂæóÂéü‰æ°", "Ë≥áÁî£„ÅÆÂÖ¨Ê≠£‰æ°ÂÄ§"],
            'correct': 1,
            'explanation': "Ë≥áÁî£Èô§ÂéªÂÇµÂãô„ÅØ„ÄÅÂ∞ÜÊù•Áô∫Áîü„Åô„Çã„Å®Ë¶ãËæº„Åæ„Çå„ÇãÈô§ÂéªË≤ªÁî®„ÅÆ„ÄåÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§„Äç„ÅßÁÆóÂÆö„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∏ÄËà¨ÂéüÂâá: ‰ºÅÊ•≠‰ºöË®àÂéüÂâá„ÅÆ„ÄåÁúüÂÆüÊÄß„ÅÆÂéüÂâá„Äç„Å´„Åä„Åë„Çã„ÄåÁúüÂÆü„Äç„ÅÆÊÑèÂë≥„Å®„Åó„Å¶Ê≠£„Åó„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Áµ∂ÂØæÁöÑÁúüÂÆü", "Áõ∏ÂØæÁöÑÁúüÂÆü", "ÂΩ¢ÂºèÁöÑÁúüÂÆü", "Ê≥ïÁöÑÁúüÂÆü"],
            'correct': 1,
            'explanation': "‰ºÅÊ•≠‰ºöË®à„ÅØË§áÊï∞„ÅÆ‰ºöË®àÂá¶ÁêÜ„ÅÆÂéüÂâá„ÉªÊâãÁ∂ö„ÅÆÈÅ∏ÊäûÈÅ©Áî®„ÇíË™ç„ÇÅ„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÊ±Ç„ÇÅ„Çâ„Çå„Çã„ÅÆ„ÅØ„ÄåÁõ∏ÂØæÁöÑÁúüÂÆü„Äç„Åß„ÅÇ„Çã„Å®Ëß£„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê∏õÊêç‰ºöË®à: Âõ∫ÂÆöË≥áÁî£„ÅÆ„ÄåÂõûÂèéÂèØËÉΩ‰æ°È°ç„Äç„Å®„ÅØ„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å´ÁÆóÂÆö„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„Å®‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„ÅÑ„Åö„Çå„ÅãÈ´ò„ÅÑÈáëÈ°ç", "Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„Å®‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈáëÈ°ç", "Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„ÅÆ„Åø", "‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„Åø"],
            'correct': 0,
            'explanation': "ÂõûÂèéÂèØËÉΩ‰æ°È°ç„ÅØ„ÄÅË≥áÁî£„ÅÆ„ÄåÊ≠£Âë≥Â£≤Âç¥‰æ°È°ç„Äç„Å®„Äå‰ΩøÁî®‰æ°ÂÄ§„Äç„ÅÆ„ÅÑ„Åö„Çå„ÅãÈ´ò„ÅÑÊñπ„ÅÆÈáëÈ°ç„Å®„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "„É™„Éº„Çπ‰ºöË®à: „Éï„Ç°„Ç§„Éä„É≥„Çπ„Éª„É™„Éº„ÇπÂèñÂºï„Å´„Åä„ÅÑ„Å¶„ÄÅÂÄüÊâã„ÅåË®à‰∏ä„Åô„ÇãË≥áÁî£„ÅÆÈ°ç„ÅØÂéüÂâá„Å®„Åó„Å¶„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["„É™„Éº„ÇπÊñôÁ∑èÈ°ç", "„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§„Å®Ë≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°çÁ≠â„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈ°ç", "Ë≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°ç", "„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§"],
            'correct': 1,
            'explanation': "ÈÄöÂ∏∏„ÅÆ„Éï„Ç°„Ç§„Éä„É≥„Çπ„Éª„É™„Éº„Çπ„Åß„ÅØ„ÄÅ„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÁèæÂú®‰æ°ÂÄ§„Å®„ÄÅË≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°çÔºàÁèæÈáëË≥ºÂÖ•‰æ°È°çÔºâ„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈ°ç„ÅßË≥áÁî£Ë®à‰∏ä„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 2,
            'q': "„Ç≠„É£„ÉÉ„Ç∑„É•„Éª„Éï„É≠„ÉºË®àÁÆóÊõ∏: ÈñìÊé•Ê≥ï„Å´„Åä„ÅÑ„Å¶„ÄÅÁ®éÂºïÂâçÂΩìÊúüÁ¥îÂà©Áõä„Åã„Çâ„Çπ„Çø„Éº„Éà„Åô„ÇãÈöõ„ÄÅÊ∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÅØ„Å©„ÅÜË™øÊï¥„Åó„Åæ„Åô„ÅãÔºü",
            'options': ["Âä†ÁÆó„Åô„Çã", "Ê∏õÁÆó„Åô„Çã", "Ë™øÊï¥„Åó„Å™„ÅÑ", "Âñ∂Ê•≠Â§ñÂèéÁõä„Å®„Åó„Å¶Êâ±„ÅÜ"],
            'correct': 0,
            'explanation': "Ê∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÅØÁèæÈáëÊîØÂá∫„Çí‰º¥„Çè„Å™„ÅÑË≤ªÁî®ÔºàÈùûË≥áÈáëÊêçÁõäÔºâ„Åß„ÅÇ„Çã„Åü„ÇÅ„ÄÅÂà©Áõä„Åã„Çâ„Çπ„Çø„Éº„Éà„Åó„Å¶„Ç≠„É£„ÉÉ„Ç∑„É•„Éï„É≠„Éº„ÇíÊ±Ç„ÇÅ„ÇãÈöõ„ÅØ„ÄåÂä†ÁÆó„Äç„Åó„Å¶Êàª„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 3,
            'q': "Á®éÂäπÊûú‰ºöË®à: Áπ∞Âª∂Á®éÈáëË≥áÁî£„ÅÆÂõûÂèéÂèØËÉΩÊÄß„ÇíÂà§Êñ≠„Åô„ÇãÈöõ„ÄÅ‰ºöÁ§æÂàÜÈ°û„Åå„ÄåÂàÜÈ°û2„Äç„ÅÆ‰ºÅÊ•≠„Å´„Åä„ÅÑ„Å¶„ÄÅ„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™‰∏ÄÊôÇÂ∑ÆÁï∞„ÅØ„ÅÑ„Å§„Åæ„ÅßË®à‰∏äÂèØËÉΩ„Åß„Åô„ÅãÔºü",
            'options': ["1Âπ¥‰ª•ÂÜÖ", "5Âπ¥‰ª•ÂÜÖ", "„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™ÂÖ®ÊúüÈñì", "Ë®à‰∏ä„Åß„Åç„Å™„ÅÑ"],
            'correct': 2,
            'explanation': "„ÄåÂàÜÈ°û2ÔºàÊ•≠Á∏æ„ÅåÂÆâÂÆö„Åó„Å¶„ÅÑ„Çã‰ºÅÊ•≠Ôºâ„Äç„ÅÆÂ†¥Âêà„ÄÅ„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™Â∞ÜÊù•Ê∏õÁÆó‰∏ÄÊôÇÂ∑ÆÁï∞„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅÊúüÈñìÂà∂Èôê„Å™„ÅèÔºàÂÖ®ÊúüÈñìÔºâÂõûÂèéÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Å®Âà§Êñ≠„Åï„Çå„Åæ„Åô„ÄÇ"
        }
    ],
    'Management': [
        {
            'level': 1,
            'q': "CVPÂàÜÊûê: ÊêçÁõäÂàÜÂ≤êÁÇπÂ£≤‰∏äÈ´ò„ÇíÊ±Ç„ÇÅ„ÇãË®àÁÆóÂºè„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âõ∫ÂÆöË≤ª √∑ Ë≤¢ÁåÆÂà©ÁõäÁéá", "Âõ∫ÂÆöË≤ª √∑ Â§âÂãïË≤ªÁéá", "Â§âÂãïË≤ª √∑ Â£≤‰∏äÈ´ò", "Âà©Áõä √∑ Â£≤‰∏äÈ´ò"],
            'correct': 0,
            'explanation': "ÊêçÁõäÂàÜÂ≤êÁÇπÂ£≤‰∏äÈ´ò Ôºù Âõ∫ÂÆöË≤ª √∑ (1 Ôºç Â§âÂãïË≤ªÁéá) Ôºù Âõ∫ÂÆöË≤ª √∑ Ë≤¢ÁåÆÂà©ÁõäÁéá „Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Âéü‰æ°„ÅÆÂàÜÈ°û: „ÄåÁ¥†‰æ° (Prime Cost)„Äç„ÇíÊßãÊàê„Åô„Çã„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Áõ¥Êé•ÊùêÊñôË≤ª Ôºã Áõ¥Êé•Âä¥ÂãôË≤ª", "Áõ¥Êé•Âä¥ÂãôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ª", "Áõ¥Êé•ÊùêÊñôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ª", "Ë≤©Â£≤Ë≤ªÂèä„Å≥‰∏ÄËà¨ÁÆ°ÁêÜË≤ª"],
            'correct': 0,
            'explanation': "Á¥†‰æ°ÔºàPrime CostÔºâ„ÅØ„ÄÅÁõ¥Êé•ÊùêÊñôË≤ª„Å®Áõ¥Êé•Âä¥ÂãôË≤ª„ÅÆÂêàË®à„Åß„Åô„ÄÇÔºàÂä†Â∑•Ë≤ª Ôºù Áõ¥Êé•Âä¥ÂãôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ªÔºâ"
        },
        {
            'level': 1,
            'q': "Ê®ôÊ∫ñÂéü‰æ°Ë®àÁÆó: ÂÆüÈöõÊ∂àË≤ªÈáè„ÅåÊ®ôÊ∫ñÊ∂àË≤ªÈáè„Çí‰∏äÂõû„Å£„ÅüÂ†¥Âêà„Å´Áô∫Áîü„Åô„ÇãÂ∑ÆÁï∞„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÊúâÂà©Êï∞ÈáèÂ∑ÆÁï∞", "‰∏çÂà©Êï∞ÈáèÂ∑ÆÁï∞", "ÊúâÂà©‰æ°Ê†ºÂ∑ÆÁï∞", "‰∏çÂà©‰æ°Ê†ºÂ∑ÆÁï∞"],
            'correct': 1,
            'explanation': "Ê®ôÊ∫ñ„Çà„Çä„ÇÇÂ§ö„Åè„ÅÆÊï∞Èáè„ÇíÊ∂àË≤ª„Åó„Å¶„Åó„Åæ„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ„Ç≥„Çπ„ÉàÂ¢ó„Å®„Å™„Çã„Åü„ÇÅ„Äå‰∏çÂà©Â∑ÆÁï∞ÔºàUnfavorableÔºâ„Äç„Å®„Å™„Çä„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ¥Êé•Âéü‰æ°Ë®àÁÆó: Âõ∫ÂÆöË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÅØ„Å©„ÅÆ„Çà„ÅÜ„Å´Âá¶ÁêÜ„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Ë£ΩÂìÅÂéü‰æ°„Å®„Åó„Å¶Âá¶ÁêÜ", "ÊúüÈñìÂéü‰æ°„Å®„Åó„Å¶Âá¶ÁêÜ", "Ë≥áÁî£„Å®„Åó„Å¶Ë®à‰∏ä", "Ë≤†ÂÇµ„Å®„Åó„Å¶Ë®à‰∏ä"],
            'correct': 1,
            'explanation': "Áõ¥Êé•Âéü‰æ°Ë®àÁÆó„Åß„ÅØ„ÄÅÂõ∫ÂÆöË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÅØÁô∫ÁîüÊôÇ„Å´„ÄåÊúüÈñìÂéü‰æ°„Äç„Å®„Åó„Å¶ÂÖ®È°çË≤ªÁî®Âá¶ÁêÜ„Åï„Çå„Åæ„ÅôÔºàCVPÂàÜÊûê„Å´ÊúâÁî®Ôºâ„ÄÇ"
        },
        {
            'level': 1,
            'q': "Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ: Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ„Å´„Åä„ÅÑ„Å¶„ÄÅÂéü‰æ°Ë®àÁÆó„ÅÆÁõÆÁöÑ„Å®„Åó„Å¶Êåô„Åí„Çâ„Çå„Å¶„ÅÑ„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ë≤°ÂãôË´∏Ë°®„ÅÆ‰ΩúÊàê", "Âéü‰æ°ÁÆ°ÁêÜ", "‰∫àÁÆóÁµ±Âà∂", "ÂæìÊ•≠Âì°Áµ¶‰∏é„ÅÆË®àÁÆó"],
            'correct': 3,
            'explanation': "Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ„Å´„ÅØ„ÄÅË≤°ÂãôË´∏Ë°®‰ΩúÊàê„ÄÅ‰æ°Ê†ºË®àÁÆó„ÄÅÂéü‰æ°ÁÆ°ÁêÜ„ÄÅ‰∫àÁÆóÁÆ°ÁêÜ„ÄÅÂü∫Êú¨Ë®àÁîªÁ≠ñÂÆö„ÅÆ5„Å§„ÅÆÁõÆÁöÑ„ÅåÊåô„Åí„Çâ„Çå„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅÁµ¶‰∏éË®àÁÆó„ÅØÂê´„Åæ„Çå„Åæ„Åõ„Çì„ÄÇ"
        },
        {
            'level': 1,
            'q': "ABC (Ê¥ªÂãïÂü∫Ê∫ñÂéü‰æ°Ë®àÁÆó): Ë£ΩÈÄ†ÈñìÊé•Ë≤ª„ÇíË£ΩÂìÅ„Å´ÈÖçË≥¶„Åô„Çã„Åü„ÇÅ„Å´‰ΩøÁî®„Åï„Çå„ÇãÂü∫Ê∫ñ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
            'options': ["ÊìçÊ•≠Â∫¶", "„Ç≥„Çπ„Éà„Éª„Éâ„É©„Ç§„Éê„Éº (Ê¥ªÂãïÂéü‰æ°Ë¶ÅÂõ†)", "Áõ¥Êé•‰ΩúÊ•≠ÊôÇÈñì", "Ê©üÊ¢∞Á®ºÂÉçÊôÇÈñì"],
            'correct': 1,
            'explanation': "ABC„Åß„ÅØ„ÄÅË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÇíÊ¥ªÂãï„Åî„Å®„Å´ÊääÊè°„Åó„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÊ¥ªÂãï„ÅÆÁô∫ÁîüË¶ÅÂõ†„Åß„ÅÇ„Çã„Äå„Ç≥„Çπ„Éà„Éª„Éâ„É©„Ç§„Éê„Éº„Äç„Å´Âü∫„Å•„ÅÑ„Å¶Ë£ΩÂìÅ„Å´ÈÖçË≥¶„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "ÊäïË≥á„ÅÆÁµåÊ∏àÊÄßË®àÁÆó: ROI (Êäï‰∏ãË≥áÊú¨Âà©ÁõäÁéá) „ÇíÊ±Ç„ÇÅ„ÇãË®àÁÆóÂºè„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âà©Áõä √∑ Â£≤‰∏äÈ´ò", "Â£≤‰∏äÈ´ò √∑ Êäï‰∏ãË≥áÊú¨", "Âà©Áõä √∑ Êäï‰∏ãË≥áÊú¨", "Êäï‰∏ãË≥áÊú¨ √∑ Âà©Áõä"],
            'correct': 2,
            'explanation': "ROI (Return On Investment) „ÅØ„ÄÅÂà©Áõä„ÇíÊäï‰∏ãË≥áÊú¨„ÅßÂâ≤„Å£„Å¶ÁÆóÂá∫„Åó„Åæ„ÅôÔºàROI = Â£≤‰∏äÈ´òÂà©ÁõäÁéá √ó Ë≥áÊú¨ÂõûËª¢ÁéáÔºâ„ÄÇ"
        },
        {
            'level': 2,
            'q': "CVPÂàÜÊûê: Âõ∫ÂÆöË≤ª1,000„ÄÅÂ§âÂãïË≤ªÁéá0.6„ÄÅÁõÆÊ®ôÂà©Áõä200„ÅÆÂ†¥Âêà„ÄÅÁõÆÊ®ôÂ£≤‰∏äÈ´ò„ÅØ„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["2,000", "3,000", "2,500", "1,200"],
            'correct': 1,
            'explanation': "ÁõÆÊ®ôÂ£≤‰∏äÈ´ò Ôºù (Âõ∫ÂÆöË≤ª Ôºã ÁõÆÊ®ôÂà©Áõä) √∑ (1 Ôºç Â§âÂãïË≤ªÁéá) Ôºù (1000 + 200) √∑ 0.4 Ôºù 3000 „Åß„Åô„ÄÇ"
        }
    ],
    'Audit': [
        {
            'level': 1,
            'q': "Áõ£Êüª„É™„Çπ„ÇØ: Áõ£Êüª„É™„Çπ„ÇØ„Éª„É¢„Éá„É´„ÅÆÊßãÊàêË¶ÅÁ¥†„Å®„Åó„Å¶Ê≠£„Åó„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âõ∫Êúâ„É™„Çπ„ÇØ √ó Áµ±Âà∂„É™„Çπ„ÇØ √ó Áô∫Ë¶ã„É™„Çπ„ÇØ", "„Éì„Ç∏„Éç„Çπ„É™„Çπ„ÇØ √ó Áõ£Êüª„É™„Çπ„ÇØ", "ÈáçË¶ÅÊÄß √ó „É™„Çπ„ÇØ", "ÊäΩÂá∫„É™„Çπ„ÇØ √ó ÈùûÊäΩÂá∫„É™„Çπ„ÇØ"],
            'correct': 0,
            'explanation': "Áõ£Êüª„É™„Çπ„ÇØ Ôºù ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„É™„Çπ„ÇØÔºàÂõ∫Êúâ„É™„Çπ„ÇØ√óÁµ±Âà∂„É™„Çπ„ÇØÔºâ √ó Áô∫Ë¶ã„É™„Çπ„ÇØ „Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áã¨Á´ãÊÄß: „ÄåÂ§ñË¶≥ÁöÑÁã¨Á´ãÊÄß„Äç„ÇíÊêç„Å™„ÅÜË¶ÅÂõ†„Å®„Å™„Çã„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ë¢´Áõ£Êüª‰ºöÁ§æ„ÅÆÊ†™Âºè‰øùÊúâ", "Ë™†ÂÆü„Åß„ÅÇ„Çã„Åì„Å®", "Â∞ÇÈñÄËÉΩÂäõ„ÇíÊúâ„Åô„Çã„Åì„Å®", "ÂÄ´ÁêÜË¶èÂÆö„ÅÆÈÅµÂÆà"],
            'correct': 0,
            'explanation': "Ë¢´Áõ£Êüª‰ºöÁ§æ„ÅÆÊ†™Âºè„ÇÑÈáçË¶Å„Å™ÁµåÊ∏àÁöÑÂà©ÂÆ≥Èñ¢‰øÇ„ÇíÊúâ„Åô„Çã„Åì„Å®„ÅØ„ÄÅÂ§ñË¶≥ÁöÑÁã¨Á´ãÊÄßÔºàÁ¨¨‰∏âËÄÖ„Åã„ÇâË¶ã„Å¶Áã¨Á´ã„Åó„Å¶„ÅÑ„Çã„Å®Ë¶ã„Åà„Çã„Åì„Å®Ôºâ„ÇíÊêç„Å™„ÅÑ„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÊÑèË¶ã: Ë≤°ÂãôË´∏Ë°®ÂÖ®‰Ωì„Å´ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„Åå„ÅÇ„Çä„ÄÅ„Åã„Å§„Åù„ÅÆÂΩ±Èüø„ÅåÂ∫ÉÁØÑ„Åß„ÅÇ„ÇãÂ†¥Âêà„Å´Ë°®Êòé„Åï„Çå„ÇãÊÑèË¶ã„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÁÑ°ÈôêÂÆöÈÅ©Ê≠£ÊÑèË¶ã", "ÈôêÂÆö‰ªòÈÅ©Ê≠£ÊÑèË¶ã", "‰∏çÈÅ©Ê≠£ÊÑèË¶ã", "ÊÑèË¶ã‰∏çË°®Êòé"],
            'correct': 2,
            'explanation': "ÈáçË¶Å„Åã„Å§Â∫ÉÁØÑÔºàPervasiveÔºâ„Å™ËôöÂÅΩË°®Á§∫„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Äå‰∏çÈÅ©Ê≠£ÊÑèË¶ãÔºàAdverse OpinionÔºâ„Äç„ÅåË°®Êòé„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "ÂÜÖÈÉ®Áµ±Âà∂: ÂÜÖÈÉ®Áµ±Âà∂„ÅÆÊï¥ÂÇô„ÉªÈÅãÁî®Ë≤¨‰ªª„ÅØË™∞„Å´„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
            'options': ["Áõ£Êüª‰∫∫", "ÁµåÂñ∂ËÄÖ", "Ê†™‰∏ª", "ÊîøÂ∫ú"],
            'correct': 1,
            'explanation': "ÂÜÖÈÉ®Áµ±Âà∂„ÇíÊï¥ÂÇô„ÅóÈÅãÁî®„Åô„ÇãË≤¨‰ªª„ÅØ„ÄåÁµåÂñ∂ËÄÖ„Äç„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇÁõ£Êüª‰∫∫„ÅØ„Åù„ÅÆÊúâÂäπÊÄß„ÇíË©ï‰æ°„ÉªÂ†±Âëä„Åô„ÇãÁ´ãÂ†¥„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªË®ºÊã†: ‰∏ÄËà¨ÁöÑ„Å´ÊúÄ„ÇÇË®ºÊòéÂäõ„ÅåÈ´ò„ÅÑ„Å®„Åï„Çå„ÇãÁõ£ÊüªË®ºÊã†„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÁµåÂñ∂ËÄÖ„Å∏„ÅÆË≥™Âïè", "Ë¶≥ÂØü", "Â§ñÈÉ®Á¢∫Ë™ç", "Á§æÂÜÖÊñáÊõ∏"],
            'correct': 2,
            'explanation': "Â§ñÈÉ®„ÅÆÁ¨¨‰∏âËÄÖ„Åã„ÇâÁõ¥Êé•ÂÖ•Êâã„Åô„Çã„ÄåÁ¢∫Ë™çÔºàExternal ConfirmationÔºâ„Äç„ÅØ„ÄÅ‰∏ÄËà¨„Å´Á§æÂÜÖË®ºÊã†„Çà„Çä„ÇÇË®ºÊòéÂäõ„ÅåÈ´ò„ÅÑ„Å®„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∏çÊ≠£ÂØæÂøú: „Äå‰∏çÊ≠£„ÅÆ„Éà„É©„Ç§„Ç¢„É≥„Ç∞„É´„Äç„ÅÆ3Ë¶ÅÁ¥†„Å´Âê´„Åæ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂãïÊ©ü„Éª„Éó„É¨„ÉÉ„Ç∑„É£„Éº", "Ê©ü‰ºö", "ÂßøÂã¢„ÉªÊ≠£ÂΩìÂåñ", "ÁΩ∞Ââá"],
            'correct': 3,
            'explanation': "‰∏çÊ≠£„ÅÆ„Éà„É©„Ç§„Ç¢„É≥„Ç∞„É´„ÅØ„ÄÅ„ÄåÂãïÊ©ü„Éª„Éó„É¨„ÉÉ„Ç∑„É£„Éº„Äç„ÄåÊ©ü‰ºö„Äç„ÄåÂßøÂã¢„ÉªÊ≠£ÂΩìÂåñ„Äç„ÅÆ3Ë¶ÅÁ¥†„Åã„ÇâÊßãÊàê„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÂ†±ÂëäÊõ∏: Áõ£ÊüªÂ†±ÂëäÊõ∏Êó•„ÅØ„ÅÑ„Å§„Åß„ÅÇ„Çã„Åπ„Åç„Åß„Åô„ÅãÔºü",
            'options': ["Ê±∫ÁÆóÊó•", "Áõ£Êüª‰∫∫„ÅåÁõ£ÊüªÊÑèË¶ã„ÇíÂΩ¢Êàê„Åô„Çã„ÅÆ„Å´ÂçÅÂàÜ„Åã„Å§ÈÅ©Âàá„Å™Áõ£ÊüªË®ºÊã†„ÇíÂÖ•Êâã„Åó„ÅüÊó•", "Ê†™‰∏ªÁ∑è‰ºöÈñãÂÇ¨Êó•", "Êúâ‰æ°Ë®ºÂà∏Â†±ÂëäÊõ∏ÊèêÂá∫Êó•"],
            'correct': 1,
            'explanation': "Áõ£ÊüªÂ†±ÂëäÊõ∏Êó•„ÅØ„ÄÅÁõ£Êüª‰∫∫„ÅåÊÑèË¶ãË°®Êòé„ÅÆÂü∫Á§é„Å®„Å™„ÇãÂçÅÂàÜ„Åã„Å§ÈÅ©Âàá„Å™Áõ£ÊüªË®ºÊã†„ÇíÂÖ•Êâã„Åó„ÅüÊó•ÔºàÁõ£ÊüªÁµÇ‰∫ÜÊó•Ôºâ„Å®„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        }
    ],
    'Company': [
        {
            'level': 1,
            'q': "Ë®≠Á´ã: Ê†™Âºè‰ºöÁ§æ„ÅÆË®≠Á´ã„Å´„Åä„Åë„ÇãÊúÄ‰ΩéË≥áÊú¨Èáë„ÅÆÈ°ç„ÅØ„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["1,000‰∏áÂÜÜ", "300‰∏áÂÜÜ", "1ÂÜÜ", "0ÂÜÜ"],
            'correct': 2,
            'explanation': "ÁèæÂú®„ÅÆ‰ºöÁ§æÊ≥ï„Åß„ÅØ„ÄÅÊúÄ‰ΩéË≥áÊú¨ÈáëÂà∂Â∫¶„ÅØÊí§ÂªÉ„Åï„Çå„Å¶„Åä„Çä„ÄÅË≥áÊú¨Èáë1ÂÜÜ„Åã„ÇâË®≠Á´ã„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ëá™Â∑±Ê†™Âºè: Ê†™Âºè‰ºöÁ§æ„ÅØËá™Â∑±Ê†™Âºè„ÇíÂèñÂæó„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÅãÔºü",
            'options': ["ÂÆåÂÖ®„Å´Á¶ÅÊ≠¢„Åï„Çå„Å¶„ÅÑ„Çã", "Ë≤°Ê∫êË¶èÂà∂Á≠â„ÅÆ‰∏ã„ÅßË™ç„ÇÅ„Çâ„Çå„Çã", "Ëá™Áî±„Å´Ë™ç„ÇÅ„Çâ„Çå„Çã", "Ëß£Êï£ÊôÇ„ÅÆ„ÅøË™ç„ÇÅ„Çâ„Çå„Çã"],
            'correct': 1,
            'explanation': "Ëá™Â∑±Ê†™Âºè„ÅÆÂèñÂæó„ÅØ„ÄÅÂàÜÈÖçÂèØËÉΩÈ°ç„ÅÆÁØÑÂõ≤ÂÜÖ„Åß„ÅÇ„Çã„Åì„Å®„ÇÑÊ†™‰∏ªÁ∑è‰ºöÊ±∫Ë≠∞„Å™„Å©„ÅÆË¶èÂà∂„ÅÆ‰∏ã„ÅßË™ç„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê©üÈñ¢Ë®≠Ë®à: ÂèñÁ∑†ÂΩπ‰ºöË®≠ÁΩÆ‰ºöÁ§æ„Å´„Åä„Åë„ÇãÂèñÁ∑†ÂΩπ„ÅÆÊúÄ‰Ωé‰∫∫Êï∞„ÅØ‰Ωï‰∫∫„Åß„Åô„ÅãÔºü",
            'options': ["1‰∫∫", "2‰∫∫", "3‰∫∫", "5‰∫∫"],
            'correct': 2,
            'explanation': "ÂèñÁ∑†ÂΩπ‰ºö„ÇíË®≠ÁΩÆ„Åô„ÇãÂ†¥Âêà„ÄÅÂèñÁ∑†ÂΩπ„ÅØ3‰∫∫‰ª•‰∏äÂøÖË¶Å„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê†™‰∏ªÁ∑è‰ºö: ÁâπÂà•Ê±∫Ë≠∞„ÅÆÂÆöË∂≥Êï∞„ÅØÂéüÂâá„Å®„Åó„Å¶„Å©„ÅÆ„Åè„Çâ„ÅÑ„Åß„Åô„ÅãÔºü",
            'options': ["Ë≠∞Ê±∫Ê®©„ÅÆÈÅéÂçäÊï∞", "Ë≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ1", "Ë≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ2", "ÂÖ®Ê†™‰∏ª"],
            'correct': 0,
            'explanation': "ÁâπÂà•Ê±∫Ë≠∞„ÅÆÂÆöË∂≥Êï∞„ÅØÂéüÂâá„Å®„Åó„Å¶„ÄåË≠∞Ê±∫Ê®©„ÅÆÈÅéÂçäÊï∞„Äç„Åß„ÅôÔºàÂÆöÊ¨æ„Åß3ÂàÜ„ÅÆ1„Åæ„ÅßÁ∑©ÂíåÂèØÔºâ„ÄÇÊ±∫Ë≠∞Ë¶Å‰ª∂„ÅØÂá∫Â∏≠Ê†™‰∏ª„ÅÆË≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ2‰ª•‰∏ä„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÂΩπ: Áõ£ÊüªÂΩπ„ÅÆ‰ªªÊúü„ÅØÂéüÂâá„Å®„Åó„Å¶‰ΩïÂπ¥„Åß„Åô„ÅãÔºü",
            'options': ["1Âπ¥", "2Âπ¥", "4Âπ¥", "10Âπ¥"],
            'correct': 2,
            'explanation': "Áõ£ÊüªÂΩπ„ÅÆ‰ªªÊúü„ÅØÂéüÂâá„Å®„Åó„Å¶4Âπ¥„Åß„Åô„ÄÇÂÆöÊ¨æ„Å´„Çà„Å£„Å¶„ÇÇÁü≠Á∏Æ„Åô„Çã„Åì„Å®„ÅØ„Åß„Åç„Åæ„Åõ„Çì„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê†™‰∏ª„ÅÆÊ®©Âà©: ÂçòÁã¨Ê†™‰∏ªÊ®©Ôºà1Ê†™„Åß„ÇÇ‰øùÊúâ„Åó„Å¶„ÅÑ„Çå„Å∞Ë°å‰Ωø„Åß„Åç„ÇãÊ®©Âà©Ôºâ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ê†™‰∏ªÁ∑è‰ºöÊãõÈõÜË´ãÊ±ÇÊ®©", "Â∏≥Á∞øÈñ≤Ë¶ßË´ãÊ±ÇÊ®©", "Ââ∞‰ΩôÈáëÈÖçÂΩìË´ãÊ±ÇÊ®©", "ÂèñÁ∑†ÂΩπËß£‰ªªË´ãÊ±ÇÊ®©"],
            'correct': 2,
            'explanation': "Ââ∞‰ΩôÈáëÈÖçÂΩìË´ãÊ±ÇÊ®©„ÇÑË≠∞Ê±∫Ê®©„ÅØ„ÄÅ1Ê†™„Åã„ÇâË™ç„ÇÅ„Çâ„Çå„ÇãÂçòÁã¨Ê†™‰∏ªÊ®©„Åß„Åô„ÄÇÂ∏≥Á∞øÈñ≤Ë¶ßÊ®©„Å™„Å©„ÅØ‰∏ÄÂÆö„ÅÆÊ†™ÂºèÊï∞„ÉªÊúüÈñì„ÅåÂøÖË¶Å„Å™Â∞ëÊï∞Ê†™‰∏ªÊ®©„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∫ãÊ•≠Ë≠≤Ê∏°: Ê†™‰∏ªÁ∑è‰ºö„ÅÆÁâπÂà•Ê±∫Ë≠∞„ÅåÂøÖË¶Å„Å®„Å™„Çã‰∫ãÊ•≠Ë≠≤Ê∏°„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["‰∫ãÊ•≠„ÅÆÂÖ®ÈÉ®„Åæ„Åü„ÅØÈáçË¶Å„Å™‰∏ÄÈÉ®„ÅÆË≠≤Ê∏°", "ÈáçË¶Å„Å™Ë≥áÁî£„ÅÆÂá¶ÂàÜ", "Â§öÈ°ç„ÅÆÂÄüË≤°", "ÊîØÈÖç‰∫∫„ÅÆÈÅ∏‰ªª"],
            'correct': 0,
            'explanation': "‰∫ãÊ•≠„ÅÆÂÖ®ÈÉ®„ÅÆË≠≤Ê∏°„ÄÅ„Åæ„Åü„ÅØ‰∫ãÊ•≠„ÅÆÈáçË¶Å„Å™‰∏ÄÈÉ®„ÅÆË≠≤Ê∏°ÔºàË≠≤Ê∏°Ë≥áÁî£„ÅåÁ∑èË≥áÁî£„ÅÆ1/5Ë∂Ö„Å™„Å©Ôºâ„Å´„ÅØ„ÄÅÊ†™‰∏ªÁ∑è‰ºö„ÅÆÁâπÂà•Ê±∫Ë≠∞„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ"
        }
    ]
}

# Load generated questions
json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
if os.path.exists(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            generated_questions = json.load(f)
            for subject, questions in generated_questions.items():
                if subject in drill_questions:
                    drill_questions[subject].extend(questions)
                else:
                    drill_questions[subject] = questions
    except Exception as e:
        st.error(f"Failed to load generated questions: {e}")

# Load Study Materials (Syllabus)
def load_study_materials():
    # Looking for 'studying' folder in 'platform' directory (moved inside)
    materials_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'studying')
    syllabus = {}
    extra_pdfs = []
    
    if not os.path.exists(materials_dir):
        return {}, []
        
    for filename in os.listdir(materials_dir):
        if filename.endswith('.xlsx') and not filename.startswith('~$'): # Ignore temp files
            try:
                # Extract subject from filename (e.g., "1-Ë≤°Âãô‰ºöË®àË´ñ„Ç≥„Éº„Çπ.xlsx" -> "Ë≤°Âãô‰ºöË®àË´ñ")
                parts = filename.split('-')
                if len(parts) > 1:
                    subject_name = parts[1].replace('„Ç≥„Éº„Çπ.xlsx', '')
                else:
                    subject_name = filename.replace('.xlsx', '')
                
                # Read Excel
                file_path = os.path.join(materials_dir, filename)
                df = pd.read_excel(file_path, header=1)
                
                # Fill merged cells (NaN) with previous value
                if '„Ç´„ÉÜ„Ç¥„É™' in df.columns:
                    df['„Ç´„ÉÜ„Ç¥„É™'] = df['„Ç´„ÉÜ„Ç¥„É™'].ffill()
                if '„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™' in df.columns:
                    df['„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™'] = df['„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™'].ffill()
                
                # Filter relevant columns
                if 'Ë¨õÂ∫ßÂêç' in df.columns:
                    items = []
                    for _, row in df.iterrows():
                        if pd.notna(row['Ë¨õÂ∫ßÂêç']):
                            items.append({
                                'category': row.get('„Ç´„ÉÜ„Ç¥„É™', ''),
                                'subcategory': row.get('„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™', ''),
                                'title': row['Ë¨õÂ∫ßÂêç'],
                                'duration': row.get('ÂÜçÁîüÊôÇÈñì/Ê®ôÊ∫ñÊôÇÈñì', '')
                            })
                    
                    # Find corresponding PDF
                    pdf_path = os.path.join(materials_dir, filename.replace('.xlsx', '.pdf'))
                    has_pdf = os.path.exists(pdf_path)
                    
                    syllabus[subject_name] = {
                        'items': items,
                        'pdf_path': pdf_path if has_pdf else None,
                        'excel_path': file_path
                    }
            except Exception as e:
                print(f"Error loading {filename}: {e}")
    
    # Load extra PDFs from 'PDF' subdirectory
    pdf_dir = os.path.join(materials_dir, 'PDF')
    if os.path.exists(pdf_dir):
        for f in os.listdir(pdf_dir):
            if f.lower().endswith('.pdf'):
                extra_pdfs.append({
                    'name': f,
                    'path': os.path.join(pdf_dir, f)
                })
                
    # Also load standalone PDFs in the root of 'studying' that are not paired with an Excel file
    # Get list of PDF paths already associated with courses
    paired_pdfs = set()
    for subject_data in syllabus.values():
        if subject_data['pdf_path']:
            paired_pdfs.add(os.path.normpath(subject_data['pdf_path']))
            
    for filename in os.listdir(materials_dir):
        if filename.lower().endswith('.pdf'):
            full_path = os.path.join(materials_dir, filename)
            if os.path.normpath(full_path) not in paired_pdfs:
                extra_pdfs.append({
                    'name': filename,
                    'path': full_path
                })
                
    return syllabus, extra_pdfs

study_materials, extra_pdfs = load_study_materials()

roadmap_md = """
# CPA 1.5 Year Strategy Roadmap

## Phase 0: Foundation (2026)
* **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics.
* **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
* **Jul - Sep**: **CRITICAL** Start Tax Law & Electives.
* **Oct - Dec**: **Dec Short Exam Challenge**. Aim to pass!

## Phase 1: Short Exam Mastery (Jan - May 2027)
* **Jan - Mar**: Solidify basics. 75%+ in drills.
* **Apr - May**: Peak conditioning. Rote memorization.

## Phase 2: Essay Sprint (Jun - Aug 2027)
* **Jun**: Revive Tax/Elective knowledge.
* **Jul**: Output training (Writing).
* **Aug**: Final adjustments.
"""

# Navigation
st.sidebar.title("CPA Platform 2027")

# User Profile in Sidebar
with st.sidebar.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        st.markdown("### üéì")
    with col2:
        curr_level = st.session_state.data.get('level', 1)
        st.write(f"**Level {curr_level}**")
    
    curr_xp = st.session_state.data.get('xp', 0)
    next_level_xp = curr_level * 100
    progress = min(curr_xp / next_level_xp, 1.0)
    st.progress(progress)
    st.caption(f"XP: {curr_xp} / {next_level_xp}")

st.sidebar.markdown("---")

# Quick Links
st.sidebar.markdown("""
    <style>
    .big-rocket-button {
        display: inline-block;
        width: 100%;
        padding: 12px;
        background: linear-gradient(135deg, #FF4B4B 0%, #FF0000 100%);
        color: white !important;
        text-align: center;
        font-size: 18px;
        font-weight: 900;
        border-radius: 12px;
        text-decoration: none !important;
        box-shadow: 0 4px 15px rgba(255, 0, 0, 0.4);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        border: 2px solid rgba(255, 255, 255, 0.2);
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .big-rocket-button:hover {
        background: linear-gradient(135deg, #FF0000 0%, #D00000 100%);
        transform: translateY(-2px) scale(1.02);
        box-shadow: 0 6px 20px rgba(255, 0, 0, 0.6);
        border-color: rgba(255, 255, 255, 0.5);
    }
    .big-rocket-button:active {
        transform: translateY(1px);
        box-shadow: 0 2px 10px rgba(255, 0, 0, 0.3);
    }
    </style>
    <a href="https://member.studying.jp/top/" target="_blank" class="big-rocket-button">
        üöÄ STUDYING
    </a>
    """, unsafe_allow_html=True)

st.sidebar.markdown("---")
page = st.sidebar.radio("Navigation", ["Dashboard üìä", "My Syllabus üìö", "Vocabulary üìñ", "Old Exams üìÑ", "Study Timer ‚è±Ô∏è", "Mock Exams üìù", "Scores üìà", "Drills üîß", "Survival Mode ‚ö°", "Roadmap üó∫Ô∏è", "Big 4 Job Hunting üíº", "Company Directory üè¢", "Future üöÄ"])

if page == "Dashboard üìä":
    st.header("Dashboard üöÄ")
    
    # --- Top Metrics Row ---
    st.subheader("üìä At a Glance")
    today = date.today()
    
    # Calculate Metrics
    # 1. Study Time Today
    logs_df = pd.DataFrame(st.session_state.data.get("logs", []))
    minutes_today = 0
    if not logs_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_logs = logs_df[logs_df['date'] == today_str]
        minutes_today = today_logs['duration'].sum()
    
    # 2. Quizzes Today
    scores_df = pd.DataFrame(st.session_state.data.get("scores", []))
    quizzes_today = 0
    avg_score_today = 0
    if not scores_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_scores = scores_df[scores_df['date'] == today_str]
        quizzes_today = len(today_scores)
        if quizzes_today > 0:
            avg_score_today = today_scores['val'].mean()

    # 3. Total XP
    total_xp = st.session_state.data.get('xp', 0)

    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Study Time (Today)", f"{minutes_today} min", delta=f"{minutes_today/60:.1f} hrs")
    m2.metric("Quizzes Completed", f"{quizzes_today}", delta=f"Avg: {avg_score_today:.0f}%" if quizzes_today > 0 else None)
    m3.metric("Total XP", f"{total_xp}", delta="Level Up Soon?" if total_xp % 100 > 80 else None)
    
    # 4. Nearest Deadline
    target_short = date(2026, 12, 13)
    days_short = (target_short - today).days
    m4.metric("Next Exam (Dec Short)", f"{days_short} Days", delta="-1 Day", delta_color="inverse")
    
    st.markdown("---")

    # --- Main Content Grid ---
    c_main_1, c_main_2 = st.columns([2, 1])
    
    with c_main_1:
        st.subheader("üóìÔ∏è Exam Countdown")
        
        # Enhanced Countdown Cards
        cd1, cd2, cd3 = st.columns(3)
        
        with cd1:
            target = date(2026, 12, 13)
            diff = (target - today).days
            st.info(f"**Dec 2026 Short**\n\n# {max(0, diff)} Days\n\n*Target: 60%*")
            
        with cd2:
            target = date(2027, 5, 23)
            diff = (target - today).days
            st.warning(f"**May 2027 Short**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")
            
        with cd3:
            target = date(2027, 8, 20)
            diff = (target - today).days
            st.error(f"**Aug 2027 Essay**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")

        # Weakness Analysis
        st.subheader("üß† Weak Areas Analysis")
        if not scores_df.empty:
            # Group by subject and calculate mean
            subject_perf = scores_df.groupby('subject')['val'].mean().sort_values()
            weakest_subject = subject_perf.index[0]
            weakest_score = subject_perf.iloc[0]
            
            st.markdown(f"""
            <div style="padding: 15px; border-radius: 10px; background-color: #fff3cd; border: 1px solid #ffeeba; color: #856404;">
                <h4>‚ö†Ô∏è Focus Area: {weakest_subject} ({weakest_score:.1f}%)</h4>
                <p>Your performance in <b>{weakest_subject}</b> is lower than other subjects. Consider doing a targeted drill.</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button(f"üî• Start {weakest_subject} Drill Now"):
                # Redirect logic (simulated by setting session state)
                # Note: Direct page switching in Streamlit is tricky without rerun, 
                # but we can set the quiz state to active for this subject
                # Ideally, user goes to Drills tab, but we can hint them.
                st.toast(f"Go to 'Drills' tab and select {weakest_subject}!", icon="üëâ")
        else:
            st.info("Complete some drills to identify your weak areas.")

        # Recent Activity Chart (Last 7 Days)
        st.subheader("üìà Study Consistency (Last 7 Days)")
        if not logs_df.empty:
            # Filter last 7 days
            logs_df['date'] = pd.to_datetime(logs_df['date']).dt.date
            last_7_days = [today - pd.Timedelta(days=i) for i in range(6, -1, -1)]
            
            daily_minutes = []
            for d in last_7_days:
                day_logs = logs_df[logs_df['date'] == d]
                daily_minutes.append(day_logs['duration'].sum())
            
            chart_data = pd.DataFrame({
                "Date": last_7_days,
                "Minutes": daily_minutes
            })
            
            fig_activity = px.bar(chart_data, x="Date", y="Minutes", title="Daily Study Time")
            st.plotly_chart(fig_activity, use_container_width=True)
        else:
            st.info("Log your study sessions to see your consistency chart.")


    with c_main_2:
        # Skill Radar
        st.subheader("Skills")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        radar_scores = [30] * 6 # Default
        
        if not scores_df.empty:
            avg_scores = []
            for sub in subjects:
                sub_df = scores_df[scores_df['subject'] == sub]
                if not sub_df.empty:
                    avg_scores.append(sub_df['val'].mean())
                else:
                    avg_scores.append(30) # Default baseline
            radar_scores = avg_scores
            
        fig = go.Figure(data=go.Scatterpolar(
            r=radar_scores,
            theta=subjects,
            fill='toself',
            name='Current Skill'
        ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])), 
            showlegend=False,
            margin=dict(l=20, r=20, t=20, b=20),
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Daily Tip Card
        st.subheader("üí° Daily Tip")
        tips = [
            "Consistency is key. 30 minutes every day is better than 5 hours once a week.",
            "Focus on 'why', not just 'how'. Understanding the logic helps in applied questions.",
            "Don't ignore the theory. It's 40-50% of the exam.",
            "Review your mistakes. The 'incorrect' options are learning opportunities.",
            "Sleep is part of studying. Memory consolidation happens during sleep.",
            "Use the 'Survival Mode' to build speed and accuracy under pressure!",
            "Audit isn't just memorization; imagine you are the auditor in that situation."
        ]
        import random
        st.info(random.choice(tips))
        
        # Progress
        st.subheader("Phase 0 Progress")
        st.progress(15)
        st.caption("Goal: Foundation Mastery")

elif page == "My Syllabus üìö":
    st.header("My Study Syllabus üìö")
    st.info("Based on your uploaded materials in 'studying' folder.")
    
    if not study_materials and not extra_pdfs:
        st.warning("No study materials found in 'studying' folder.")
    else:
        # Progress Tracking
        if 'syllabus_progress' not in st.session_state.data:
            st.session_state.data['syllabus_progress'] = []
            
        completed_items = set(st.session_state.data['syllabus_progress'])
        
        # Callback for checkbox
        def toggle_syllabus(key):
            if key in st.session_state.data['syllabus_progress']:
                st.session_state.data['syllabus_progress'].remove(key)
            else:
                st.session_state.data['syllabus_progress'].append(key)
                # Add XP for completing a lecture!
                st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + 50
                st.toast("Lecture Completed! +50 XP", icon="üéì")
            save_data(st.session_state.data)

        # Tabs for subjects
        if study_materials:
            subjects = list(study_materials.keys())
            tabs = st.tabs(subjects)
            
            for i, subject in enumerate(subjects):
                with tabs[i]:
                    data = study_materials[subject]
                    items = data['items']
                    pdf_path = data['pdf_path']
                    excel_path = data['excel_path']
                    
                    # Header Actions
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        st.subheader(f"{subject} ({len(items)} Lectures)")
                    with c2:
                        if pdf_path:
                            if st.button(f"üìÑ Open PDF", key=f"pdf_{subject}"):
                                try:
                                    os.startfile(pdf_path)
                                    st.toast(f"Opening {subject} PDF...", icon="üöÄ")
                                except Exception as e:
                                    st.error(f"Cannot open PDF: {e}")
                        
                        if st.button(f"üìä Open Excel", key=f"excel_{subject}"):
                            try:
                                os.startfile(excel_path)
                                st.toast(f"Opening {subject} Excel...", icon="üìä")
                            except Exception as e:
                                st.error(f"Cannot open Excel: {e}")

                    
                    # Progress Bar for Subject
                    subject_completed = [item['title'] for item in items if f"{subject}|{item['title']}" in completed_items]
                    prog = len(subject_completed) / len(items) if items else 0
                    st.progress(prog)
                    st.caption(f"Progress: {len(subject_completed)} / {len(items)} ({prog:.1%})")
                    
                    # Group by Category/Subcategory
                    df = pd.DataFrame(items)
                    if not df.empty and 'category' in df.columns:
                        for cat, group in df.groupby('category'):
                            with st.expander(f"üìÇ {cat}", expanded=True):
                                for idx, row in group.iterrows():
                                    title = row['title']
                                    unique_key = f"{subject}|{title}"
                                    is_done = unique_key in completed_items
                                    
                                    c_chk, c_txt, c_time = st.columns([0.5, 4, 1.5])
                                    with c_chk:
                                        # Use subject and index to ensure widget key uniqueness
                                        st.checkbox("", value=is_done, key=f"chk_{subject}_{idx}", on_change=toggle_syllabus, kwargs={'key': unique_key})
                                    
                                    with c_txt:
                                        if is_done:
                                            st.markdown(f"~~{title}~~")
                                        else:
                                            st.markdown(f"**{title}**")
                                            if row['subcategory']:
                                                st.caption(f"‚îî {row['subcategory']}")
                                                
                                    with c_time:
                                        st.caption(f"‚è±Ô∏è {row['duration']}")

        # Supplemental Resources (Extra PDFs)
        if extra_pdfs:
            st.markdown("---")
            st.subheader("üìö Supplemental Resources")
            for i, pdf in enumerate(extra_pdfs):
                c1, c2 = st.columns([4, 1])
                with c1:
                    st.markdown(f"üìÑ **{pdf['name']}**")
                with c2:
                    if st.button("Open", key=f"extra_pdf_{i}_{pdf['name']}"):
                        try:
                            os.startfile(pdf['path'])
                            st.toast(f"Opening {pdf['name']}...", icon="üöÄ")
                        except Exception as e:
                            st.error(f"Cannot open PDF: {e}")

elif page == "Vocabulary üìñ":
    st.header("Vocabulary Mastery üìñ")
    st.info("Master the essential accounting terminology in Japanese and English.")

    # Create Tabs
    tab1, tab2 = st.tabs(["üìö Word List", "‚ö° Tap & Study (Flashcards)"])

    # --- TAB 1: Word List ---
    with tab1:
        st.subheader("Bilingual Terminology List")
        
        # Subject Selection
        subjects = list(vocab_data.keys())
        selected_subject = st.selectbox("Select Subject", subjects, key="vocab_list_subject")
        
        if selected_subject:
            terms = vocab_data[selected_subject]
            st.write(f"Found {len(terms)} terms for **{selected_subject}**.")
            
            for term in terms:
                with st.expander(f"**{term['term']}** ({term['jp']})"):
                    st.markdown(f"**üáØüáµ Definition:** {term['desc']}")
                    st.markdown(f"**üá∫üá∏ Definition:** {term.get('desc_en', 'No English definition available.')}")

    # --- TAB 2: Flashcards ---
    with tab2:
        st.subheader("‚ö° Flashcard Mode")
        st.markdown("Tap to flip the card, swipe (click next) to move to the next word.")
        
        # Initialize Session State for Flashcards
        if 'flashcard_active' not in st.session_state:
            st.session_state.flashcard_active = False
            st.session_state.flashcard_subject = subjects[0]
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False

        # Subject Selection for Flashcards
        fc_subject = st.selectbox("Select Subject for Study", subjects, key="fc_subject_selector")
        
        # Start/Reset Button
        if st.button("Start / Restart Session", type="primary"):
            st.session_state.flashcard_active = True
            st.session_state.flashcard_subject = fc_subject
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False
            st.rerun()

        if st.session_state.flashcard_active:
            current_terms = vocab_data.get(st.session_state.flashcard_subject, [])
            total_cards = len(current_terms)
            
            if total_cards == 0:
                st.warning("No words available for this subject.")
            else:
                current_idx = st.session_state.flashcard_index
                
                # Check if session is finished
                if current_idx >= total_cards:
                    st.balloons()
                    st.success(f"üéâ You've completed all {total_cards} words for {st.session_state.flashcard_subject}!")
                    if st.button("Start Over"):
                        st.session_state.flashcard_index = 0
                        st.session_state.flashcard_flipped = False
                        st.rerun()
                else:
                    word_data = current_terms[current_idx]
                    
                    # Progress Bar
                    progress = (current_idx + 1) / total_cards
                    st.progress(progress)
                    st.caption(f"Card {current_idx + 1} of {total_cards}")

                    # Card Container
                    card_container = st.container()
                    
                    # Card Logic
                    with card_container:
                        # Styling
                        st.markdown("""
                        <style>
                        .flashcard {
                            border: 2px solid #e0e0e0;
                            border-radius: 15px;
                            padding: 40px;
                            text-align: center;
                            background-color: white;
                            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                            min-height: 200px;
                            display: flex;
                            flex-direction: column;
                            justify-content: center;
                            align-items: center;
                            margin-bottom: 20px;
                        }
                        .flashcard-term { font-size: 28px; font-weight: bold; color: #1e88e5; }
                        .flashcard-jp { font-size: 24px; font-weight: bold; color: #d32f2f; margin-top: 10px;}
                        .flashcard-desc { font-size: 16px; color: #424242; margin-top: 15px; }
                        </style>
                        """, unsafe_allow_html=True)

                        if not st.session_state.flashcard_flipped:
                            # FRONT SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div style="color: #9e9e9e; margin-top: 20px;">(Tap 'Flip' to see meaning)</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            if st.button("üîÑ Flip Card", use_container_width=True):
                                st.session_state.flashcard_flipped = True
                                st.rerun()
                                
                        else:
                            # BACK SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div class="flashcard-jp">{word_data['jp']}</div>
                                <div class="flashcard-desc">üáØüáµ {word_data['desc']}</div>
                                <div class="flashcard-desc">üá∫üá∏ {word_data.get('desc_en', '')}</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            col_prev, col_next = st.columns(2)
                            with col_prev:
                                if st.button("‚¨ÖÔ∏è Previous", use_container_width=True):
                                    if st.session_state.flashcard_index > 0:
                                        st.session_state.flashcard_index -= 1
                                        st.session_state.flashcard_flipped = False
                                        st.rerun()
                            
                            with col_next:
                                if st.button("Next ‚û°Ô∏è", use_container_width=True):
                                    st.session_state.flashcard_index += 1
                                    st.session_state.flashcard_flipped = False
                                    st.rerun()

elif page == "Old Exams üìÑ":
    st.header("Old Exam Papers üìÑ")
    
    # Path to EXAM folder
    # platform/app.py -> platform/EXAM
    base_dir = os.path.dirname(os.path.abspath(__file__))
    exam_dir = os.path.join(base_dir, 'EXAM')
    metadata_file = os.path.join(base_dir, 'exam_metadata.json')
    
    metadata = {}
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
        except Exception as e:
            st.error(f"Error loading metadata: {e}")

    if not os.path.exists(exam_dir):
        st.error(f"EXAM directory not found at: {exam_dir}")
    else:
        # --- Vocab Analysis Section ---
        vocab_file = os.path.join(base_dir, 'exam_vocab.json')
        if os.path.exists(vocab_file):
            with st.expander("üìä Exam Vocabulary Analysis (Tangocho)", expanded=False):
                st.info("Top frequent words extracted from actual exam papers. Master these!")
                
                try:
                    with open(vocab_file, "r", encoding="utf-8") as f:
                        exam_vocab = json.load(f)
                    
                    # Subject selector
                    subjects = list(exam_vocab.keys())
                    if subjects:
                        selected_subject = st.selectbox("Select Subject for Vocabulary", subjects)
                        
                        if selected_subject:
                            words = exam_vocab[selected_subject]
                            
                            # Display as a dataframe or cloud
                            # Create a nice dataframe
                            df_vocab = pd.DataFrame(words)
                            df_vocab.columns = ["Word", "Frequency"]
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.dataframe(df_vocab, use_container_width=True, height=400)
                                
                            with col2:
                                if not df_vocab.empty:
                                    st.markdown("### Top Keywords")
                                    # Create a bar chart
                                    fig = px.bar(
                                        df_vocab.head(20), 
                                        x='Frequency', 
                                        y='Word', 
                                        orientation='h',
                                        title=f"Top 20 Words in {selected_subject}",
                                        color='Frequency',
                                        color_continuous_scale='Viridis'
                                    )
                                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"Error loading vocabulary: {e}")
        
        st.divider()

        files = [f for f in os.listdir(exam_dir) if f.lower().endswith('.pdf')]
        
        if not files:
            st.warning("No PDF exam papers found.")
        else:
            st.write(f"Found {len(files)} exam papers.")
            
            # Sort by filename to keep subjects grouped (01, 02, ...)
            for f in sorted(files):
                info = metadata.get(f, {})
                display_title = f"**{f}**"
                sub_info = ""
                
                if info:
                    # Construct nice title
                    # e.g. R7 Short-Answer (Tanto) I - Corporate Law (‰ºÅÊ•≠Ê≥ï)
                    year = info.get('year', '')
                    exam_type = info.get('type', '')
                    subject = info.get('subject', '')
                    
                    # Create a clean badge-like string
                    display_title = f"**{subject}** - {year} {exam_type}"
                    sub_info = f"Filename: {f}"
                
                with st.container():
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"üìÑ {display_title}")
                        if sub_info:
                            st.caption(sub_info)
                    with col2:
                        if st.button("Open", key=f"open_exam_{f}"):
                            try:
                                file_path = os.path.join(exam_dir, f)
                                if os.name == 'nt':
                                    os.startfile(file_path)
                                    st.toast(f"Opening {f}...", icon="üöÄ")
                                else:
                                    st.warning("File opening is only supported on Windows locally.")
                            except Exception as e:
                                st.error(f"Error opening file: {e}")
                    st.divider()
            
            st.info("üí° Tip: Use these papers to practice time management.")

elif page == "Study Timer ‚è±Ô∏è":
    st.header("Study Timer")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Log Study Session")
        with st.form("timer_form"):
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective"])
            duration = st.number_input("Duration (minutes)", min_value=1, value=60)
            date_val = st.date_input("Date", value=date.today())
            submitted = st.form_submit_button("Log Session")
            
            if submitted:
                new_log = {
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'duration': duration
                }
                st.session_state.data["logs"].append(new_log)
                save_data(st.session_state.data)
                st.success("Session logged!")
                
    with col2:
        st.subheader("Recent Logs")
        if st.session_state.data["logs"]:
            df_logs = pd.DataFrame(st.session_state.data["logs"])
            st.dataframe(df_logs.sort_values('date', ascending=False))
            
            total_mins = df_logs['duration'].sum()
            hours = total_mins // 60
            mins = total_mins % 60
            st.metric("Total Study Time", f"{hours}h {mins}m")
        else:
            st.info("No logs yet.")

elif page == "Mock Exams üìù":
    st.header("Mock Exam Schedule")
    df_exams = pd.DataFrame(mock_exams)
    st.table(df_exams)

elif page == "Scores üìà":
    st.header("Score Tracker")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        with st.form("score_form"):
            name = st.text_input("Exam/Drill Name")
            date_val = st.date_input("Date", value=date.today())
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective", "Total"])
            val = st.number_input("Score (%)", min_value=0, max_value=100, value=70)
            submitted = st.form_submit_button("Save Score")
            
            if submitted:
                new_score = {
                    'name': name,
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'val': val
                }
                st.session_state.data["scores"].append(new_score)
                save_data(st.session_state.data)
                st.success("Score saved!")
                
    with col2:
        if st.session_state.data["scores"]:
            df = pd.DataFrame(st.session_state.data["scores"])
            st.subheader("History")
            st.dataframe(df.sort_values('date', ascending=False))
            
            # Line Chart
            st.subheader("Trend")
            fig = go.Figure()
            for sub in df['subject'].unique():
                sub_df = df[df['subject'] == sub].sort_values('date')
                fig.add_trace(go.Scatter(x=sub_df['date'], y=sub_df['val'], mode='lines+markers', name=sub))
            fig.update_layout(yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No scores recorded yet.")

elif page == "Drills üîß":
    st.header("Drills ‚úèÔ∏è")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("Select Topic")
        subject = st.radio("Subject", ["Financial", "Management", "Audit", "Company"])
        
        st.subheader("Select Level")
        level = st.radio("Level", ["Level 1 (Basic)", "Level 2 (Standard)", "Level 3 (Advanced)", "Vocabulary (Important Words)"])
        level_map = {
            "Level 1 (Basic)": 1, 
            "Level 2 (Standard)": 2, 
            "Level 3 (Advanced)": 3,
            "Vocabulary (Important Words)": "vocab"
        }
        selected_level = level_map[level]
        
        if selected_level == "vocab":
            st.info("üí° Hint: These are key English terms often found in global accounting standards (IFRS/US GAAP).")
            
            # Add Tangocyo List View
            with st.expander("üìñ View Vocabulary List (Tangocyo)"):
                vocab_list_view = vocab_data.get(subject, [])
                if vocab_list_view:
                    for v in vocab_list_view:
                        st.markdown(f"**{v['term']}** ({v['jp']})")
                        st.markdown(f"- üáØüáµ {v['desc']}")
                        st.markdown(f"- üá∫üá∏ {v.get('desc_en', '')}")
                        st.divider()
                else:
                    st.warning("No vocabulary data available.")
    
        # Load generated questions if available and not already loaded
        if 'generated_questions' not in st.session_state:
            try:
                with open('questions.json', 'r', encoding='utf-8') as f:
                    st.session_state.generated_questions = json.load(f)
            except FileNotFoundError:
                st.session_state.generated_questions = {}

        if st.button("Start / Restart Quiz"):
            import random
            st.session_state.quiz_state['active'] = True
            st.session_state.quiz_state['subject'] = subject
            st.session_state.quiz_state['level'] = selected_level
            st.session_state.quiz_state['q_index'] = 0
            st.session_state.quiz_state['score'] = 0
            st.session_state.quiz_state['show_feedback'] = False
            st.session_state.quiz_state['selected_option'] = None
            
            # Select questions based on level
            if selected_level == "vocab":
                vocab_list = vocab_data.get(subject, [])
                if vocab_list:
                    vocab_questions = []
                    for v in vocab_list:
                        vocab_questions.append({
                            'q': f"„ÄêÈáçË¶ÅË™ûÂè•„Äë „Äå{v['term']}„Äç „ÅÆÊÑèÂë≥„Å®„Åó„Å¶ÊúÄ„ÇÇÈÅ©Âàá„Å™„ÇÇ„ÅÆ„ÅØÔºü",
                            'options': [v['desc'], "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: ÈÄÜ„ÅÆÊÑèÂë≥Ôºâ", "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: ÁÑ°Èñ¢‰øÇ„Å™ÂÆöÁæ©Ôºâ", "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: È°û‰ººÁî®Ë™û„ÅÆÂÆöÁæ©Ôºâ"],
                            'correct': 0,
                            'explanation': f"**{v['term']} ({v['jp']})**\n\n**üáØüáµ Êó•Êú¨Ë™û:** {v['desc']}\n\n**üá∫üá∏ English:** {v.get('desc_en', 'No English description available.')}",
                            'type': 'vocab'
                        })
                    # Shuffle options for each question
                    for q in vocab_questions:
                        correct_opt = q['options'][0]
                        random.shuffle(q['options'])
                        q['correct'] = q['options'].index(correct_opt)
                    
                    st.session_state.quiz_state['questions'] = vocab_questions
                else:
                    st.warning(f"No vocabulary data for {subject} yet.")
                    st.session_state.quiz_state['active'] = False
            
            elif selected_level == 2 or selected_level == 3:
                # Use generated questions for Level 2/3
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level_gen_qs = [q for q in gen_qs if q.get('level') == selected_level]
                
                if level_gen_qs:
                     # Pick 10 random questions
                    if len(level_gen_qs) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(level_gen_qs, 10)
                    else:
                        st.session_state.quiz_state['questions'] = level_gen_qs
                else:
                    st.warning(f"No generated questions for {subject} Level {selected_level} yet.")
                    st.session_state.quiz_state['active'] = False

            else:
                # Level 1 (Static questions + Generated Level 0)
                raw_questions = drill_questions.get(subject, [])
                # Filter for Level 1 or undefined (legacy)
                static_level1 = [q for q in raw_questions if q.get('level', 1) == 1]
                
                # Fetch Level 0 from generated questions
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level0_gen_qs = [q for q in gen_qs if q.get('level') == 0]
                
                # Merge
                all_level1_questions = static_level1 + level0_gen_qs
                
                if all_level1_questions:
                    # Random sample if too many
                    if len(all_level1_questions) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(all_level1_questions, 10)
                    else:
                        st.session_state.quiz_state['questions'] = all_level1_questions
                else:
                    st.warning(f"No questions found for {subject} Level 1.")
                    st.session_state.quiz_state['active'] = False
                
    with col2:
        qs = st.session_state.quiz_state
        if qs['active']:
            current_q = qs['questions'][qs['q_index']]
            total_q = len(qs['questions'])
            
            st.subheader(f"Question {qs['q_index'] + 1} / {total_q}")
            st.markdown(f"**{current_q['q']}**")
            
            # Options
            options = current_q['options']
            
            # If feedback is shown, disable interaction or show result
            if qs['show_feedback']:
                for idx, opt in enumerate(options):
                    if idx == current_q['correct']:
                        st.markdown(f"<div class='correct-answer'>{opt} (Correct)</div>", unsafe_allow_html=True)
                    elif idx == qs['selected_option']:
                        st.markdown(f"<div class='incorrect-answer'>{opt} (Your Answer)</div>", unsafe_allow_html=True)
                    else:
                        st.text(opt)
                
                st.markdown("### Explanation")
                st.info(current_q['explanation'])
                
                if qs['q_index'] < total_q - 1:
                    if st.button("Next Question"):
                        qs['q_index'] += 1
                        qs['show_feedback'] = False
                        qs['selected_option'] = None
                        st.rerun()
                else:
                    score = qs['score']
                    st.success(f"Quiz Completed! Score: {score} / {total_q}")
                    
                    if st.button("Finish & Claim XP"):
                        # XP Logic
                        earned_xp = score * 10
                        current_xp = st.session_state.data.get('xp', 0)
                        current_level = st.session_state.data.get('level', 1)
                        
                        new_xp = current_xp + earned_xp
                        required_xp = current_level * 100
                        
                        leveled_up = False
                        while new_xp >= required_xp:
                            new_xp -= required_xp
                            current_level += 1
                            required_xp = current_level * 100
                            leveled_up = True
                        
                        st.session_state.data['xp'] = new_xp
                        st.session_state.data['level'] = current_level
                        
                        # Save score history
                        st.session_state.data["scores"].append({
                            'name': f"Drill: {qs.get('subject', 'General')} Lv{qs.get('level', '?')}",
                            'date': date.today().strftime("%Y-%m-%d"),
                            'subject': qs.get('subject', 'General'),
                            'val': (score / total_q) * 100 if total_q > 0 else 0
                        })
                        save_data(st.session_state.data)
                        
                        if leveled_up:
                            st.balloons()
                            st.success(f"LEVEL UP! You are now Level {current_level}!")
                        else:
                            st.success(f"Earned {earned_xp} XP!")
                            
                        qs['active'] = False
                        st.rerun()
                        
            else:
                choice = st.radio("Choose Answer:", options, index=None, key=f"q_{qs['q_index']}")
                if st.button("Submit Answer"):
                    if choice:
                        selected_idx = options.index(choice)
                        qs['selected_option'] = selected_idx
                        qs['show_feedback'] = True
                        if selected_idx == current_q['correct']:
                            qs['score'] += 1
                        st.rerun()
                    else:
                        st.warning("Please select an option.")
        else:
            st.info("Select a subject and level from the sidebar to start.")

elif page == "Survival Mode ‚ö°":
    st.header("‚ö° Survival Mode")
    st.markdown("### Challenge your limits! 3 Strikes and you're out.")
    
    # Initialize State
    if 'survival' not in st.session_state:
        st.session_state.survival = {
            'active': False,
            'lives': 3,
            'streak': 0,
            'score': 0,
            'q': None,
            'feedback': False,
            'user_ans': None,
            'target_streak': "Unlimited"
        }
    
    ss = st.session_state.survival
    
    # Load Questions Logic
    if 'all_questions' not in st.session_state:
        all_qs = []
        # Static
        for sub, qs in drill_questions.items():
            for q in qs:
                # Create a copy to avoid modifying original
                q_copy = q.copy()
                q_copy['subject'] = sub
                all_qs.append(q_copy)
        # Generated
        json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
        if os.path.exists(json_path):
             try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gen_qs = json.load(f)
                    for sub, qs in gen_qs.items():
                        for q in qs:
                            q_copy = q.copy()
                            q_copy['subject'] = sub
                            all_qs.append(q_copy)
             except:
                 pass
        st.session_state.all_questions = all_qs
    
    if not ss['active']:
        st.subheader("Select Challenge Mode")
        streak_target = st.radio("Target Streak", ["Unlimited", 1, 5, 10], horizontal=True, format_func=lambda x: "‚àû Unlimited" if x == "Unlimited" else f"Target: {x} üî•")

        if st.button("üöÄ Start Challenge", use_container_width=True):
            ss['active'] = True
            ss['lives'] = 3
            ss['streak'] = 0
            ss['score'] = 0
            ss['q'] = None
            ss['feedback'] = False
            ss['target_streak'] = streak_target
            st.rerun()
            
    else:
        # Metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("Lives", "‚ù§Ô∏è" * ss['lives'])
        target_display = "‚àû" if ss.get('target_streak', "Unlimited") == "Unlimited" else ss['target_streak']
        c2.metric("Streak", f"üî• {ss['streak']} / {target_display}")
        c3.metric("Score", ss['score'])
        
        target = ss.get('target_streak', "Unlimited")
        is_win = target != "Unlimited" and ss['streak'] >= target

        if ss['lives'] <= 0 or is_win:
            if is_win:
                st.balloons()
                st.success(f"üéâ MISSION ACCOMPLISHED! You reached a {ss['streak']} streak!")
            else:
                st.error("üíÄ GAME OVER")
            
            st.markdown(f"### Final Score: {ss['score']}")
            
            # Save High Score
            if ss['score'] > 0:
                st.session_state.data["scores"].append({
                    'name': f"Survival Mode ‚ö° (Target {target})",
                    'date': date.today().strftime("%Y-%m-%d"),
                    'subject': 'Survival',
                    'val': ss['score'] # Just storing score
                })
                save_data(st.session_state.data)
            
            if st.button("Try Again", use_container_width=True):
                ss['active'] = False
                st.rerun()
        else:
            # Get Question
            if ss['q'] is None:
                import random
                if st.session_state.all_questions:
                    q_data = random.choice(st.session_state.all_questions)
                    # Shuffle options
                    opts = q_data['options'].copy()
                    correct_text = q_data['options'][q_data['correct']]
                    random.shuffle(opts)
                    
                    ss['q'] = {
                        'q': q_data['q'],
                        'options': opts,
                        'correct_idx': opts.index(correct_text),
                        'explanation': q_data['explanation'],
                        'subject': q_data.get('subject', 'General')
                    }
                else:
                    st.error("No questions found!")
                    st.stop()
            
            q = ss['q']
            
            st.markdown(f"**[{q['subject']}]** {q['q']}")
            
            if not ss['feedback']:
                # Use a form to prevent reload on radio selection
                with st.form(key=f"surv_form_{ss['score']}_{ss['lives']}"):
                    ans = st.radio("Select Answer:", q['options'])
                    submit = st.form_submit_button("Submit Answer")
                    
                    if submit:
                        ss['user_ans'] = q['options'].index(ans)
                        ss['feedback'] = True
                        
                        if ss['user_ans'] == q['correct_idx']:
                            # Bonus XP for streak
                            bonus = ss['streak'] * 2
                            points = 10 + bonus
                            ss['score'] += points
                            ss['streak'] += 1
                            st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + points
                            st.toast(f"Correct! +{points} XP", icon="‚úÖ")
                            
                            # Check Win
                            target = ss.get('target_streak', "Unlimited")
                            if target != "Unlimited" and ss['streak'] >= target:
                                st.rerun()
                        else:
                            ss['lives'] -= 1
                            ss['streak'] = 0
                            st.toast("Wrong Answer!", icon="‚ùå")
                        
                        st.rerun()
            else:
                # Show Feedback
                if ss['user_ans'] == q['correct_idx']:
                    st.success("‚úÖ Correct!")
                else:
                    st.error(f"‚ùå Wrong! Correct: {q['options'][q['correct_idx']]}")
                
                st.info(f"**Explanation:**\n\n{q['explanation']}")
                
                if st.button("Next Question ‚û°", use_container_width=True):
                    ss['q'] = None
                    ss['feedback'] = False
                    st.rerun()

elif page == "Roadmap üó∫Ô∏è":
    st.header("üó∫Ô∏è CPA Exam Strategy Roadmap (2026-2027)")
    
    # 1. Countdown Section
    today = date.today()
    tanto_date = date(2027, 5, 23) # Estimated
    ronbun_date = date(2027, 8, 20) # Estimated
    
    days_tanto = (tanto_date - today).days
    days_ronbun = (ronbun_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Days to May Short Exam", f"{days_tanto} Days", "Target: Pass")
    col2.metric("Days to Aug Essay Exam", f"{days_ronbun} Days", "Final Goal")
    col3.metric("Current Phase", "Foundation (2026)", "Build Habits")
    
    st.divider()

    # 2. Tabs
    tab1, tab2, tab3 = st.tabs(["üìä Visual Schedule (Gantt)", "üóìÔ∏è Monthly Strategy", "‚è∞ Daily Routine"])
    
    with tab1:
        st.subheader("Strategic Timeline")
        # Gantt Chart Data
        df_gantt = pd.DataFrame([
            dict(Task="Foundation (Fin/Mgmt)", Start='2026-02-01', Finish='2026-06-30', Phase='Phase 0: Foundation'),
            dict(Task="Audit & Company Law", Start='2026-04-01', Finish='2026-09-30', Phase='Phase 0: Foundation'),
            dict(Task="Tax Law & Electives", Start='2026-07-01', Finish='2026-12-31', Phase='Phase 0: Foundation'),
            dict(Task="Dec Short (Practice)", Start='2026-10-01', Finish='2026-12-13', Phase='Phase 0: Foundation'),
            dict(Task="Short Exam Mastery", Start='2027-01-01', Finish='2027-05-23', Phase='Phase 1: Short Exam'),
            dict(Task="Essay Sprint", Start='2027-05-24', Finish='2027-08-20', Phase='Phase 2: Essay Sprint'),
        ])
        
        # Create Gantt
        fig = px.timeline(df_gantt, x_start="Start", x_end="Finish", y="Task", color="Phase", 
                          title="CPA Exam 1.5 Year Plan",
                          color_discrete_sequence=px.colors.qualitative.Prism)
        fig.update_yaxes(autorange="reversed") # Task order top-to-bottom
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("üí° **Golden Route**: Pass May Short -> Pass August Essay in one go.")

    with tab2:
        st.subheader("Detailed Monthly Strategy")
        
        with st.expander("Phase 0: Foundation (2026)", expanded=True):
            st.markdown("""
            *   **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics (Calculations).
            *   **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
            *   **Jul - Sep**: **CRITICAL** Start Tax Law & Electives (Management/Statistics).
            *   **Oct - Dec**: **Dec Short Exam Challenge**. Aim for 60%+ even if you fail.
            """)
            
        with st.expander("Phase 1: Short Exam Mastery (Jan - May 2027)"):
            st.markdown("""
            *   **Jan - Mar**: Solidify basics. Aim for 75%+ in drills. Focus on weak areas.
            *   **Apr**: Mock Exams (TAC/Ohara). Analyze errors thoroughly.
            *   **May**: Peak conditioning. Rote memorization of text (Audit/Company Law). **PASS EXAM**.
            """)
            
        with st.expander("Phase 2: Essay Sprint (Jun - Aug 2027)"):
            st.markdown("""
            *   **Jun**: Revive Tax/Elective knowledge (often forgotten during Short prep).
            *   **Jul**: Output training (Writing). Learn "Key Phrases" for theory questions.
            *   **Aug**: Final adjustments. Health management is key. **PASS EXAM**.
            """)

    with tab3:
        st.subheader("‚è∞ Ideal Daily Routine (Student/Full-time Study)")
        
        schedule_data = [
            {"Time": "07:00 - 08:00", "Activity": "Wake up / Light Breakfast / Review Vocab"},
            {"Time": "08:00 - 11:00", "Activity": "üß† **Deep Work 1**: Financial Accounting (Calc) - 3h"},
            {"Time": "11:00 - 12:00", "Activity": "Lunch / Nap (20m)"},
            {"Time": "12:00 - 15:00", "Activity": "üß† **Deep Work 2**: Management Accounting / Theory - 3h"},
            {"Time": "15:00 - 16:00", "Activity": "Gym / Walk / Break"},
            {"Time": "16:00 - 19:00", "Activity": "üß† **Deep Work 3**: Corporate Law / Audit - 3h"},
            {"Time": "19:00 - 20:00", "Activity": "Dinner / Relax"},
            {"Time": "20:00 - 22:00", "Activity": "üìñ **Review**: Weak areas / Next day planning - 2h"},
            {"Time": "22:00 - 23:00", "Activity": "Wind down / Sleep"},
        ]
        st.table(pd.DataFrame(schedule_data))
        st.success("Target: **10+ Hours/Day** of high-quality study.")

elif page == "Big 4 Job Hunting üíº":
    st.header("üè¢ Big 4 CPA Job Hunting Strategy")
    st.markdown("Strategy guide and comparison for the major audit firms in Japan.")

    tab1, tab2, tab_depts, tab3, tab4, tab5 = st.tabs(["Strategy & Timeline", "Big 4 Comparison", "Departments (FAS/Tax/...) üè¢", "Tech & Data Science Advantage ü§ñ", "Boston Career Forum üá∫üá∏", "Interview & Case Prep üìù"])

    with tab1:
        st.subheader("üìÖ Job Hunting Timeline (Typical)")
        st.info("The job hunting season for CPA candidates peaks immediately after the August Essay Exam.")
        
        timeline_data = [
            {"Period": "August (Late)", "Activity": "Essay Exam Ends", "Details": "Rest for a few days, then prepare for briefings."},
            {"Period": "September", "Activity": "Firm Briefings (Setsumeikai)", "Details": "Attend online/offline sessions. Key for networking."},
            {"Period": "October", "Activity": "Entry Sheet (ES) Submission", "Details": "Prepare resumes. Focus on 'Why this firm?'"},
            {"Period": "November (Mid)", "Activity": "Results Announcement", "Details": "Official passing results released."},
            {"Period": "November (Late)", "Activity": "Interviews & Offers", "Details": "Intensive interview period (1-2 weeks). Offers issued quickly."}
        ]
        st.table(pd.DataFrame(timeline_data))

        st.subheader("üí° Key Strategies")
        st.markdown("""
        *   **Start Early**: Don't wait for the results. Attend briefings in September.
        *   **Differentiate**: All Big 4 do audit. Focus on culture, specific clients (e.g., Tech, Auto), or non-audit opportunities (IPO, Advisory).
        *   **Networking**: Use alumni connections (OB/OG Visits) if possible.
        """)

    with tab2:
        st.subheader("üìä Big 4 Audit Firms vs. Tech Giants Comparison")
        
        # Personalized Ranking Section
        st.markdown("### üèÜ Personalized Ranking for You (ML/DS Master's Student)")
        st.info("""
        Based on your **CPA Goal** + **ML/Data Science Strength**, here is your recommended priority:
        
        1.  ü•á **PwC Aarata / EY ShinNihon**: Best balance of **Digital Audit** innovation and **CPA License** support. Both have dedicated "Digital" tracks for auditors.
        2.  ü•à **Deloitte Tohmatsu**: Massive scale and data access. Great for "Audit Analytics" but slightly more traditional hierarchy.
        3.  ü•â **Accenture / IBM**: **Top Tier for Tech**, but ‚ö†Ô∏è **WARNING**: You likely **cannot** complete the CPA practical experience (Jitsumu Hoshu) requirement here. Great for *after* getting your CPA, or if you pivot to Consulting.
        """)

        # Radar Chart
        st.subheader("Visual Comparison (Illustrative)")
        categories = ['Tech/AI Focus', 'Global Network', 'Domestic Scale', 'IPO/Venture', 'Work-Life Balance']

        fig = go.Figure()

        # Tohmatsu (Deloitte)
        fig.add_trace(go.Scatterpolar(
            r=[4, 5, 5, 5, 3],
            theta=categories,
            fill='toself',
            name='Tohmatsu (Deloitte)'
        ))
        # AZSA (KPMG)
        fig.add_trace(go.Scatterpolar(
            r=[3, 4, 5, 3, 4],
            theta=categories,
            fill='toself',
            name='AZSA (KPMG)'
        ))
        # EY ShinNihon
        fig.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 3, 3],
            theta=categories,
            fill='toself',
            name='EY ShinNihon'
        ))
        # PwC Aarata
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 3, 2, 4],
            theta=categories,
            fill='toself',
            name='PwC Aarata'
        ))
        # Accenture (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 2, 2],
            theta=categories,
            fill='toself',
            name='Accenture (Ref)'
        ))
        # IBM (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 4, 1, 4],
            theta=categories,
            fill='toself',
            name='IBM (Ref)'
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5]
                )),
            showlegend=True,
            height=500,
            margin=dict(l=40, r=40, t=20, b=20)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("üè¢ Firm Details")
        firms_data = [
            {
                "Firm Name (JP)": "ÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫„Éà„Éº„Éû„ÉÑ (Tohmatsu)",
                "Network": "Deloitte",
                "Key Strengths": "Largest scale, aggressive growth, strong in IPOs and Venture support.",
                "Culture": "Meritocratic, Sports-oriented, High energy.",
                "Link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"
            },
            {
                "Firm Name (JP)": "ÊúâÈôêË≤¨‰ªª „ÅÇ„Åö„ÅïÁõ£ÊüªÊ≥ï‰∫∫ (AZSA)",
                "Network": "KPMG",
                "Key Strengths": "Balanced portfolio, strong domestic manufacturing clients.",
                "Culture": "Conservative, Collaborative, 'Gentlemanly'.",
                "Link": "https://home.kpmg/jp/ja/home/careers.html"
            },
            {
                "Firm Name (JP)": "EYÊñ∞Êó•Êú¨ÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫ (EY ShinNihon)",
                "Network": "EY",
                "Key Strengths": "Long history, large number of listed clients, strong Digital Audit focus.",
                "Culture": "Traditional yet transforming, Diversity focus.",
                "Link": "https://www.ey.com/ja_jp/careers/audit"
            },
            {
                "Firm Name (JP)": "PwC„ÅÇ„Çâ„ÅüÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫ (PwC Aarata)",
                "Network": "PwC",
                "Key Strengths": "Global integration, strong advisory connection, newer organizational style.",
                "Culture": "Global, Flat hierarchy, Innovative.",
                "Link": "https://www.pwc.com/jp/ja/careers/audit.html"
            },
            {
                "Firm Name (JP)": "„Ç¢„ÇØ„Çª„É≥„ÉÅ„É•„Ç¢ (Accenture)",
                "Network": "Accenture",
                "Key Strengths": "Absolute leader in DX/IT Consulting. High salary.",
                "Culture": "Up or Out (Evolving), High performance, Tech-first.",
                "Link": "https://www.accenture.com/jp-ja/careers"
            },
            {
                "Firm Name (JP)": "Êó•Êú¨IBM (IBM Japan)",
                "Network": "IBM",
                "Key Strengths": "Deep research (Watson), Hybrid Cloud, Legacy stability.",
                "Culture": "Engineering-driven, Mature, Good work-life balance.",
                "Link": "https://www.ibm.com/jp-ja/employment"
            }
        ]
        
        # Display as a styled table or cards
        for firm in firms_data:
            with st.expander(f"{firm['Firm Name (JP)']} ({firm['Network']})", expanded=True):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**Strengths:** {firm['Key Strengths']}")
                    st.markdown(f"**Culture:** {firm['Culture']}")
                with col2:
                    st.link_button("Recruit Page", firm['Link'])

    with tab_depts:
        st.subheader("üè¢ Service Lines & Business Units")
        st.markdown("Beyond Audit: Understanding the different career paths within Big 4.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üîç Audit & Assurance (Áõ£Êüª„Éª‰øùË®º)")
            st.info("""
            **The Core Business.**
            *   **Role:** Examining financial statements to ensure accuracy and compliance.
            *   **Pros:** Stability, clear career path, high demand for CPAs.
            *   **Cons:** Can be repetitive, busy season is intense.
            *   **For You:** "Digital Audit" roles are growing fast here.
            """)
            
            st.markdown("### üí∞ Financial Advisory (FAS)")
            st.warning("""
            **The "Deal" Makers.**
            *   **Role:** M&A support, Valuations, Due Diligence, Forensic investigations.
            *   **Pros:** High compensation, dynamic work, exposure to high-level strategy.
            *   **Cons:** Very high pressure, long hours, up-or-out culture.
            *   **For You:** **Forensic Technology** (Fraud Detection) is a perfect fit for Data Science skills.
            """)

        with col2:
            st.markdown("### ‚öñÔ∏è Tax (Á®éÂãô)")
            st.info("""
            **The Specialists.**
            *   **Role:** Corporate tax compliance, Transfer Pricing, International Tax.
            *   **Pros:** Deep expertise, high autonomy, stable.
            *   **Cons:** Highly specialized (niche), constant regulatory changes.
            *   **For You:** "Tax Technology" is emerging, but less common for new grads than Audit.
            """)
            
            st.markdown("### üöÄ Consulting („Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞)")
            st.success("""
            **The Problem Solvers.**
            *   **Role:** Strategy, IT Implementation, Operations improvement.
            *   **Note:** Usually a separate entity (e.g., Deloitte Tohmatsu Consulting vs. Deloitte Tohmatsu Audit).
            *   **Pros:** Variety of projects, high pay.
            *   **Cons:** Travel, unstable workload, "Jack of all trades" risk.
            """)

    with tab3:
        st.subheader("ü§ñ Leveraging Data Science & ML in CPA Job Hunting")
        st.markdown("""
        **Profile:** Double Degree Master's Student (Keio üáØüáµ & Leibniz Hannover üá©üá™) | **Major:** Mechanical Engineering
        
        **Your Technical Arsenal:**
        *   **Advanced ML:** Graph Neural Networks (GNNs), PyTorch, Bayesian Inference (MCMC/TMCMC).
        *   **Engineering:** Finite Element Analysis (FEA), Structural Health Monitoring.
        *   **Languages:** Python, MATLAB, TypeScript.
        
        Your background is a **massive differentiator** in the modern audit industry. All Big 4 firms are heavily investing in "Audit Transformation" and "Digital Audit".
        """)

        st.markdown("---")
        st.markdown("### üìö Recommended Reading")
        st.markdown("""
        > **[The State of Generative AI in the Enterprise (Deloitte)](https://www.deloitte.com/global/en/issues/generative-ai/state-of-ai-in-enterprise.html)**  
        > *This report highlights how enterprises are adopting GenAI. Essential reading for interviews to show commercial awareness.*
        """)
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üéØ Target Roles")
            st.success("**1. Digital Audit Specialist**")
            st.markdown("Work at the intersection of Audit and Tech. Use Python/SQL to analyze full population data instead of sampling.")
            
            st.success("**2. AI Governance / Algorithm Assurance**")
            st.markdown("Audit AI models! With your GNN/Bayesian background, you can audit complex *algorithms* themselves, not just the financial numbers.")
            
            st.success("**3. Financial Advisory (FAS) - Forensics**")
            st.markdown("Your experience in 'Defect Localization' translates perfectly to **Fraud Detection** (finding anomalies in massive datasets).")

        with col2:
            st.markdown("### üí° Strategic Actions")
            st.info("**Resume / Entry Sheet (ES)**")
            st.markdown("*   **Highlight Research**: Explicitly mention your GNN work for Aerospace/CFRP. It shows you can handle *complex, unstructured data*.")
            st.markdown("*   **Keywords**: `PyTorch`, `Bayesian Inference`, `Uncertainty Quantification`, `End-to-End Pipelines`.")
            
            st.info("**Interview Questions to Ask**")
            st.markdown("*   *\"How can I apply Bayesian methods to audit risk assessment?\"*\n*   *\"Does your firm analyze unstructured data (like contracts/images) using GNNs or NLP?\"*")
            
            st.info("**Firm-Specific Tech Vibes**")
            st.markdown("""
            *   **EY**: Very strong brand in "Digital Audit". Has "EY Digital" specific recruiting tracks.
            *   **PwC**: Strong on "Tech-enablement". "Digital Upskilling" for all staff is a key slogan.
            *   **Deloitte**: "Audit Analytics" is a core part of their massive scale.
            *   **KPMG**: "Digital Innovation" focus, often collaborative with their consulting arm.
            """)

    with tab4:
        st.subheader("üá∫üá∏ Boston Career Forum (BCF)")
        st.markdown("The world's largest job fair for Japanese-English bilinguals. **Crucial for Master's students.**")
        
        st.info("üí° **Why BCF for You?**\n*   **Speed**: Offers (Naitei) often given in 3 days (Fri-Sun).\n*   **Positions**: Big 4 hires for **Advisory/Consulting** heavily here, not just Audit.\n*   **Timing**: Held in November, aligning perfectly with post-essay exam period.")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üìÖ Timeline")
            st.markdown("""
            *   **Aug-Sep**: Registration & Resume Upload.
            *   **Sep-Oct**: Online Applications & Skype Interviews (Pre-event).
            *   **Nov (Event)**: Walk-ins (Risky) vs. Scheduled Interviews (Safe).
            """)
        with col2:
            st.markdown("### üéØ Strategy")
            st.markdown("""
            *   **Pre-Event is King**: Secure interviews *before* flying to Boston.
            *   **Target**: Big 4 (US & Japan offices), Consulting (MBB/Accenture), Tech.
            *   **Dinner Invitations**: If you do well, you get invited to dinner. This is effectively the final interview.
            """)
        st.link_button("BCF Official Site", "https://careerforum.net/en/event/bos/")

    with tab5:
        st.subheader("üìù Interview & Case Prep: The 'Master' Level")
        
        st.info("üí° **Goal**: Move beyond 'prepared answers'. Show **Intellectual Curiosity** and **Professional Maturity**.")

        # --- Interactive Mock Interview ---
        st.markdown("### ü§ñ Mock Interview Simulator")
        mock_mode = st.radio("Select Mode:", ["Behavioral (HR/Partner)", "Technical (Audit/Accounting)", "Case/Logic (Consulting)"], horizontal=True)
        
        if st.button("üé≤ Generate Question"):
            import random
            
            if "Behavioral" in mock_mode:
                q_bank = [
                    {"q": "Why do you want to be a CPA instead of an Engineer?", "hint": "Connect 'Reliability' in Engineering to 'Assurance' in Audit."},
                    {"q": "Why our firm specifically? (Why not others?)", "hint": "Mention specific culture, clients (Tech/Auto), or digital initiatives."},
                    {"q": "Tell me about a time you failed.", "hint": "Focus on the **Lesson Learned** and **Improvement**, not the failure itself."},
                    {"q": "How do you handle disagreement with a team member?", "hint": "Emphasize **Listening**, **Data-driven discussion**, and **Shared Goals**."},
                    {"q": "What is your career plan for the next 5-10 years?", "hint": "Be ambitious but realistic. 'Digital Audit Specialist' -> 'Project Manager'."},
                    {"q": "Describe your research in simple terms to a 10-year-old.", "hint": "Tests communication skills. Avoid jargon. Use analogies."}
                ]
            elif "Technical" in mock_mode:
                q_bank = [
                    {"q": "What is the difference between 'Audit' and 'Advisory'?", "hint": "Audit = Assurance (Past/Present). Advisory = Consulting (Future/Improvement)."},
                    {"q": "Explain 'Materiality' in Audit.", "hint": "The threshold above which a misstatement would influence decision making."},
                    {"q": "How would you audit a company with massive data volumes?", "hint": "ITAC (IT Application Controls) + Data Analytics (Full population testing)."},
                    {"q": "What are the risks of using AI in financial reporting?", "hint": "Black box logic, Bias, Hallucinations, Lack of audit trail."},
                    {"q": "Explain the concept of 'Going Concern'.", "hint": "The assumption that a company will continue operating in the foreseeable future."}
                ]
            else: # Case
                q_bank = [
                    {"q": "Estimate the number of smartphones sold in Japan annually.", "hint": "Pop (125M) x Penetration (80%) / Replacement Cycle (3 years)."},
                    {"q": "A client's profit is down 20%. How do you analyze it?", "hint": "Revenue vs Cost. Price x Vol. Fixed vs Variable. External vs Internal."},
                    {"q": "Should a Japanese auto-maker enter the EV market in India?", "hint": "Market Size, Competition, Regulation, Infrastructure, Capabilities."},
                    {"q": "How would you use AI to improve audit efficiency?", "hint": "Automated document review, Anomaly detection in journals, Chatbot for inquiries."}
                ]
            
            selected = random.choice(q_bank)
            st.session_state['mock_q'] = selected
            st.session_state['show_hint'] = False
        
        if 'mock_q' in st.session_state:
            st.markdown(f"#### ‚ùì Q: {st.session_state['mock_q']['q']}")
            
            if st.button("Show Hint / Direction"):
                st.session_state['show_hint'] = not st.session_state.get('show_hint', False)
                
            if st.session_state.get('show_hint', False):
                st.success(f"üí° **Direction**: {st.session_state['mock_q']['hint']}")
        
        st.divider()

        # --- Detailed Guide ---
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üó£Ô∏è Core Competency Questions (STAR Method)")
            with st.expander("1. Self-Introduction & Why CPA?", expanded=True):
                st.markdown("""
                **The 'Engineer to Auditor' Narrative**:
                *   "I research **Defect Localization** in aerospace structures using **AI**. My job is to find 'hidden cracks' before they cause failure."
                *   "I realized **Audit** is the same concept but for **Business Structures**. I want to use my tech skills to find 'financial cracks' and ensure stability."
                *   **Why**: "Engineering is precise. Accounting is the language of business. I want to combine **Precision + Business Logic**."
                """)
            
            with st.expander("2. Handling Conflict / Teamwork"):
                st.markdown("""
                *   **Situation**: "In a joint research project with 3 others..."
                *   **Task**: "We disagreed on the simulation method (Speed vs Accuracy)."
                *   **Action**: "I didn't argue opinion. I proposed a **small-scale benchmark test** to compare data."
                *   **Result**: "Data showed my method was 2x faster with 99% accuracy. Team agreed based on evidence."
                *   **Key**: You are **Data-Driven** and **Collaborative**.
                """)

        with col2:
            st.markdown("### üôã‚Äç‚ôÇÔ∏è Reverse Questions (Gyakushitsumon)")
            st.info("Asking good questions is more important than giving good answers.")
            
            with st.expander("Level 1: The 'Safe' Questions"):
                st.markdown("""
                *   "What does a typical day look like for a first-year associate?"
                *   "How is the team structure for a typical audit engagement?"
                *   "What kind of training support is available for CPA exam (Jitsumu Hoshu)?"
                """)
                
            with st.expander("Level 2: The 'Interest' Questions"):
                st.markdown("""
                *   "I am interested in the Digital Audit sector. How early can I get involved in data analytics projects?"
                *   "What differentiates a 'High Performer' from an average one in your firm?"
                *   "Can you tell me about the most challenging project you've worked on recently?"
                """)
                
            with st.expander("Level 3: The 'Killer' Questions (Partner Level)"):
                st.markdown("""
                *   "With the rise of AI, how do you see the **business model of Audit** changing in 5 years? Will it shift from 'Time-Charge' to 'Value-Based'?"
                *   "How is the firm preparing for the auditing of **Non-Financial Information** (ESG/Sustainability)? I believe my engineering background could be useful there."
                *   "I want to be a bridge between the Tech team and the Audit team. Is there a career path for a 'Hybrid' professional?"
                """)


elif page == "Company Directory üè¢":
    st.header("üè¢ Company Directory for CPA Candidates")
    st.markdown("A curated list of potential employers in Japan for CPA holders, ranging from Audit to Tech.")

    tab1, tab2, tab3 = st.tabs(["Audit (Big 4 & Mid)", "Consulting & FAS", "Tech & Enterprise"])

    with tab1:
        st.subheader("Big 4 Audit Firms (The Standard Path)")
        big4 = [
            {"name": "Deloitte Touche Tohmatsu", "desc": "Largest scale, aggressive growth. Strong in IPO support.", "link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"},
            {"name": "KPMG AZSA", "desc": "Balanced portfolio, strong manufacturing clients. 'Gentleman' culture.", "link": "https://home.kpmg/jp/ja/home/careers.html"},
            {"name": "EY ShinNihon", "desc": "Longest history, most listed clients. Strong Digital Audit focus.", "link": "https://www.ey.com/ja_jp/careers/audit"},
            {"name": "PwC Aarata / Kyoto", "desc": "Global integration, innovative. PwC Kyoto is famous for high profitability.", "link": "https://www.pwc.com/jp/ja/careers/audit.html"}
        ]
        for c in big4:
            with st.expander(f"ü¶Å {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

        st.divider()
        st.subheader("Mid-Tier Audit Firms (ÂáÜÂ§ßÊâã)")
        st.info("üí° **Why Mid-Tier?** Faster promotion, broader experience (you do everything), better work-life balance.")
        mid_tier = [
            {"name": "Grant Thornton Taiyo (Â§™ÈôΩ)", "desc": "Largest mid-tier. Very growing. Good alternative to Big 4.", "link": "https://www.grantthornton.jp/recruit/"},
            {"name": "Crowe Toyo (Êù±ÈôΩ)", "desc": "Strong in domestic IPOs. Traditional but stable.", "link": "https://www.toyo-audit.or.jp/recruit/"},
            {"name": "BDO Sanyu (‰∏âÂÑ™)", "desc": "Friendly culture. Good international network via BDO.", "link": "https://www.bdo.or.jp/sanyu/recruit/"},
            {"name": "RSM Seiwa (Ê∏ÖÂíå)", "desc": "Mid-sized, focus on healthcare and mid-cap clients.", "link": "https://www.seiwa-audit.or.jp/recruit/"}
        ]
        for c in mid_tier:
            with st.expander(f"üêØ {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab2:
        st.subheader("FAS (Financial Advisory Services)")
        st.info("üí° **High Expertise**: M&A, Valuation, Forensics. Often requires CPA + English/Tech.")
        fas = [
            {"name": "Deloitte Tohmatsu Financial Advisory (DTFA)", "link": "https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/dtfa/dtfa-recruit.html"},
            {"name": "KPMG FAS", "link": "https://home.kpmg/jp/ja/home/careers/fas.html"},
            {"name": "PwC Advisory", "link": "https://www.pwc.com/jp/ja/careers/advisory.html"},
            {"name": "EY Strategy and Transactions", "link": "https://www.ey.com/ja_jp/careers/strategy-and-transactions"}
        ]
        for c in fas:
            st.link_button(f"üíº {c['name']}", c['link'])

        st.divider()
        st.subheader("Consulting Firms")
        st.markdown("Finance transformation, ERP implementation, Strategy.")
        consulting = [
            {"name": "Accenture (Strategy & Consulting)", "desc": "Top tier for DX/IT. High salary, hard work.", "link": "https://www.accenture.com/jp-ja/careers"},
            {"name": "BayCurrent Consulting", "desc": "Rapidly growing Japanese firm. High salary.", "link": "https://www.baycurrent.co.jp/recruit/"},
            {"name": "Nomura Research Institute (NRI)", "desc": "Stable, high salary, strong domestic presence.", "link": "https://www.nri.com/jp/career"},
            {"name": "ABeam Consulting", "desc": "Strong in SAP/ERP. Good for CPAs liking systems.", "link": "https://www.abeam.com/jp/ja/careers"}
        ]
        for c in consulting:
            with st.expander(f"üß† {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab3:
        st.subheader("Tech & Enterprise (CFO Track)")
        st.info("üí° **Business Side**: FP&A, Accounting Manager, IPO Prep.")
        
        tech = [
            {"name": "Google / Amazon / MS (Japan)", "desc": "FP&A roles. Very high English requirement. Competitive.", "link": "https://careers.google.com/"},
            {"name": "Rakuten Group", "desc": "English official language. Massive FinTech ecosystem.", "link": "https://corp.rakuten.co.jp/careers/"},
            {"name": "Line Yahoo", "desc": "Major domestic tech player. Strong benefits.", "link": "https://www.lycorp.co.jp/ja/recruit/"},
            {"name": "Mercari", "desc": "Modern tech culture. Good for ambitious finance pros.", "link": "https://careers.mercari.com/"}
        ]
        st.markdown("#### Tech / Global")
        for c in tech:
            st.markdown(f"**{c['name']}**: {c['desc']} [Link]({c['link']})")

        st.divider()
        st.markdown("#### Trading Companies (Sogo Shosha)")
        shosha = ["Mitsubishi Corp", "Mitsui & Co", "Itochu", "Sumitomo Corp", "Marubeni"]
        st.write(", ".join(shosha))
        st.caption("Extremely competitive. High salary. Global rotations.")


elif page == "Future üöÄ":
    st.header("üöÄ 100-Year Life & Career Plan: The 'Founder' Trajectory")
    st.markdown("Your roadmap from **Master's Student** to **Tech CEO**. A comprehensive simulation of career, wealth, and life milestones.")

    # Top Status Board
    st.subheader("üìç Current Status")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Current Age", "24", "Phase: Foundation")
    c2.metric("Next Big Milestone", "CPA Exam Pass", "2027 (Age 25)")
    c3.metric("Career Goal", "Audit Tech Founder", "Launch @ Age 35")
    c4.metric("Financial Freedom", "Target: Age 45", "Asset Goal: 500M JPY")
    
    st.divider()

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["‚è≥ 100-Year Timeline", "üß† Skill Evolution", "üí∞ Wealth (Monte Carlo)", "ü¶Ñ Entrepreneurship Blueprint", "üíç Life & Family"])

    with tab1:
        st.subheader("The Century Plan (Age 24 - 100)")
        
        timeline_events = [
            {"Age": 24, "Year": 2026, "Phase": "Foundation", "Event": "Master's (Germany/Japan) + CPA Study Start", "Status": "Current", "Importance": 3},
            {"Age": 25, "Year": 2027, "Phase": "Foundation", "Event": "Pass CPA Exam (May/Aug) üèÜ", "Status": "Goal", "Importance": 5},
            {"Age": 26, "Year": 2028, "Phase": "Foundation", "Event": "Graduation & Join Big 4 (Digital Audit/FAS)", "Status": "Planned", "Importance": 4},
            {"Age": 29, "Year": 2031, "Phase": "Growth", "Event": "Promoted to Senior Associate. Lead ML Projects.", "Status": "Planned", "Importance": 3},
            {"Age": 30, "Year": 2032, "Phase": "Life", "Event": "Marriage üíç (Target)", "Status": "Life", "Importance": 5},
            {"Age": 32, "Year": 2034, "Phase": "Growth", "Event": "Manager Promotion. Deep expertise in AI Governance.", "Status": "Planned", "Importance": 3},
            {"Age": 35, "Year": 2037, "Phase": "Launch", "Event": "üöÄ FOUND YOUR COMPANY (AI Audit Firm). Disruption.", "Status": "Dream", "Importance": 5},
            {"Age": 40, "Year": 2042, "Phase": "Scale", "Event": "Global Expansion. AI-First Assurance.", "Status": "Dream", "Importance": 4},
            {"Age": 45, "Year": 2047, "Phase": "Exit", "Event": "IPO or Strategic Partnership. Financial Freedom.", "Status": "Dream", "Importance": 5},
            {"Age": 50, "Year": 2052, "Phase": "Invest", "Event": "Angel Investor for Deep Tech. University Lecturer.", "Status": "Vision", "Importance": 3},
            {"Age": 60, "Year": 2062, "Phase": "Legacy", "Event": "Establish Scholarship Foundation.", "Status": "Vision", "Importance": 3},
            {"Age": 80, "Year": 2082, "Phase": "Wisdom", "Event": "Write Memoirs. Mentor next gen.", "Status": "Vision", "Importance": 2},
            {"Age": 100, "Year": 2102, "Phase": "Complete", "Event": "Die Empty. No regrets.", "Status": "Final", "Importance": 5}
        ]
        
        df_timeline = pd.DataFrame(timeline_events)
        
        # Visual Timeline - Improved
        fig_timeline = px.scatter(
            df_timeline, 
            x="Year", 
            y="Age", 
            color="Phase", 
            size="Importance",
            hover_name="Event",
            text="Event", 
            title="Life Trajectory Map", 
            size_max=40,
            template="plotly_white"
        )
        fig_timeline.update_traces(textposition='top center', marker=dict(line=dict(width=2, color='DarkSlateGrey')))
        fig_timeline.update_layout(
            height=600,
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True, title="Age"),
            showlegend=True
        )
        # Add connecting line
        fig_timeline.add_trace(go.Scatter(
            x=df_timeline["Year"], 
            y=df_timeline["Age"], 
            mode='lines', 
            line=dict(color='lightgrey', width=1, dash='dot'),
            showlegend=False,
            hoverinfo='skip'
        ))
        
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        with st.expander("Show Data Table"):
            st.dataframe(df_timeline, use_container_width=True)

    with tab2:
        st.subheader("üß† Skill Evolution: The 'T-Shaped' Professional")
        st.markdown("Visualizing your growth from a CPA specialist to a Tech CEO.")
        
        categories = ['Accounting/Audit', 'Coding/AI', 'English/Global', 'Leadership', 'Risk Taking']
        
        fig_radar = go.Figure()
        
        fig_radar.add_trace(go.Scatterpolar(
            r=[4, 2, 3, 2, 2],
            theta=categories,
            fill='toself',
            name='Current (Age 24)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 4, 3],
            theta=categories,
            fill='toself',
            name='Manager (Age 32)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 5, 5],
            theta=categories,
            fill='toself',
            name='Founder/CEO (Age 40)'
        ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                visible=True,
                range=[0, 5]
                )),
            showlegend=True,
            title="Skill Radar Chart"
        )
        
        col_r1, col_r2 = st.columns([2, 1])
        with col_r1:
            st.plotly_chart(fig_radar, use_container_width=True)
        with col_r2:
            st.info("üí° **Key Insight**")
            st.markdown("""
            *   **Accounting**: Must be perfect early on (CPA).
            *   **Coding/AI**: Your differentiator. Grow this during your Associate years.
            *   **Risk Taking**: The biggest shift required to become a Founder.
            """)

    with tab3:
        st.subheader("üí∞ Financial Simulation: Monte Carlo Analysis")
        st.markdown("A Quant-style simulation of your future wealth. **Life is probabilistic, not deterministic.**")
        
        # --- Interactive Sliders ---
        col_ctrl1, col_ctrl2 = st.columns(2)
        with col_ctrl1:
            st.markdown("**Income & Savings**")
            initial_salary = st.slider("Starting Salary (Million JPY)", 4.0, 10.0, 6.0, 0.5)
            savings_rate = st.slider("Savings Rate (%)", 10, 70, 30, 5) / 100.0
            investment_return_mean = st.slider("Expected Return (%)", 1.0, 15.0, 5.0, 0.5) / 100.0
            investment_volatility = st.slider("Volatility (Risk) (%)", 5.0, 30.0, 15.0, 1.0) / 100.0
            
        with col_ctrl2:
            st.markdown("**Startup Variables**")
            launch_age = st.slider("Launch Age", 28, 45, 35)
            exit_age = st.slider("Exit Age", launch_age + 3, 60, 45)
            exit_valuation = st.slider("Exit Valuation (Million JPY)", 100, 10000, 500, 100)
            exit_prob = st.slider("Exit Success Probability (%)", 10, 90, 30, 5) / 100.0
            
        st.divider()

        if st.button("Run Monte Carlo Simulation (100 Scenarios)"):
            with st.spinner("Running 100 simulations..."):
                # Simulation Data
                years = list(range(2026, 2060))
                ages = list(range(24, 58))
                n_sims = 100
                
                # Store all paths
                all_paths = []
                
                for i in range(n_sims):
                    path = []
                    current_asset = 1.0
                    
                    # Startup outcome for this simulation
                    is_successful_exit = np.random.random() < exit_prob
                    
                    for age in ages:
                        # Salary Logic
                        if age < launch_age:
                            # Corporate Phase
                            if age < 26: sal = 0
                            elif age < 30: sal = initial_salary
                            elif age < 35: sal = initial_salary * 1.5
                            elif age < 40: sal = initial_salary * 2.0
                            else: sal = initial_salary * 2.5
                            
                            current_asset += (sal * savings_rate)
                            
                        elif age == launch_age:
                            # Launch Cost
                            current_asset -= 5.0
                            if current_asset < 0: current_asset = 0
                            
                        elif age < exit_age:
                            # Founder Phase (Lean)
                            sal = 4.0
                            current_asset += (sal * 0.1)
                            
                        elif age == exit_age:
                            # Exit Event
                            if is_successful_exit:
                                current_asset += exit_valuation
                            else:
                                current_asset += 0 # Failed exit
                                
                        else:
                            # Post-Exit / Investor
                            pass

                        # Investment Return (Stochastic)
                        # Geometric Brownian Motion component: exp((mu - 0.5*sigma^2) + sigma*Z)
                        # Simplified: return ~ N(mean, vol)
                        r = np.random.normal(investment_return_mean, investment_volatility)
                        current_asset *= (1 + r)
                        
                        path.append(current_asset)
                    
                    all_paths.append(path)
                
                # Calculate Percentiles
                all_paths_np = np.array(all_paths) # shape (n_sims, n_years)
                p10 = np.percentile(all_paths_np, 10, axis=0)
                p50 = np.percentile(all_paths_np, 50, axis=0)
                p90 = np.percentile(all_paths_np, 90, axis=0)
                
                # Plot
                df_mc = pd.DataFrame({
                    "Age": ages,
                    "P10 (Pessimistic)": p10,
                    "P50 (Median)": p50,
                    "P90 (Optimistic)": p90
                })
                
                fig_mc = go.Figure()
                fig_mc.add_trace(go.Scatter(x=ages, y=p90, mode='lines', name='90th Percentile (Lucky)', line=dict(width=0), showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p10, mode='lines', name='10th Percentile (Unlucky)', line=dict(width=0), fill='tonexty', fillcolor='rgba(0,100,80,0.2)', showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p50, mode='lines', name='Median Outcome', line=dict(color='rgb(0,100,80)')))
                
                fig_mc.update_layout(title="Monte Carlo Wealth Projection (90% Confidence Interval)", yaxis_title="Net Assets (Million JPY)", hovermode="x")
                st.plotly_chart(fig_mc, use_container_width=True)
                
                st.success(f"Simulation Complete. Median Asset at Age {ages[-1]}: **{p50[-1]:.1f}M JPY**")
                if p90[-1] > 1000:
                    st.balloons()
        else:
            st.info("Click the button above to run the Monte Carlo simulation.")

    with tab4:
        st.subheader("ü¶Ñ Entrepreneurship Blueprint: 'Next-Gen AI Audit Firm'")
        
        # Business Stats
        m1, m2, m3 = st.columns(3)
        m1.metric("TAM (Total Addressable Market)", "¬•500 Billion", "Audit Market in Japan")
        m2.metric("Target Market", "¬•50 Billion", "Mid-Cap Listed Companies")
        m3.metric("Your Edge", "Tech + License", "Unbeatable Combo")
        
        st.markdown("---")
        
        st.info("üí° **Why AI Audit Firm > SaaS?**")
        st.markdown("""
        *   **SaaS Weakness**: High churn, low barrier to entry, "race to the bottom" pricing. Anyone can build a tool.
        *   **Audit Strength**: **Regulatory Moat**. Only licensed firms can sign off on financial statements. High switching costs.
        *   **The Opportunity**: Build a **Tech-Enabled Audit Firm** (Service + Tech) that operates at 10x efficiency of Big 4, undercutting their fees while maintaining higher margins.
        """)

        st.markdown("""
        **Vision**: Replace the "Army of Associates" with **Autonomous AI Agents**. Focus on high-level judgement and client relationships.
        
        **Phase 1: The "Insider" (Age 26-34)**
        *   **Goal**: Become a domain expert (CPA License is the Key). Understand *exactly* where the inefficiencies are in Big 4.
        *   **Action**: Lead "Digital Transformation" projects. Learn the *regulatory constraints* inside out.
        
        **Phase 2: The "Prototype" (Age 34-35)**
        *   **Goal**: Build the "AI Auditor" (Internal Tool).
        *   **Tech**: RAG (Retrieval Augmented Generation) for accounting standards, GNNs for transaction anomaly detection.
        *   **Team**: You (CTO/CEO) + Experienced Audit Partner (for credibility/signing).
        
        **Phase 3: The "Disruption" (Age 35+)**
        *   **Target**: Mid-cap public companies (tired of high Big 4 fees).
        *   **Product**: **"AI-First Statutory Audit"**. 
        *   **Value Prop**: "Faster audit, lower fees, deeper insights." Not just a software tool, but the *full service*.
        """)

    with tab5:
        st.subheader("üíç Life, Family & Happiness")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üë®‚Äçüë©‚Äçüëß Family Goals")
            st.write("*   **Age 30**: Marriage (Partner who understands the startup grind).")
            st.write("*   **Age 32**: First Child.")
            st.write("*   **Age 35**: Second Child (Coincides with Startup Launch - Tough!).")
            st.write("*   **Policy**: Weekends are for family. No work on Sundays.")
            
        with col2:
            st.markdown("### ‚úàÔ∏è Experiences")
            st.write("*   **20s**: Backpacking Europe/Asia (Cheap travel).")
            st.write("*   **30s**: Family trips to Hawaii/Okinawa.")
            st.write("*   **40s**: World Cruise (Post-Exit).")
            st.write("*   **Hobbies**: Hiking, Coding, Wine Tasting.")


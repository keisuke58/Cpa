import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date
import json
import os

# Set page config
st.set_page_config(page_title="CPA Perfect Platform 2027", layout="wide", page_icon="üìö")

# Data Persistence
DATA_FILE = "cpa_data.json"

def load_data():
    defaults = {"scores": [], "logs": [], "xp": 0, "level": 1, "badges": []}
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                # Merge defaults for backward compatibility
                for k, v in defaults.items():
                    if k not in data:
                        data[k] = v
                return data
            except:
                return defaults
    return defaults

def save_data(data):
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Initialize Session State
if 'data' not in st.session_state:
    st.session_state.data = load_data()

if 'quiz_state' not in st.session_state:
    st.session_state.quiz_state = {
        'active': False,
        'subject': None,
        'level': None,
        'q_index': 0,
        'score': 0,
        'show_feedback': False,
        'selected_option': None
    }

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4e8cff;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
    }
    .correct-answer {
        background-color: #d1fae5;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #10b981;
        color: #065f46;
    }
    .incorrect-answer {
        background-color: #fee2e2;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ef4444;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

# Mock Data
mock_exams = [
    {'date': '2026-11-15', 'type': 'Short', 'name': 'Dec Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2026-12-13', 'type': 'Short', 'name': 'Official Dec Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-04-25', 'type': 'Short', 'name': 'May Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-05-23', 'type': 'Short', 'name': 'Official May Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-07-10', 'type': 'Essay', 'name': 'Essay Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-08-20', 'type': 'Essay', 'name': 'Official Aug Essay Exam', 'provider': 'CPAAOB', 'status': 'Target'}
]

# Vocabulary Data
vocab_data = {
    'Financial': [
        {'term': 'Going Concern', 'jp': 'Á∂ôÁ∂ö‰ºÅÊ•≠„ÅÆÂâçÊèê', 'desc': '‰ºÅÊ•≠„ÅåÂ∞ÜÊù•„Å´„Çè„Åü„Å£„Å¶‰∫ãÊ•≠„ÇíÁ∂ôÁ∂ö„Åô„Çã„Å®„ÅÑ„ÅÜÂâçÊèê„ÄÇ'},
        {'term': 'Accrual Basis', 'jp': 'Áô∫Áîü‰∏ªÁæ©', 'desc': 'ÁèæÈáë„ÅÆÂèéÊîØ„Å´„Åã„Åã„Çè„Çâ„Åö„ÄÅÁµåÊ∏àÁöÑ‰∫ãË±°„ÅÆÁô∫ÁîüÊôÇÁÇπ„ÅßÂèéÁõä„ÉªË≤ªÁî®„ÇíË™çË≠ò„Åô„ÇãÂéüÂâá„ÄÇ'},
        {'term': 'Materiality', 'jp': 'ÈáçË¶ÅÊÄß', 'desc': 'Ë≤°ÂãôË´∏Ë°®Âà©Áî®ËÄÖ„ÅÆÊÑèÊÄùÊ±∫ÂÆö„Å´ÂΩ±Èüø„Çí‰∏é„Åà„ÇãÊÉÖÂ†±„ÅÆÊÄßË≥™„ÇÑÈáëÈ°ç„ÅÆÂ§ß„Åç„Åï„ÄÇ'},
        {'term': 'Impairment', 'jp': 'Ê∏õÊêç', 'desc': 'Ë≥áÁî£„ÅÆÂèéÁõäÊÄß„Åå‰Ωé‰∏ã„Åó„ÅüÁµêÊûú„ÄÅÊäïË≥áÈ°ç„ÅÆÂõûÂèé„ÅåË¶ãËæº„ÇÅ„Å™„Åè„Å™„Å£„ÅüÂ†¥Âêà„Å´Â∏≥Á∞ø‰æ°È°ç„ÇíÊ∏õÈ°ç„Åô„Çã„Åì„Å®„ÄÇ'},
        {'term': 'Asset Retirement Obligation', 'jp': 'Ë≥áÁî£Èô§ÂéªÂÇµÂãô', 'desc': 'ÊúâÂΩ¢Âõ∫ÂÆöË≥áÁî£„ÅÆÂèñÂæó„ÇÑ‰ΩøÁî®„Å´„Çà„Å£„Å¶Áîü„Åò„Çã„ÄÅÈô§Âéª„Å´Èñ¢„Åô„ÇãÂ∞ÜÊù•„ÅÆÊ≥ïÁöÑÁæ©Âãô„ÄÇ'},
        {'term': 'Fair Value', 'jp': 'ÂÖ¨Ê≠£‰æ°ÂÄ§', 'desc': 'Â∏ÇÂ†¥ÂèÇÂä†ËÄÖÈñì„ÅßÁß©Â∫è„ÅÇ„ÇãÂèñÂºï„ÅåË°å„Çè„Çå„ÅüÂ†¥Âêà„Å´ÊàêÁ´ã„Åô„Çã‰æ°Ê†º„ÄÇ'},
        {'term': 'Deferred Tax Asset', 'jp': 'Áπ∞Âª∂Á®éÈáëË≥áÁî£', 'desc': 'Â∞ÜÊù•„ÅÆÁ®éÈáë„ÇíÊ∏õ„Çâ„ÅôÂäπÊûú„Åå„ÅÇ„Çã‰∏ÄÊôÇÂ∑ÆÁï∞„ÄÇÂõûÂèéÂèØËÉΩÊÄß„ÅÆÊ§úË®é„ÅåÂøÖË¶Å„ÄÇ'},
        {'term': 'Equity Method', 'jp': 'ÊåÅÂàÜÊ≥ï', 'desc': 'ÊäïË≥á‰ºöÁ§æ„ÅÆÊåÅÂàÜ„Å´Âøú„Åò„Å¶„ÄÅË¢´ÊäïË≥á‰ºöÁ§æ„ÅÆÊêçÁõäÁ≠â„ÇíÂèçÊò†„Åï„Åõ„Çã‰ºöË®àÂá¶ÁêÜ„ÄÇÈñ¢ÈÄ£‰ºöÁ§æÁ≠â„Å´ÈÅ©Áî®„ÄÇ'},
        {'term': 'Goodwill', 'jp': '„ÅÆ„Çå„Çì', 'desc': '‰ºÅÊ•≠Ë≤∑ÂèéÁ≠â„ÅÆÈöõ„Å´ÊîØÊâï„Å£„ÅüÂØæ‰æ°„Åå„ÄÅÂèó„ÅëÂÖ•„Çå„ÅüÁ¥îË≥áÁî£„ÅÆÊôÇ‰æ°„Çí‰∏äÂõû„ÇãË∂ÖÈÅéÂèéÁõäÂäõ„ÄÇ'},
        {'term': 'Comprehensive Income', 'jp': 'ÂåÖÊã¨Âà©Áõä', 'desc': 'Á¥îË≥áÁî£„ÅÆÂ§âÂãïÈ°ç„ÅÆ„ÅÜ„Å°„ÄÅË≥áÊú¨ÂèñÂºï„Å´„Çà„Çâ„Å™„ÅÑÈÉ®ÂàÜ„ÄÇÂΩìÊúüÁ¥îÂà©ÁõäÔºã„Åù„ÅÆ‰ªñ„ÅÆÂåÖÊã¨Âà©Áõä„ÄÇ'},
        {'term': 'Provision', 'jp': 'ÂºïÂΩìÈáë', 'desc': 'Â∞ÜÊù•„ÅÆÁâπÂÆö„ÅÆË≤ªÁî®„ÇÑÊêçÂ§±„Å´ÂÇô„Åà„Å¶„ÄÅÂΩìÊúü„ÅÆË≤ªÁî®„Å®„Åó„Å¶Ë®à‰∏ä„Åï„Çå„ÇãÈáëÈ°ç„ÄÇ'},
        {'term': 'Contingent Liability', 'jp': 'ÂÅ∂Áô∫ÂÇµÂãô', 'desc': 'Â∞ÜÊù•„ÅÆ‰∫ãË±°„ÅÆÁô∫Áîü„Éª‰∏çÁô∫Áîü„Å´„Çà„Å£„Å¶ÂÇµÂãô„ÅåÁ¢∫ÂÆö„Åô„ÇãÊΩúÂú®ÁöÑ„Å™Áæ©Âãô„ÄÇ'}
    ],
    'Management': [
        {'term': 'Opportunity Cost', 'jp': 'Ê©ü‰ºöÂéü‰æ°', 'desc': '„ÅÇ„Çã‰ª£ÊõøÊ°à„ÇíÈÅ∏Êäû„Åó„Åü„Åì„Å®„Å´„Çà„Å£„Å¶Áä†Áâ≤„Å®„Å™„Å£„ÅüÔºàË´¶„ÇÅ„ÅüÔºâÊúÄÂ§ß„ÅÆÂà©Áõä„ÄÇ'},
        {'term': 'Sunk Cost', 'jp': 'ÂüãÊ≤°Âéü‰æ°', 'desc': 'ÈÅéÂéª„ÅÆÊÑèÊÄùÊ±∫ÂÆö„Å´„Çà„Å£„Å¶Êó¢„Å´Áô∫Áîü„Åó„ÄÅÂõûÂèé‰∏çËÉΩ„Å™„Ç≥„Çπ„Éà„ÄÇÊÑèÊÄùÊ±∫ÂÆö„Åß„ÅØÁÑ°Ë¶ñ„Åô„Åπ„Åç„ÄÇ'},
        {'term': 'Break-even Point', 'jp': 'ÊêçÁõäÂàÜÂ≤êÁÇπ', 'desc': 'Â£≤‰∏äÈ´ò„Å®Á∑èË≤ªÁî®„ÅåÁ≠â„Åó„Åè„Å™„Çä„ÄÅÂà©Áõä„Åå„Çº„É≠„Å®„Å™„ÇãÁÇπ„ÄÇ'},
        {'term': 'Safety Margin', 'jp': 'ÂÆâÂÖ®‰ΩôË£ïÁéá', 'desc': 'ÁèæÂú®„ÅÆÂ£≤‰∏äÈ´ò„ÅåÊêçÁõäÂàÜÂ≤êÁÇπ„Çí„Å©„Çå„Å†„Åë‰∏äÂõû„Å£„Å¶„ÅÑ„Çã„Åã„ÇíÁ§∫„ÅôÊåáÊ®ô„ÄÇÈ´ò„ÅÑ„Åª„Å©ÂÆâÂÖ®„ÄÇ'},
        {'term': 'Cost Driver', 'jp': '„Ç≥„Çπ„Éà„Éª„Éâ„É©„Ç§„Éê„Éº', 'desc': 'Ê¥ªÂãïÂéü‰æ°Ë®àÁÆóÔºàABCÔºâ„Å´„Åä„ÅÑ„Å¶„ÄÅ„Ç≥„Çπ„ÉàÁô∫Áîü„ÅÆÂéüÂõ†„Å®„Å™„ÇãÊ¥ªÂãïÈáè„ÇÑË¶ÅÂõ†„ÄÇ'},
        {'term': 'Standard Costing', 'jp': 'Ê®ôÊ∫ñÂéü‰æ°Ë®àÁÆó', 'desc': 'ÁßëÂ≠¶ÁöÑ„ÉªÁµ±Ë®àÁöÑË™øÊüª„Å´Âü∫„Å•„ÅÑ„Å¶Ë®≠ÂÆö„Åï„Çå„ÅüÁõÆÊ®ôÂéü‰æ°„ÇíÁî®„ÅÑ„Å¶Ë°å„ÅÜÂéü‰æ°Ë®àÁÆó„ÄÇ'},
        {'term': 'Variance Analysis', 'jp': 'Â∑ÆÁï∞ÂàÜÊûê', 'desc': 'Ê®ôÊ∫ñÂéü‰æ°„Å®ÂÆüÈöõÂéü‰æ°„ÅÆÂ∑ÆÈ°çÔºàÂ∑ÆÁï∞Ôºâ„ÇíÂàÜÊûê„Åó„ÄÅÂéüÂõ†„ÇíÁâπÂÆö„Åó„Å¶ÁÆ°ÁêÜ„Å´ÂΩπÁ´ã„Å¶„ÇãÊâãÊ≥ï„ÄÇ'},
        {'term': 'Direct Costing', 'jp': 'Áõ¥Êé•Âéü‰æ°Ë®àÁÆó', 'desc': 'Âéü‰æ°„ÇíÂ§âÂãïË≤ª„Å®Âõ∫ÂÆöË≤ª„Å´ÂàÜËß£„Åó„ÄÅÂ§âÂãïË≤ª„ÅÆ„Åø„ÇíË£ΩÂìÅÂéü‰æ°„Å®„Åô„ÇãË®àÁÆóÊâãÊ≥ïÔºàCVPÂàÜÊûê„Å´ÊúâÁî®Ôºâ„ÄÇ'},
        {'term': 'ROI (Return on Investment)', 'jp': 'Êäï‰∏ãË≥áÊú¨Âà©ÁõäÁéá', 'desc': 'ÊäïË≥á„Åó„ÅüË≥áÊú¨„Å´ÂØæ„Åó„Å¶„Å©„Çå„Å†„Åë„ÅÆÂà©Áõä„Çí‰∏ä„Åí„Åü„Åã„ÇíÁ§∫„ÅôÂèéÁõäÊÄßÊåáÊ®ô„ÄÇ'},
        {'term': 'Balanced Scorecard', 'jp': '„Éê„É©„É≥„Çπ„Éà„Éª„Çπ„Ç≥„Ç¢„Ç´„Éº„Éâ', 'desc': 'Ë≤°Âãô„ÄÅÈ°ßÂÆ¢„ÄÅÊ•≠Âãô„Éó„É≠„Çª„Çπ„ÄÅÂ≠¶Áøí„Å®ÊàêÈï∑„ÅÆ4„Å§„ÅÆË¶ñÁÇπ„Åã„ÇâÊ•≠Á∏æ„ÇíË©ï‰æ°„Åô„ÇãÊâãÊ≥ï„ÄÇ'},
        {'term': 'Just-In-Time (JIT)', 'jp': '„Ç∏„É£„Çπ„Éà„Éª„Ç§„É≥„Éª„Çø„Ç§„É†', 'desc': 'ÂøÖË¶Å„Å™„ÇÇ„ÅÆ„Çí„ÄÅÂøÖË¶Å„Å™ÊôÇ„Å´„ÄÅÂøÖË¶Å„Å™Èáè„Å†„ÅëÁîüÁî£„Éª‰æõÁµ¶„Åô„ÇãÁîüÁî£ÊñπÂºè„ÄÇ'},
        {'term': 'Kaizen Costing', 'jp': 'ÊîπÂñÑÂéü‰æ°Ë®àÁÆó', 'desc': 'Ë£ΩÈÄ†ÊÆµÈöé„Å´„Åä„ÅÑ„Å¶„ÄÅÁ∂ôÁ∂öÁöÑ„Å™ÊîπÂñÑÊ¥ªÂãï„ÇíÈÄö„Åò„Å¶Âéü‰æ°‰ΩéÊ∏õ„ÇíÂõ≥„ÇãÊâãÊ≥ï„ÄÇ'}
    ],
    'Audit': [
        {'term': 'Professional Skepticism', 'jp': 'ËÅ∑Ê•≠ÁöÑÊáêÁñëÂøÉ', 'desc': 'Â∏∏„Å´ÁñëÂøµ„ÇíÊåÅ„Å°„ÄÅÁõ£ÊüªË®ºÊã†„ÇíÊâπÂà§ÁöÑ„Å´Ë©ï‰æ°„Åô„ÇãÂßøÂã¢„ÄÇ'},
        {'term': 'Audit Risk', 'jp': 'Áõ£Êüª„É™„Çπ„ÇØ', 'desc': 'Ë≤°ÂãôË´∏Ë°®„Å´ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„Åå„ÅÇ„Çã„Å´„ÇÇ„Åã„Åã„Çè„Çâ„Åö„ÄÅÁõ£Êüª‰∫∫„Åå‰∏çÈÅ©Âàá„Å™ÊÑèË¶ã„ÇíË°®Êòé„Åô„Çã„É™„Çπ„ÇØ„ÄÇ'},
        {'term': 'Material Misstatement', 'jp': 'ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫', 'desc': 'Ë≤°ÂãôË´∏Ë°®Âà©Áî®ËÄÖ„ÅÆÂà§Êñ≠„ÇíË™§„Çâ„Åõ„ÇãÂèØËÉΩÊÄß„ÅÆ„ÅÇ„ÇãË™§„Çä„ÇÑ‰∏çÊ≠£„ÄÇ'},
        {'term': 'Internal Control', 'jp': 'ÂÜÖÈÉ®Áµ±Âà∂', 'desc': 'Ê•≠Âãô„ÅÆÊúâÂäπÊÄß„ÉªÂäπÁéáÊÄß„ÄÅË≤°ÂãôÂ†±Âëä„ÅÆ‰ø°È†ºÊÄß„Å™„Å©„ÇíÁ¢∫‰øù„Åô„Çã„Åü„ÇÅ„Å´ÁµÑÁπîÂÜÖ„Å´ÊßãÁØâ„Åï„Çå„Çã„Éó„É≠„Çª„Çπ„ÄÇ'},
        {'term': 'Substantive Procedures', 'jp': 'ÂÆüË®ºÊâãÁ∂ö', 'desc': 'ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„ÇíÁô∫Ë¶ã„Åô„Çã„Åü„ÇÅ„Å´„ÄÅÂèñÂºï„ÇÑÊÆãÈ´ò„ÅÆË©≥Á¥∞„ÇíÁõ¥Êé•Ê§úË®º„Åô„ÇãÊâãÁ∂ö„ÄÇ'},
        {'term': 'Significant Deficiency', 'jp': 'ÈáçË¶Å„Å™‰∏çÂÇô', 'desc': 'ÂÜÖÈÉ®Áµ±Âà∂„ÅÆ‰∏çÂÇô„ÅÆ„ÅÜ„Å°„ÄÅË≤°ÂãôË´∏Ë°®„ÅÆ‰ø°È†ºÊÄß„Å´ÈáçË¶Å„Å™ÂΩ±Èüø„ÇíÂèä„Åº„ÅôÂèØËÉΩÊÄß„ÅåÈ´ò„ÅÑ„ÇÇ„ÅÆ„ÄÇ'},
        {'term': 'Key Audit Matters (KAM)', 'jp': 'Áõ£Êüª‰∏ä„ÅÆ‰∏ªË¶Å„Å™Ê§úË®é‰∫ãÈ†Ö', 'desc': 'ÂΩìÂπ¥Â∫¶„ÅÆÁõ£Êüª„Å´„Åä„ÅÑ„Å¶„ÄÅËÅ∑Ê•≠ÁöÑÂ∞ÇÈñÄÂÆ∂„Å®„Åó„Å¶Áâπ„Å´ÈáçË¶Å„Åß„ÅÇ„Çã„Å®Âà§Êñ≠„Åó„Åü‰∫ãÈ†Ö„ÄÇ'},
        {'term': 'Audit Evidence', 'jp': 'Áõ£ÊüªË®ºÊã†', 'desc': 'Áõ£ÊüªÊÑèË¶ã„ÅÆÂü∫Á§é„Å®„Å™„ÇãÁµêË´ñ„ÇíÂ∞é„Åè„Åü„ÇÅ„Å´Áõ£Êüª‰∫∫„ÅåÂÖ•Êâã„Åó„ÅüÊÉÖÂ†±„ÄÇ'},
        {'term': 'Sampling Risk', 'jp': 'Ë©¶Êüª„É™„Çπ„ÇØ', 'desc': 'Áõ£Êüª‰∫∫„ÅåÊØçÈõÜÂõ£„ÅÆ‰∏ÄÈÉ®ÔºàË©¶ÊüªÔºâ„Å´Âü∫„Å•„ÅÑ„Å¶ÁµêË´ñ„ÇíÂá∫„ÅôÈöõ„Å´„ÄÅÊØçÈõÜÂõ£ÂÖ®‰Ωì„ÇíÁ≤æÊüª„Åó„ÅüÂ†¥Âêà„Å®Áï∞„Å™„ÇãÁµêË´ñ„Å´„Å™„Çã„É™„Çπ„ÇØ„ÄÇ'},
        {'term': 'Management Representation Letter', 'jp': 'ÁµåÂñ∂ËÄÖÁ¢∫Ë™çÊõ∏', 'desc': 'ÁµåÂñ∂ËÄÖ„ÅåÁõ£Êüª‰∫∫„Å´ÂØæ„Åó„Å¶„ÄÅË≤°ÂãôË´∏Ë°®‰ΩúÊàêË≤¨‰ªª„ÅÆÂ±•Ë°å„ÇÑÊÉÖÂ†±„ÅÆÂÆåÂÖ®ÊÄß„Å™„Å©„ÇíÊñáÊõ∏„ÅßÁ¢∫Ë™ç„Åô„Çã„ÇÇ„ÅÆ„ÄÇ'},
        {'term': 'Subsequent Events', 'jp': 'ÂæåÁô∫‰∫ãË±°', 'desc': 'Ê±∫ÁÆóÊó•Âæå„Å´Áô∫Áîü„Åó„Åü‰∫ãË±°„Åß„ÄÅÊ¨°Êúü‰ª•Èôç„ÅÆË≤°ÊîøÁä∂ÊÖã„ÇÑÁµåÂñ∂ÊàêÁ∏æ„Å´ÂΩ±Èüø„ÇíÂèä„Åº„Åô„ÇÇ„ÅÆ„ÄÇ'}
    ],
    'Company': [
        {'term': 'Fiduciary Duty', 'jp': 'ÂèóË®óËÄÖË≤¨‰ªª', 'desc': 'ÂèñÁ∑†ÂΩπ„Å™„Å©„Åå‰ºöÁ§æ„ÇÑÊ†™‰∏ª„ÅÆ„Åü„ÇÅ„Å´Âø†ÂÆü„Å´ËÅ∑Âãô„ÇíÈÅÇË°å„Åô„ÇãÁæ©ÂãôÔºàÂñÑÁÆ°Ê≥®ÊÑèÁæ©Âãô„ÉªÂø†ÂÆüÁæ©ÂãôÔºâ„ÄÇ'},
        {'term': 'Shareholder Derivative Suit', 'jp': 'Ê†™‰∏ª‰ª£Ë°®Ë®¥Ë®ü', 'desc': '‰ºöÁ§æ„ÅåÂèñÁ∑†ÂΩπ„ÅÆË≤¨‰ªª„ÇíËøΩÂèä„Åó„Å™„ÅÑÂ†¥Âêà„Å´„ÄÅÊ†™‰∏ª„Åå‰ºöÁ§æ„Å´‰ª£„Çè„Å£„Å¶ÊèêËµ∑„Åô„ÇãË®¥Ë®ü„ÄÇ'},
        {'term': 'Business Judgment Rule', 'jp': 'ÁµåÂñ∂Âà§Êñ≠„ÅÆÂéüÂâá', 'desc': 'ÂèñÁ∑†ÂΩπ„ÅÆÁµåÂñ∂Âà§Êñ≠„ÅåÂêàÁêÜÁöÑ„ÅßË™†ÂÆü„Å´Ë°å„Çè„Çå„ÅüÂ†¥Âêà„ÄÅÁµêÊûúÁöÑ„Å´ÊêçÂÆ≥„ÅåÁîü„Åò„Å¶„ÇÇË≤¨‰ªª„ÇíÂïè„Çè„Çå„Å™„ÅÑÂéüÂâá„ÄÇ'},
        {'term': 'Authorized Shares', 'jp': 'Áô∫Ë°åÂèØËÉΩÊ†™ÂºèÁ∑èÊï∞', 'desc': 'ÂÆöÊ¨æ„ÅßÂÆö„ÇÅ„Çâ„Çå„Åü„ÄÅ‰ºöÁ§æ„ÅåÁô∫Ë°å„Åô„Çã„Åì„Å®„Åå„Åß„Åç„ÇãÊ†™Âºè„ÅÆ‰∏äÈôêÊï∞„ÄÇ'},
        {'term': 'Treasury Stock', 'jp': 'Ëá™Â∑±Ê†™Âºè', 'desc': '‰ºöÁ§æ„Åå‰øùÊúâ„Åô„ÇãËá™Á§æ„ÅÆÊ†™Âºè„ÄÇË≠∞Ê±∫Ê®©„ÇÑÈÖçÂΩìË´ãÊ±ÇÊ®©„ÅØ„Å™„ÅÑ„ÄÇ'},
        {'term': 'Articles of Incorporation', 'jp': 'ÂÆöÊ¨æ', 'desc': '‰ºöÁ§æ„ÅÆÁõÆÁöÑ„ÄÅÂïÜÂè∑„ÄÅÊú¨Â∫óÊâÄÂú®Âú∞„Å™„Å©„ÅÆÂü∫Êú¨Ë¶èÂâá„ÇíÂÆö„ÇÅ„ÅüÊ†πÊú¨Ë¶èÂâá„ÄÇ'},
        {'term': 'Board of Directors', 'jp': 'ÂèñÁ∑†ÂΩπ‰ºö', 'desc': 'Ê•≠ÂãôÂü∑Ë°å„ÅÆÊ±∫ÂÆö„ÇÑÂèñÁ∑†ÂΩπ„ÅÆËÅ∑ÂãôÂü∑Ë°å„ÅÆÁõ£Áù£„ÇíË°å„ÅÜÊ©üÈñ¢„ÄÇ'},
        {'term': 'Statutory Auditor', 'jp': 'Áõ£ÊüªÂΩπ', 'desc': 'ÂèñÁ∑†ÂΩπ„ÅÆËÅ∑ÂãôÂü∑Ë°å„ÇÑ‰ºöË®à„ÇíÁõ£Êüª„Åô„ÇãÊ©üÈñ¢„ÄÇ'},
        {'term': 'General Meeting of Shareholders', 'jp': 'Ê†™‰∏ªÁ∑è‰ºö', 'desc': 'Ê†™Âºè‰ºöÁ§æ„ÅÆÊúÄÈ´òÊÑèÊÄùÊ±∫ÂÆöÊ©üÈñ¢„ÄÇÊ†™‰∏ª„ÅßÊßãÊàê„Åï„Çå„Çã„ÄÇ'},
        {'term': 'Corporate Governance', 'jp': '„Ç≥„Éº„Éù„É¨„Éº„Éà„Éª„Ç¨„Éê„Éä„É≥„Çπ', 'desc': '‰ºÅÊ•≠ÁµåÂñ∂„ÇíË¶èÂæã„Åô„Çã„Åü„ÇÅ„ÅÆ‰ªïÁµÑ„Åø„ÄÇ‰ºÅÊ•≠Áµ±Ê≤ª„ÄÇ'},
        {'term': 'Stock Option', 'jp': '„Çπ„Éà„ÉÉ„ÇØ„Éª„Ç™„Éó„Ç∑„Éß„É≥', 'desc': 'Ëá™Á§æÊ†™„Çí„ÅÇ„Çâ„Åã„Åò„ÇÅÊ±∫„ÇÅ„Çâ„Çå„Åü‰æ°Ê†º„ÅßË≥ºÂÖ•„Åß„Åç„ÇãÊ®©Âà©„ÄÇÂΩπÂì°„ÇÑÂæìÊ•≠Âì°„Å∏„ÅÆ„Ç§„É≥„Çª„É≥„ÉÜ„Ç£„Éñ„ÄÇ'},
        {'term': 'Mergers and Acquisitions (M&A)', 'jp': 'M&AÔºàÂêà‰Ωµ„ÉªË≤∑ÂèéÔºâ', 'desc': '‰ºÅÊ•≠„ÅÆÂêà‰Ωµ„ÇÑË≤∑Âèé„ÅÆÁ∑èÁß∞„ÄÇÁµÑÁπîÂÜçÁ∑®Ë°åÁÇ∫„ÇíÂê´„ÇÄ„ÄÇ'}
    ]
}

drill_questions = {
    'Financial': [
        {
            'level': 1,
            'q': "ÁèæÈáëÈ†êÈáë: Ë≤∏ÂÄüÂØæÁÖßË°®„ÅÆ„ÄåÁèæÈáë„Äç„Å´Âê´„Åæ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Á¥ôÂπ£ (Bank notes)", "Á°¨Ë≤® (Coins)", "ÈÉµ‰æøÂàáÊâã (Postage stamps)", "ÂΩìÂ∫ßÈ†êÈáë (Demand deposits)"],
            'correct': 2,
            'explanation': "ÈÉµ‰æøÂàáÊâã„ÅØ„ÄåË≤ØËîµÂìÅ„Äç„Åæ„Åü„ÅØ„ÄåÈÄö‰ø°Ë≤ª„Äç„Å®„Åó„Å¶Âá¶ÁêÜ„Åï„Çå„ÄÅÁèæÈáë„Å´„ÅØÂê´„Åæ„Çå„Åæ„Åõ„Çì„ÄÇÁèæÈáë„Å´„ÅØÈÄöË≤®„ÄÅÂ∞èÂàáÊâã„ÄÅÂΩìÂ∫ßÈ†êÈáë„Å™„Å©„ÅåÂê´„Åæ„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê∏õ‰æ°ÂÑüÂç¥: Ë≥áÁî£„ÅÆÂà©Áî®Èáè„Å´Âü∫„Å•„ÅÑ„Å¶Ê∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÇíË®àÁÆó„Åô„ÇãÊñπÊ≥ï„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂÆöÈ°çÊ≥ï (Straight-line)", "ÂÆöÁéáÊ≥ï (Declining-balance)", "ÁîüÁî£È´òÊØî‰æãÊ≥ï (Production-output)", "Á¥öÊï∞Ê≥ï (Sum-of-the-years'-digits)"],
            'correct': 2,
            'explanation': "ÁîüÁî£È´òÊØî‰æãÊ≥ï„ÅØ„ÄÅÁ∑èË¶ãÁ©çÁîüÁî£Èáè„Å´ÂØæ„Åô„ÇãÂΩìÊúü„ÅÆÂÆüÈöõÁîüÁî£Èáè„ÅÆÂâ≤Âêà„Å´Âü∫„Å•„ÅÑ„Å¶Ë≤ªÁî®„ÇíÈÖçÂàÜ„Åô„ÇãÊñπÊ≥ï„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê£öÂç∏Ë≥áÁî£: Áâ©‰æ°‰∏äÊòáÂ±ÄÈù¢„Å´„Åä„ÅÑ„Å¶„ÄÅÂΩìÊúüÁ¥îÂà©Áõä„ÅåÊúÄ„ÇÇÂ§ß„Åç„Åè„Å™„ÇãË©ï‰æ°ÊñπÊ≥ï„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂÖàÂÖ•ÂÖàÂá∫Ê≥ï (FIFO)", "ÂæåÂÖ•ÂÖàÂá∫Ê≥ï (LIFO)", "ÁßªÂãïÂπ≥ÂùáÊ≥ï (Weighted Average)", "ÂÄãÂà•Ê≥ï (Specific Identification)"],
            'correct': 0,
            'explanation': "ÂÖàÂÖ•ÂÖàÂá∫Ê≥ï(FIFO)„Åß„ÅØ„ÄÅÈÅéÂéª„ÅÆÔºàÂÆâ„ÅÑÔºâÂú®Â∫´„ÅåÂÖà„Å´Â£≤‰∏äÂéü‰æ°„Å®„Å™„Çä„ÄÅÊúüÊú´Âú®Â∫´„Å´Áõ¥Ëøë„ÅÆÔºàÈ´ò„ÅÑÔºâÂçò‰æ°„ÅåÊÆã„Çã„Åü„ÇÅ„ÄÅÂ£≤‰∏äÂéü‰æ°„ÅåÂ∞è„Åï„Åè„Å™„ÇäÂà©Áõä„ÅåÂ§ß„Åç„Åè„Å™„Çä„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ë≥áÁî£Èô§ÂéªÂÇµÂãô: Ë≥áÁî£Èô§ÂéªÂÇµÂãô„ÅØÂΩìÂàù‰Ωï„Çí„ÇÇ„Å£„Å¶Ê∏¨ÂÆö„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Èô§ÂéªË≤ªÁî®„ÅÆÂ∞ÜÊù•‰æ°ÂÄ§", "Èô§ÂéªË≤ªÁî®„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§", "Ë≥áÁî£„ÅÆÂèñÂæóÂéü‰æ°", "Ë≥áÁî£„ÅÆÂÖ¨Ê≠£‰æ°ÂÄ§"],
            'correct': 1,
            'explanation': "Ë≥áÁî£Èô§ÂéªÂÇµÂãô„ÅØ„ÄÅÂ∞ÜÊù•Áô∫Áîü„Åô„Çã„Å®Ë¶ãËæº„Åæ„Çå„ÇãÈô§ÂéªË≤ªÁî®„ÅÆ„ÄåÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§„Äç„ÅßÁÆóÂÆö„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∏ÄËà¨ÂéüÂâá: ‰ºÅÊ•≠‰ºöË®àÂéüÂâá„ÅÆ„ÄåÁúüÂÆüÊÄß„ÅÆÂéüÂâá„Äç„Å´„Åä„Åë„Çã„ÄåÁúüÂÆü„Äç„ÅÆÊÑèÂë≥„Å®„Åó„Å¶Ê≠£„Åó„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Áµ∂ÂØæÁöÑÁúüÂÆü", "Áõ∏ÂØæÁöÑÁúüÂÆü", "ÂΩ¢ÂºèÁöÑÁúüÂÆü", "Ê≥ïÁöÑÁúüÂÆü"],
            'correct': 1,
            'explanation': "‰ºÅÊ•≠‰ºöË®à„ÅØË§áÊï∞„ÅÆ‰ºöË®àÂá¶ÁêÜ„ÅÆÂéüÂâá„ÉªÊâãÁ∂ö„ÅÆÈÅ∏ÊäûÈÅ©Áî®„ÇíË™ç„ÇÅ„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÊ±Ç„ÇÅ„Çâ„Çå„Çã„ÅÆ„ÅØ„ÄåÁõ∏ÂØæÁöÑÁúüÂÆü„Äç„Åß„ÅÇ„Çã„Å®Ëß£„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê∏õÊêç‰ºöË®à: Âõ∫ÂÆöË≥áÁî£„ÅÆ„ÄåÂõûÂèéÂèØËÉΩ‰æ°È°ç„Äç„Å®„ÅØ„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å´ÁÆóÂÆö„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„Å®‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„ÅÑ„Åö„Çå„ÅãÈ´ò„ÅÑÈáëÈ°ç", "Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„Å®‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈáëÈ°ç", "Ê≠£Âë≥Â£≤Âç¥‰æ°È°ç„ÅÆ„Åø", "‰ΩøÁî®‰æ°ÂÄ§„ÅÆ„Åø"],
            'correct': 0,
            'explanation': "ÂõûÂèéÂèØËÉΩ‰æ°È°ç„ÅØ„ÄÅË≥áÁî£„ÅÆ„ÄåÊ≠£Âë≥Â£≤Âç¥‰æ°È°ç„Äç„Å®„Äå‰ΩøÁî®‰æ°ÂÄ§„Äç„ÅÆ„ÅÑ„Åö„Çå„ÅãÈ´ò„ÅÑÊñπ„ÅÆÈáëÈ°ç„Å®„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "„É™„Éº„Çπ‰ºöË®à: „Éï„Ç°„Ç§„Éä„É≥„Çπ„Éª„É™„Éº„ÇπÂèñÂºï„Å´„Åä„ÅÑ„Å¶„ÄÅÂÄüÊâã„ÅåË®à‰∏ä„Åô„ÇãË≥áÁî£„ÅÆÈ°ç„ÅØÂéüÂâá„Å®„Åó„Å¶„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["„É™„Éº„ÇπÊñôÁ∑èÈ°ç", "„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§„Å®Ë≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°çÁ≠â„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈ°ç", "Ë≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°ç", "„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÂâ≤ÂºïÁèæÂú®‰æ°ÂÄ§"],
            'correct': 1,
            'explanation': "ÈÄöÂ∏∏„ÅÆ„Éï„Ç°„Ç§„Éä„É≥„Çπ„Éª„É™„Éº„Çπ„Åß„ÅØ„ÄÅ„É™„Éº„ÇπÊñôÁ∑èÈ°ç„ÅÆÁèæÂú®‰æ°ÂÄ§„Å®„ÄÅË≤∏Êâã„ÅÆË≥ºÂÖ•‰æ°È°çÔºàÁèæÈáëË≥ºÂÖ•‰æ°È°çÔºâ„ÅÆ„ÅÑ„Åö„Çå„Åã‰Ωé„ÅÑÈ°ç„ÅßË≥áÁî£Ë®à‰∏ä„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 2,
            'q': "„Ç≠„É£„ÉÉ„Ç∑„É•„Éª„Éï„É≠„ÉºË®àÁÆóÊõ∏: ÈñìÊé•Ê≥ï„Å´„Åä„ÅÑ„Å¶„ÄÅÁ®éÂºïÂâçÂΩìÊúüÁ¥îÂà©Áõä„Åã„Çâ„Çπ„Çø„Éº„Éà„Åô„ÇãÈöõ„ÄÅÊ∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÅØ„Å©„ÅÜË™øÊï¥„Åó„Åæ„Åô„ÅãÔºü",
            'options': ["Âä†ÁÆó„Åô„Çã", "Ê∏õÁÆó„Åô„Çã", "Ë™øÊï¥„Åó„Å™„ÅÑ", "Âñ∂Ê•≠Â§ñÂèéÁõä„Å®„Åó„Å¶Êâ±„ÅÜ"],
            'correct': 0,
            'explanation': "Ê∏õ‰æ°ÂÑüÂç¥Ë≤ª„ÅØÁèæÈáëÊîØÂá∫„Çí‰º¥„Çè„Å™„ÅÑË≤ªÁî®ÔºàÈùûË≥áÈáëÊêçÁõäÔºâ„Åß„ÅÇ„Çã„Åü„ÇÅ„ÄÅÂà©Áõä„Åã„Çâ„Çπ„Çø„Éº„Éà„Åó„Å¶„Ç≠„É£„ÉÉ„Ç∑„É•„Éï„É≠„Éº„ÇíÊ±Ç„ÇÅ„ÇãÈöõ„ÅØ„ÄåÂä†ÁÆó„Äç„Åó„Å¶Êàª„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 3,
            'q': "Á®éÂäπÊûú‰ºöË®à: Áπ∞Âª∂Á®éÈáëË≥áÁî£„ÅÆÂõûÂèéÂèØËÉΩÊÄß„ÇíÂà§Êñ≠„Åô„ÇãÈöõ„ÄÅ‰ºöÁ§æÂàÜÈ°û„Åå„ÄåÂàÜÈ°û2„Äç„ÅÆ‰ºÅÊ•≠„Å´„Åä„ÅÑ„Å¶„ÄÅ„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™‰∏ÄÊôÇÂ∑ÆÁï∞„ÅØ„ÅÑ„Å§„Åæ„ÅßË®à‰∏äÂèØËÉΩ„Åß„Åô„ÅãÔºü",
            'options': ["1Âπ¥‰ª•ÂÜÖ", "5Âπ¥‰ª•ÂÜÖ", "„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™ÂÖ®ÊúüÈñì", "Ë®à‰∏ä„Åß„Åç„Å™„ÅÑ"],
            'correct': 2,
            'explanation': "„ÄåÂàÜÈ°û2ÔºàÊ•≠Á∏æ„ÅåÂÆâÂÆö„Åó„Å¶„ÅÑ„Çã‰ºÅÊ•≠Ôºâ„Äç„ÅÆÂ†¥Âêà„ÄÅ„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞ÂèØËÉΩ„Å™Â∞ÜÊù•Ê∏õÁÆó‰∏ÄÊôÇÂ∑ÆÁï∞„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅÊúüÈñìÂà∂Èôê„Å™„ÅèÔºàÂÖ®ÊúüÈñìÔºâÂõûÂèéÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Å®Âà§Êñ≠„Åï„Çå„Åæ„Åô„ÄÇ"
        }
    ],
    'Management': [
        {
            'level': 1,
            'q': "CVPÂàÜÊûê: ÊêçÁõäÂàÜÂ≤êÁÇπÂ£≤‰∏äÈ´ò„ÇíÊ±Ç„ÇÅ„ÇãË®àÁÆóÂºè„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âõ∫ÂÆöË≤ª √∑ Ë≤¢ÁåÆÂà©ÁõäÁéá", "Âõ∫ÂÆöË≤ª √∑ Â§âÂãïË≤ªÁéá", "Â§âÂãïË≤ª √∑ Â£≤‰∏äÈ´ò", "Âà©Áõä √∑ Â£≤‰∏äÈ´ò"],
            'correct': 0,
            'explanation': "ÊêçÁõäÂàÜÂ≤êÁÇπÂ£≤‰∏äÈ´ò Ôºù Âõ∫ÂÆöË≤ª √∑ (1 Ôºç Â§âÂãïË≤ªÁéá) Ôºù Âõ∫ÂÆöË≤ª √∑ Ë≤¢ÁåÆÂà©ÁõäÁéá „Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Âéü‰æ°„ÅÆÂàÜÈ°û: „ÄåÁ¥†‰æ° (Prime Cost)„Äç„ÇíÊßãÊàê„Åô„Çã„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Áõ¥Êé•ÊùêÊñôË≤ª Ôºã Áõ¥Êé•Âä¥ÂãôË≤ª", "Áõ¥Êé•Âä¥ÂãôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ª", "Áõ¥Êé•ÊùêÊñôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ª", "Ë≤©Â£≤Ë≤ªÂèä„Å≥‰∏ÄËà¨ÁÆ°ÁêÜË≤ª"],
            'correct': 0,
            'explanation': "Á¥†‰æ°ÔºàPrime CostÔºâ„ÅØ„ÄÅÁõ¥Êé•ÊùêÊñôË≤ª„Å®Áõ¥Êé•Âä¥ÂãôË≤ª„ÅÆÂêàË®à„Åß„Åô„ÄÇÔºàÂä†Â∑•Ë≤ª Ôºù Áõ¥Êé•Âä¥ÂãôË≤ª Ôºã Ë£ΩÈÄ†ÈñìÊé•Ë≤ªÔºâ"
        },
        {
            'level': 1,
            'q': "Ê®ôÊ∫ñÂéü‰æ°Ë®àÁÆó: ÂÆüÈöõÊ∂àË≤ªÈáè„ÅåÊ®ôÊ∫ñÊ∂àË≤ªÈáè„Çí‰∏äÂõû„Å£„ÅüÂ†¥Âêà„Å´Áô∫Áîü„Åô„ÇãÂ∑ÆÁï∞„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÊúâÂà©Êï∞ÈáèÂ∑ÆÁï∞", "‰∏çÂà©Êï∞ÈáèÂ∑ÆÁï∞", "ÊúâÂà©‰æ°Ê†ºÂ∑ÆÁï∞", "‰∏çÂà©‰æ°Ê†ºÂ∑ÆÁï∞"],
            'correct': 1,
            'explanation': "Ê®ôÊ∫ñ„Çà„Çä„ÇÇÂ§ö„Åè„ÅÆÊï∞Èáè„ÇíÊ∂àË≤ª„Åó„Å¶„Åó„Åæ„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅ„Ç≥„Çπ„ÉàÂ¢ó„Å®„Å™„Çã„Åü„ÇÅ„Äå‰∏çÂà©Â∑ÆÁï∞ÔºàUnfavorableÔºâ„Äç„Å®„Å™„Çä„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ¥Êé•Âéü‰æ°Ë®àÁÆó: Âõ∫ÂÆöË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÅØ„Å©„ÅÆ„Çà„ÅÜ„Å´Âá¶ÁêÜ„Åï„Çå„Åæ„Åô„ÅãÔºü",
            'options': ["Ë£ΩÂìÅÂéü‰æ°„Å®„Åó„Å¶Âá¶ÁêÜ", "ÊúüÈñìÂéü‰æ°„Å®„Åó„Å¶Âá¶ÁêÜ", "Ë≥áÁî£„Å®„Åó„Å¶Ë®à‰∏ä", "Ë≤†ÂÇµ„Å®„Åó„Å¶Ë®à‰∏ä"],
            'correct': 1,
            'explanation': "Áõ¥Êé•Âéü‰æ°Ë®àÁÆó„Åß„ÅØ„ÄÅÂõ∫ÂÆöË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÅØÁô∫ÁîüÊôÇ„Å´„ÄåÊúüÈñìÂéü‰æ°„Äç„Å®„Åó„Å¶ÂÖ®È°çË≤ªÁî®Âá¶ÁêÜ„Åï„Çå„Åæ„ÅôÔºàCVPÂàÜÊûê„Å´ÊúâÁî®Ôºâ„ÄÇ"
        },
        {
            'level': 1,
            'q': "Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ: Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ„Å´„Åä„ÅÑ„Å¶„ÄÅÂéü‰æ°Ë®àÁÆó„ÅÆÁõÆÁöÑ„Å®„Åó„Å¶Êåô„Åí„Çâ„Çå„Å¶„ÅÑ„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ë≤°ÂãôË´∏Ë°®„ÅÆ‰ΩúÊàê", "Âéü‰æ°ÁÆ°ÁêÜ", "‰∫àÁÆóÁµ±Âà∂", "ÂæìÊ•≠Âì°Áµ¶‰∏é„ÅÆË®àÁÆó"],
            'correct': 3,
            'explanation': "Âéü‰æ°Ë®àÁÆóÂü∫Ê∫ñ„Å´„ÅØ„ÄÅË≤°ÂãôË´∏Ë°®‰ΩúÊàê„ÄÅ‰æ°Ê†ºË®àÁÆó„ÄÅÂéü‰æ°ÁÆ°ÁêÜ„ÄÅ‰∫àÁÆóÁÆ°ÁêÜ„ÄÅÂü∫Êú¨Ë®àÁîªÁ≠ñÂÆö„ÅÆ5„Å§„ÅÆÁõÆÁöÑ„ÅåÊåô„Åí„Çâ„Çå„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅÁµ¶‰∏éË®àÁÆó„ÅØÂê´„Åæ„Çå„Åæ„Åõ„Çì„ÄÇ"
        },
        {
            'level': 1,
            'q': "ABC (Ê¥ªÂãïÂü∫Ê∫ñÂéü‰æ°Ë®àÁÆó): Ë£ΩÈÄ†ÈñìÊé•Ë≤ª„ÇíË£ΩÂìÅ„Å´ÈÖçË≥¶„Åô„Çã„Åü„ÇÅ„Å´‰ΩøÁî®„Åï„Çå„ÇãÂü∫Ê∫ñ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
            'options': ["ÊìçÊ•≠Â∫¶", "„Ç≥„Çπ„Éà„Éª„Éâ„É©„Ç§„Éê„Éº (Ê¥ªÂãïÂéü‰æ°Ë¶ÅÂõ†)", "Áõ¥Êé•‰ΩúÊ•≠ÊôÇÈñì", "Ê©üÊ¢∞Á®ºÂÉçÊôÇÈñì"],
            'correct': 1,
            'explanation': "ABC„Åß„ÅØ„ÄÅË£ΩÈÄ†ÈñìÊé•Ë≤ª„ÇíÊ¥ªÂãï„Åî„Å®„Å´ÊääÊè°„Åó„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÊ¥ªÂãï„ÅÆÁô∫ÁîüË¶ÅÂõ†„Åß„ÅÇ„Çã„Äå„Ç≥„Çπ„Éà„Éª„Éâ„É©„Ç§„Éê„Éº„Äç„Å´Âü∫„Å•„ÅÑ„Å¶Ë£ΩÂìÅ„Å´ÈÖçË≥¶„Åó„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "ÊäïË≥á„ÅÆÁµåÊ∏àÊÄßË®àÁÆó: ROI (Êäï‰∏ãË≥áÊú¨Âà©ÁõäÁéá) „ÇíÊ±Ç„ÇÅ„ÇãË®àÁÆóÂºè„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âà©Áõä √∑ Â£≤‰∏äÈ´ò", "Â£≤‰∏äÈ´ò √∑ Êäï‰∏ãË≥áÊú¨", "Âà©Áõä √∑ Êäï‰∏ãË≥áÊú¨", "Êäï‰∏ãË≥áÊú¨ √∑ Âà©Áõä"],
            'correct': 2,
            'explanation': "ROI (Return On Investment) „ÅØ„ÄÅÂà©Áõä„ÇíÊäï‰∏ãË≥áÊú¨„ÅßÂâ≤„Å£„Å¶ÁÆóÂá∫„Åó„Åæ„ÅôÔºàROI = Â£≤‰∏äÈ´òÂà©ÁõäÁéá √ó Ë≥áÊú¨ÂõûËª¢ÁéáÔºâ„ÄÇ"
        },
        {
            'level': 2,
            'q': "CVPÂàÜÊûê: Âõ∫ÂÆöË≤ª1,000„ÄÅÂ§âÂãïË≤ªÁéá0.6„ÄÅÁõÆÊ®ôÂà©Áõä200„ÅÆÂ†¥Âêà„ÄÅÁõÆÊ®ôÂ£≤‰∏äÈ´ò„ÅØ„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["2,000", "3,000", "2,500", "1,200"],
            'correct': 1,
            'explanation': "ÁõÆÊ®ôÂ£≤‰∏äÈ´ò Ôºù (Âõ∫ÂÆöË≤ª Ôºã ÁõÆÊ®ôÂà©Áõä) √∑ (1 Ôºç Â§âÂãïË≤ªÁéá) Ôºù (1000 + 200) √∑ 0.4 Ôºù 3000 „Åß„Åô„ÄÇ"
        }
    ],
    'Audit': [
        {
            'level': 1,
            'q': "Áõ£Êüª„É™„Çπ„ÇØ: Áõ£Êüª„É™„Çπ„ÇØ„Éª„É¢„Éá„É´„ÅÆÊßãÊàêË¶ÅÁ¥†„Å®„Åó„Å¶Ê≠£„Åó„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Âõ∫Êúâ„É™„Çπ„ÇØ √ó Áµ±Âà∂„É™„Çπ„ÇØ √ó Áô∫Ë¶ã„É™„Çπ„ÇØ", "„Éì„Ç∏„Éç„Çπ„É™„Çπ„ÇØ √ó Áõ£Êüª„É™„Çπ„ÇØ", "ÈáçË¶ÅÊÄß √ó „É™„Çπ„ÇØ", "ÊäΩÂá∫„É™„Çπ„ÇØ √ó ÈùûÊäΩÂá∫„É™„Çπ„ÇØ"],
            'correct': 0,
            'explanation': "Áõ£Êüª„É™„Çπ„ÇØ Ôºù ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„É™„Çπ„ÇØÔºàÂõ∫Êúâ„É™„Çπ„ÇØ√óÁµ±Âà∂„É™„Çπ„ÇØÔºâ √ó Áô∫Ë¶ã„É™„Çπ„ÇØ „Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áã¨Á´ãÊÄß: „ÄåÂ§ñË¶≥ÁöÑÁã¨Á´ãÊÄß„Äç„ÇíÊêç„Å™„ÅÜË¶ÅÂõ†„Å®„Å™„Çã„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ë¢´Áõ£Êüª‰ºöÁ§æ„ÅÆÊ†™Âºè‰øùÊúâ", "Ë™†ÂÆü„Åß„ÅÇ„Çã„Åì„Å®", "Â∞ÇÈñÄËÉΩÂäõ„ÇíÊúâ„Åô„Çã„Åì„Å®", "ÂÄ´ÁêÜË¶èÂÆö„ÅÆÈÅµÂÆà"],
            'correct': 0,
            'explanation': "Ë¢´Áõ£Êüª‰ºöÁ§æ„ÅÆÊ†™Âºè„ÇÑÈáçË¶Å„Å™ÁµåÊ∏àÁöÑÂà©ÂÆ≥Èñ¢‰øÇ„ÇíÊúâ„Åô„Çã„Åì„Å®„ÅØ„ÄÅÂ§ñË¶≥ÁöÑÁã¨Á´ãÊÄßÔºàÁ¨¨‰∏âËÄÖ„Åã„ÇâË¶ã„Å¶Áã¨Á´ã„Åó„Å¶„ÅÑ„Çã„Å®Ë¶ã„Åà„Çã„Åì„Å®Ôºâ„ÇíÊêç„Å™„ÅÑ„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÊÑèË¶ã: Ë≤°ÂãôË´∏Ë°®ÂÖ®‰Ωì„Å´ÈáçË¶Å„Å™ËôöÂÅΩË°®Á§∫„Åå„ÅÇ„Çä„ÄÅ„Åã„Å§„Åù„ÅÆÂΩ±Èüø„ÅåÂ∫ÉÁØÑ„Åß„ÅÇ„ÇãÂ†¥Âêà„Å´Ë°®Êòé„Åï„Çå„ÇãÊÑèË¶ã„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÁÑ°ÈôêÂÆöÈÅ©Ê≠£ÊÑèË¶ã", "ÈôêÂÆö‰ªòÈÅ©Ê≠£ÊÑèË¶ã", "‰∏çÈÅ©Ê≠£ÊÑèË¶ã", "ÊÑèË¶ã‰∏çË°®Êòé"],
            'correct': 2,
            'explanation': "ÈáçË¶Å„Åã„Å§Â∫ÉÁØÑÔºàPervasiveÔºâ„Å™ËôöÂÅΩË°®Á§∫„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Äå‰∏çÈÅ©Ê≠£ÊÑèË¶ãÔºàAdverse OpinionÔºâ„Äç„ÅåË°®Êòé„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "ÂÜÖÈÉ®Áµ±Âà∂: ÂÜÖÈÉ®Áµ±Âà∂„ÅÆÊï¥ÂÇô„ÉªÈÅãÁî®Ë≤¨‰ªª„ÅØË™∞„Å´„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
            'options': ["Áõ£Êüª‰∫∫", "ÁµåÂñ∂ËÄÖ", "Ê†™‰∏ª", "ÊîøÂ∫ú"],
            'correct': 1,
            'explanation': "ÂÜÖÈÉ®Áµ±Âà∂„ÇíÊï¥ÂÇô„ÅóÈÅãÁî®„Åô„ÇãË≤¨‰ªª„ÅØ„ÄåÁµåÂñ∂ËÄÖ„Äç„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇÁõ£Êüª‰∫∫„ÅØ„Åù„ÅÆÊúâÂäπÊÄß„ÇíË©ï‰æ°„ÉªÂ†±Âëä„Åô„ÇãÁ´ãÂ†¥„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªË®ºÊã†: ‰∏ÄËà¨ÁöÑ„Å´ÊúÄ„ÇÇË®ºÊòéÂäõ„ÅåÈ´ò„ÅÑ„Å®„Åï„Çå„ÇãÁõ£ÊüªË®ºÊã†„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÁµåÂñ∂ËÄÖ„Å∏„ÅÆË≥™Âïè", "Ë¶≥ÂØü", "Â§ñÈÉ®Á¢∫Ë™ç", "Á§æÂÜÖÊñáÊõ∏"],
            'correct': 2,
            'explanation': "Â§ñÈÉ®„ÅÆÁ¨¨‰∏âËÄÖ„Åã„ÇâÁõ¥Êé•ÂÖ•Êâã„Åô„Çã„ÄåÁ¢∫Ë™çÔºàExternal ConfirmationÔºâ„Äç„ÅØ„ÄÅ‰∏ÄËà¨„Å´Á§æÂÜÖË®ºÊã†„Çà„Çä„ÇÇË®ºÊòéÂäõ„ÅåÈ´ò„ÅÑ„Å®„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∏çÊ≠£ÂØæÂøú: „Äå‰∏çÊ≠£„ÅÆ„Éà„É©„Ç§„Ç¢„É≥„Ç∞„É´„Äç„ÅÆ3Ë¶ÅÁ¥†„Å´Âê´„Åæ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["ÂãïÊ©ü„Éª„Éó„É¨„ÉÉ„Ç∑„É£„Éº", "Ê©ü‰ºö", "ÂßøÂã¢„ÉªÊ≠£ÂΩìÂåñ", "ÁΩ∞Ââá"],
            'correct': 3,
            'explanation': "‰∏çÊ≠£„ÅÆ„Éà„É©„Ç§„Ç¢„É≥„Ç∞„É´„ÅØ„ÄÅ„ÄåÂãïÊ©ü„Éª„Éó„É¨„ÉÉ„Ç∑„É£„Éº„Äç„ÄåÊ©ü‰ºö„Äç„ÄåÂßøÂã¢„ÉªÊ≠£ÂΩìÂåñ„Äç„ÅÆ3Ë¶ÅÁ¥†„Åã„ÇâÊßãÊàê„Åï„Çå„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÂ†±ÂëäÊõ∏: Áõ£ÊüªÂ†±ÂëäÊõ∏Êó•„ÅØ„ÅÑ„Å§„Åß„ÅÇ„Çã„Åπ„Åç„Åß„Åô„ÅãÔºü",
            'options': ["Ê±∫ÁÆóÊó•", "Áõ£Êüª‰∫∫„ÅåÁõ£ÊüªÊÑèË¶ã„ÇíÂΩ¢Êàê„Åô„Çã„ÅÆ„Å´ÂçÅÂàÜ„Åã„Å§ÈÅ©Âàá„Å™Áõ£ÊüªË®ºÊã†„ÇíÂÖ•Êâã„Åó„ÅüÊó•", "Ê†™‰∏ªÁ∑è‰ºöÈñãÂÇ¨Êó•", "Êúâ‰æ°Ë®ºÂà∏Â†±ÂëäÊõ∏ÊèêÂá∫Êó•"],
            'correct': 1,
            'explanation': "Áõ£ÊüªÂ†±ÂëäÊõ∏Êó•„ÅØ„ÄÅÁõ£Êüª‰∫∫„ÅåÊÑèË¶ãË°®Êòé„ÅÆÂü∫Á§é„Å®„Å™„ÇãÂçÅÂàÜ„Åã„Å§ÈÅ©Âàá„Å™Áõ£ÊüªË®ºÊã†„ÇíÂÖ•Êâã„Åó„ÅüÊó•ÔºàÁõ£ÊüªÁµÇ‰∫ÜÊó•Ôºâ„Å®„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        }
    ],
    'Company': [
        {
            'level': 1,
            'q': "Ë®≠Á´ã: Ê†™Âºè‰ºöÁ§æ„ÅÆË®≠Á´ã„Å´„Åä„Åë„ÇãÊúÄ‰ΩéË≥áÊú¨Èáë„ÅÆÈ°ç„ÅØ„ÅÑ„Åè„Çâ„Åß„Åô„ÅãÔºü",
            'options': ["1,000‰∏áÂÜÜ", "300‰∏áÂÜÜ", "1ÂÜÜ", "0ÂÜÜ"],
            'correct': 2,
            'explanation': "ÁèæÂú®„ÅÆ‰ºöÁ§æÊ≥ï„Åß„ÅØ„ÄÅÊúÄ‰ΩéË≥áÊú¨ÈáëÂà∂Â∫¶„ÅØÊí§ÂªÉ„Åï„Çå„Å¶„Åä„Çä„ÄÅË≥áÊú¨Èáë1ÂÜÜ„Åã„ÇâË®≠Á´ã„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ëá™Â∑±Ê†™Âºè: Ê†™Âºè‰ºöÁ§æ„ÅØËá™Â∑±Ê†™Âºè„ÇíÂèñÂæó„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÅãÔºü",
            'options': ["ÂÆåÂÖ®„Å´Á¶ÅÊ≠¢„Åï„Çå„Å¶„ÅÑ„Çã", "Ë≤°Ê∫êË¶èÂà∂Á≠â„ÅÆ‰∏ã„ÅßË™ç„ÇÅ„Çâ„Çå„Çã", "Ëá™Áî±„Å´Ë™ç„ÇÅ„Çâ„Çå„Çã", "Ëß£Êï£ÊôÇ„ÅÆ„ÅøË™ç„ÇÅ„Çâ„Çå„Çã"],
            'correct': 1,
            'explanation': "Ëá™Â∑±Ê†™Âºè„ÅÆÂèñÂæó„ÅØ„ÄÅÂàÜÈÖçÂèØËÉΩÈ°ç„ÅÆÁØÑÂõ≤ÂÜÖ„Åß„ÅÇ„Çã„Åì„Å®„ÇÑÊ†™‰∏ªÁ∑è‰ºöÊ±∫Ë≠∞„Å™„Å©„ÅÆË¶èÂà∂„ÅÆ‰∏ã„ÅßË™ç„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê©üÈñ¢Ë®≠Ë®à: ÂèñÁ∑†ÂΩπ‰ºöË®≠ÁΩÆ‰ºöÁ§æ„Å´„Åä„Åë„ÇãÂèñÁ∑†ÂΩπ„ÅÆÊúÄ‰Ωé‰∫∫Êï∞„ÅØ‰Ωï‰∫∫„Åß„Åô„ÅãÔºü",
            'options': ["1‰∫∫", "2‰∫∫", "3‰∫∫", "5‰∫∫"],
            'correct': 2,
            'explanation': "ÂèñÁ∑†ÂΩπ‰ºö„ÇíË®≠ÁΩÆ„Åô„ÇãÂ†¥Âêà„ÄÅÂèñÁ∑†ÂΩπ„ÅØ3‰∫∫‰ª•‰∏äÂøÖË¶Å„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê†™‰∏ªÁ∑è‰ºö: ÁâπÂà•Ê±∫Ë≠∞„ÅÆÂÆöË∂≥Êï∞„ÅØÂéüÂâá„Å®„Åó„Å¶„Å©„ÅÆ„Åè„Çâ„ÅÑ„Åß„Åô„ÅãÔºü",
            'options': ["Ë≠∞Ê±∫Ê®©„ÅÆÈÅéÂçäÊï∞", "Ë≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ1", "Ë≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ2", "ÂÖ®Ê†™‰∏ª"],
            'correct': 0,
            'explanation': "ÁâπÂà•Ê±∫Ë≠∞„ÅÆÂÆöË∂≥Êï∞„ÅØÂéüÂâá„Å®„Åó„Å¶„ÄåË≠∞Ê±∫Ê®©„ÅÆÈÅéÂçäÊï∞„Äç„Åß„ÅôÔºàÂÆöÊ¨æ„Åß3ÂàÜ„ÅÆ1„Åæ„ÅßÁ∑©ÂíåÂèØÔºâ„ÄÇÊ±∫Ë≠∞Ë¶Å‰ª∂„ÅØÂá∫Â∏≠Ê†™‰∏ª„ÅÆË≠∞Ê±∫Ê®©„ÅÆ3ÂàÜ„ÅÆ2‰ª•‰∏ä„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "Áõ£ÊüªÂΩπ: Áõ£ÊüªÂΩπ„ÅÆ‰ªªÊúü„ÅØÂéüÂâá„Å®„Åó„Å¶‰ΩïÂπ¥„Åß„Åô„ÅãÔºü",
            'options': ["1Âπ¥", "2Âπ¥", "4Âπ¥", "10Âπ¥"],
            'correct': 2,
            'explanation': "Áõ£ÊüªÂΩπ„ÅÆ‰ªªÊúü„ÅØÂéüÂâá„Å®„Åó„Å¶4Âπ¥„Åß„Åô„ÄÇÂÆöÊ¨æ„Å´„Çà„Å£„Å¶„ÇÇÁü≠Á∏Æ„Åô„Çã„Åì„Å®„ÅØ„Åß„Åç„Åæ„Åõ„Çì„ÄÇ"
        },
        {
            'level': 1,
            'q': "Ê†™‰∏ª„ÅÆÊ®©Âà©: ÂçòÁã¨Ê†™‰∏ªÊ®©Ôºà1Ê†™„Åß„ÇÇ‰øùÊúâ„Åó„Å¶„ÅÑ„Çå„Å∞Ë°å‰Ωø„Åß„Åç„ÇãÊ®©Âà©Ôºâ„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["Ê†™‰∏ªÁ∑è‰ºöÊãõÈõÜË´ãÊ±ÇÊ®©", "Â∏≥Á∞øÈñ≤Ë¶ßË´ãÊ±ÇÊ®©", "Ââ∞‰ΩôÈáëÈÖçÂΩìË´ãÊ±ÇÊ®©", "ÂèñÁ∑†ÂΩπËß£‰ªªË´ãÊ±ÇÊ®©"],
            'correct': 2,
            'explanation': "Ââ∞‰ΩôÈáëÈÖçÂΩìË´ãÊ±ÇÊ®©„ÇÑË≠∞Ê±∫Ê®©„ÅØ„ÄÅ1Ê†™„Åã„ÇâË™ç„ÇÅ„Çâ„Çå„ÇãÂçòÁã¨Ê†™‰∏ªÊ®©„Åß„Åô„ÄÇÂ∏≥Á∞øÈñ≤Ë¶ßÊ®©„Å™„Å©„ÅØ‰∏ÄÂÆö„ÅÆÊ†™ÂºèÊï∞„ÉªÊúüÈñì„ÅåÂøÖË¶Å„Å™Â∞ëÊï∞Ê†™‰∏ªÊ®©„Åß„Åô„ÄÇ"
        },
        {
            'level': 1,
            'q': "‰∫ãÊ•≠Ë≠≤Ê∏°: Ê†™‰∏ªÁ∑è‰ºö„ÅÆÁâπÂà•Ê±∫Ë≠∞„ÅåÂøÖË¶Å„Å®„Å™„Çã‰∫ãÊ•≠Ë≠≤Ê∏°„ÅØ„Å©„Çå„Åß„Åô„ÅãÔºü",
            'options': ["‰∫ãÊ•≠„ÅÆÂÖ®ÈÉ®„Åæ„Åü„ÅØÈáçË¶Å„Å™‰∏ÄÈÉ®„ÅÆË≠≤Ê∏°", "ÈáçË¶Å„Å™Ë≥áÁî£„ÅÆÂá¶ÂàÜ", "Â§öÈ°ç„ÅÆÂÄüË≤°", "ÊîØÈÖç‰∫∫„ÅÆÈÅ∏‰ªª"],
            'correct': 0,
            'explanation': "‰∫ãÊ•≠„ÅÆÂÖ®ÈÉ®„ÅÆË≠≤Ê∏°„ÄÅ„Åæ„Åü„ÅØ‰∫ãÊ•≠„ÅÆÈáçË¶Å„Å™‰∏ÄÈÉ®„ÅÆË≠≤Ê∏°ÔºàË≠≤Ê∏°Ë≥áÁî£„ÅåÁ∑èË≥áÁî£„ÅÆ1/5Ë∂Ö„Å™„Å©Ôºâ„Å´„ÅØ„ÄÅÊ†™‰∏ªÁ∑è‰ºö„ÅÆÁâπÂà•Ê±∫Ë≠∞„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ"
        }
    ]
}

# Load generated questions
json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
if os.path.exists(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            generated_questions = json.load(f)
            for subject, questions in generated_questions.items():
                if subject in drill_questions:
                    drill_questions[subject].extend(questions)
                else:
                    drill_questions[subject] = questions
    except Exception as e:
        st.error(f"Failed to load generated questions: {e}")

# Load Study Materials (Syllabus)
def load_study_materials():
    # Looking for 'studying' folder in 'platform' directory (moved inside)
    materials_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'studying')
    syllabus = {}
    extra_pdfs = []
    
    if not os.path.exists(materials_dir):
        return {}, []
        
    for filename in os.listdir(materials_dir):
        if filename.endswith('.xlsx') and not filename.startswith('~$'): # Ignore temp files
            try:
                # Extract subject from filename (e.g., "1-Ë≤°Âãô‰ºöË®àË´ñ„Ç≥„Éº„Çπ.xlsx" -> "Ë≤°Âãô‰ºöË®àË´ñ")
                parts = filename.split('-')
                if len(parts) > 1:
                    subject_name = parts[1].replace('„Ç≥„Éº„Çπ.xlsx', '')
                else:
                    subject_name = filename.replace('.xlsx', '')
                
                # Read Excel
                file_path = os.path.join(materials_dir, filename)
                df = pd.read_excel(file_path, header=1)
                
                # Fill merged cells (NaN) with previous value
                if '„Ç´„ÉÜ„Ç¥„É™' in df.columns:
                    df['„Ç´„ÉÜ„Ç¥„É™'] = df['„Ç´„ÉÜ„Ç¥„É™'].ffill()
                if '„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™' in df.columns:
                    df['„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™'] = df['„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™'].ffill()
                
                # Filter relevant columns
                if 'Ë¨õÂ∫ßÂêç' in df.columns:
                    items = []
                    for _, row in df.iterrows():
                        if pd.notna(row['Ë¨õÂ∫ßÂêç']):
                            items.append({
                                'category': row.get('„Ç´„ÉÜ„Ç¥„É™', ''),
                                'subcategory': row.get('„Çµ„Éñ„Ç´„ÉÜ„Ç¥„É™', ''),
                                'title': row['Ë¨õÂ∫ßÂêç'],
                                'duration': row.get('ÂÜçÁîüÊôÇÈñì/Ê®ôÊ∫ñÊôÇÈñì', '')
                            })
                    
                    # Find corresponding PDF
                    pdf_path = os.path.join(materials_dir, filename.replace('.xlsx', '.pdf'))
                    has_pdf = os.path.exists(pdf_path)
                    
                    syllabus[subject_name] = {
                        'items': items,
                        'pdf_path': pdf_path if has_pdf else None,
                        'excel_path': file_path
                    }
            except Exception as e:
                print(f"Error loading {filename}: {e}")
    
    # Load extra PDFs from 'PDF' subdirectory
    pdf_dir = os.path.join(materials_dir, 'PDF')
    if os.path.exists(pdf_dir):
        for f in os.listdir(pdf_dir):
            if f.lower().endswith('.pdf'):
                extra_pdfs.append({
                    'name': f,
                    'path': os.path.join(pdf_dir, f)
                })
                
    # Also load standalone PDFs in the root of 'studying' that are not paired with an Excel file
    # Get list of PDF paths already associated with courses
    paired_pdfs = set()
    for subject_data in syllabus.values():
        if subject_data['pdf_path']:
            paired_pdfs.add(os.path.normpath(subject_data['pdf_path']))
            
    for filename in os.listdir(materials_dir):
        if filename.lower().endswith('.pdf'):
            full_path = os.path.join(materials_dir, filename)
            if os.path.normpath(full_path) not in paired_pdfs:
                extra_pdfs.append({
                    'name': filename,
                    'path': full_path
                })
                
    return syllabus, extra_pdfs

study_materials, extra_pdfs = load_study_materials()

roadmap_md = """
# CPA 1.5 Year Strategy Roadmap

## Phase 0: Foundation (2026)
* **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics.
* **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
* **Jul - Sep**: **CRITICAL** Start Tax Law & Electives.
* **Oct - Dec**: **Dec Short Exam Challenge**. Aim to pass!

## Phase 1: Short Exam Mastery (Jan - May 2027)
* **Jan - Mar**: Solidify basics. 75%+ in drills.
* **Apr - May**: Peak conditioning. Rote memorization.

## Phase 2: Essay Sprint (Jun - Aug 2027)
* **Jun**: Revive Tax/Elective knowledge.
* **Jul**: Output training (Writing).
* **Aug**: Final adjustments.
"""

# Navigation
st.sidebar.title("CPA Platform 2027")

# User Profile in Sidebar
with st.sidebar.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        st.markdown("### üéì")
    with col2:
        curr_level = st.session_state.data.get('level', 1)
        st.write(f"**Level {curr_level}**")
    
    curr_xp = st.session_state.data.get('xp', 0)
    next_level_xp = curr_level * 100
    progress = min(curr_xp / next_level_xp, 1.0)
    st.progress(progress)
    st.caption(f"XP: {curr_xp} / {next_level_xp}")

st.sidebar.markdown("---")

# Quick Links
st.sidebar.markdown("""
    <style>
    .big-rocket-button {
        display: inline-block;
        width: 100%;
        padding: 12px;
        background: linear-gradient(135deg, #FF4B4B 0%, #FF0000 100%);
        color: white !important;
        text-align: center;
        font-size: 18px;
        font-weight: 900;
        border-radius: 12px;
        text-decoration: none !important;
        box-shadow: 0 4px 15px rgba(255, 0, 0, 0.4);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        border: 2px solid rgba(255, 255, 255, 0.2);
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .big-rocket-button:hover {
        background: linear-gradient(135deg, #FF0000 0%, #D00000 100%);
        transform: translateY(-2px) scale(1.02);
        box-shadow: 0 6px 20px rgba(255, 0, 0, 0.6);
        border-color: rgba(255, 255, 255, 0.5);
    }
    .big-rocket-button:active {
        transform: translateY(1px);
        box-shadow: 0 2px 10px rgba(255, 0, 0, 0.3);
    }
    </style>
    <a href="https://member.studying.jp/top/" target="_blank" class="big-rocket-button">
        üöÄ STUDYING
    </a>
    """, unsafe_allow_html=True)

st.sidebar.markdown("---")
page = st.sidebar.radio("Navigation", ["Dashboard", "My Syllabus üìö", "Old Exams üìÑ", "Study Timer", "Mock Exams", "Scores", "Drills", "Survival Mode ‚ö°", "Roadmap", "Big 4 Job Hunting", "Company Directory üè¢", "Future üöÄ"])

if page == "Dashboard":
    st.header("Dashboard")
    st.subheader("Goal: 2027 May Short & Aug Essay")
    
    # Countdowns
    col1, col2, col3 = st.columns(3)
    today = date.today()
    
    with col1:
        target = date(2026, 12, 13)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>Dec 2026 Short</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
        
    with col2:
        target = date(2027, 5, 23)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>May 2027 Short</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
        
    with col3:
        target = date(2027, 8, 20)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>Aug 2027 Essay</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Daily Tip
    st.subheader("üí° Daily CPA Tip")
    tips = [
        "Consistency is key. 30 minutes every day is better than 5 hours once a week.",
        "Focus on 'why', not just 'how'. Understanding the logic helps in applied questions.",
        "Don't ignore the theory. It's 40-50% of the exam.",
        "Review your mistakes. The 'incorrect' options are learning opportunities.",
        "Sleep is part of studying. Memory consolidation happens during sleep.",
        "Use the 'Survival Mode' to build speed and accuracy under pressure!",
        "Audit isn't just memorization; imagine you are the auditor in that situation."
    ]
    import random
    st.info(random.choice(tips))
    
    st.markdown("---")
    
    # Study Time & Radar Chart
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.subheader("Skill Balance")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        # Mock scores for radar chart if empty
        radar_scores = [60, 55, 40, 45, 30, 30]
        
        # Calculate from actual scores if available
        if st.session_state.data["scores"]:
            df_scores = pd.DataFrame(st.session_state.data["scores"])
            avg_scores = []
            for sub in subjects:
                sub_df = df_scores[df_scores['subject'] == sub]
                if not sub_df.empty:
                    avg_scores.append(sub_df['val'].mean())
                else:
                    avg_scores.append(30) # Default baseline
            radar_scores = avg_scores
            
        fig = go.Figure(data=go.Scatterpolar(
            r=radar_scores,
            theta=subjects,
            fill='toself',
            name='Current Skill'
        ))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
    with c2:
        st.subheader("Phase Progress: Foundation")
        st.progress(15)
        st.markdown("""
        * Focus: Financial & Management Accounting Calculation
        * Goal: Complete basic lectures by Aug 2026
        * Next Milestone: Dec 2026 Short Exam
        """)

elif page == "My Syllabus üìö":
    st.header("My Study Syllabus üìö")
    st.info("Based on your uploaded materials in 'studying' folder.")
    
    if not study_materials and not extra_pdfs:
        st.warning("No study materials found in 'studying' folder.")
    else:
        # Progress Tracking
        if 'syllabus_progress' not in st.session_state.data:
            st.session_state.data['syllabus_progress'] = []
            
        completed_items = set(st.session_state.data['syllabus_progress'])
        
        # Callback for checkbox
        def toggle_syllabus(key):
            if key in st.session_state.data['syllabus_progress']:
                st.session_state.data['syllabus_progress'].remove(key)
            else:
                st.session_state.data['syllabus_progress'].append(key)
                # Add XP for completing a lecture!
                st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + 50
                st.toast("Lecture Completed! +50 XP", icon="üéì")
            save_data(st.session_state.data)

        # Tabs for subjects
        if study_materials:
            subjects = list(study_materials.keys())
            tabs = st.tabs(subjects)
            
            for i, subject in enumerate(subjects):
                with tabs[i]:
                    data = study_materials[subject]
                    items = data['items']
                    pdf_path = data['pdf_path']
                    excel_path = data['excel_path']
                    
                    # Header Actions
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        st.subheader(f"{subject} ({len(items)} Lectures)")
                    with c2:
                        if pdf_path:
                            if st.button(f"üìÑ Open PDF", key=f"pdf_{subject}"):
                                try:
                                    os.startfile(pdf_path)
                                    st.toast(f"Opening {subject} PDF...", icon="üöÄ")
                                except Exception as e:
                                    st.error(f"Cannot open PDF: {e}")
                        
                        if st.button(f"üìä Open Excel", key=f"excel_{subject}"):
                            try:
                                os.startfile(excel_path)
                                st.toast(f"Opening {subject} Excel...", icon="üìä")
                            except Exception as e:
                                st.error(f"Cannot open Excel: {e}")

                    
                    # Progress Bar for Subject
                    subject_completed = [item['title'] for item in items if f"{subject}|{item['title']}" in completed_items]
                    prog = len(subject_completed) / len(items) if items else 0
                    st.progress(prog)
                    st.caption(f"Progress: {len(subject_completed)} / {len(items)} ({prog:.1%})")
                    
                    # Group by Category/Subcategory
                    df = pd.DataFrame(items)
                    if not df.empty and 'category' in df.columns:
                        for cat, group in df.groupby('category'):
                            with st.expander(f"üìÇ {cat}", expanded=True):
                                for idx, row in group.iterrows():
                                    title = row['title']
                                    unique_key = f"{subject}|{title}"
                                    is_done = unique_key in completed_items
                                    
                                    c_chk, c_txt, c_time = st.columns([0.5, 4, 1.5])
                                    with c_chk:
                                        # Use subject and index to ensure widget key uniqueness
                                        st.checkbox("", value=is_done, key=f"chk_{subject}_{idx}", on_change=toggle_syllabus, kwargs={'key': unique_key})
                                    
                                    with c_txt:
                                        if is_done:
                                            st.markdown(f"~~{title}~~")
                                        else:
                                            st.markdown(f"**{title}**")
                                            if row['subcategory']:
                                                st.caption(f"‚îî {row['subcategory']}")
                                                
                                    with c_time:
                                        st.caption(f"‚è±Ô∏è {row['duration']}")

        # Supplemental Resources (Extra PDFs)
        if extra_pdfs:
            st.markdown("---")
            st.subheader("üìö Supplemental Resources")
            for i, pdf in enumerate(extra_pdfs):
                c1, c2 = st.columns([4, 1])
                with c1:
                    st.markdown(f"üìÑ **{pdf['name']}**")
                with c2:
                    if st.button("Open", key=f"extra_pdf_{i}_{pdf['name']}"):
                        try:
                            os.startfile(pdf['path'])
                            st.toast(f"Opening {pdf['name']}...", icon="üöÄ")
                        except Exception as e:
                            st.error(f"Cannot open PDF: {e}")

elif page == "Old Exams üìÑ":
    st.header("Old Exam Papers üìÑ")
    
    # Path to EXAM folder
    # platform/app.py -> platform/EXAM
    base_dir = os.path.dirname(os.path.abspath(__file__))
    exam_dir = os.path.join(base_dir, 'EXAM')
    metadata_file = os.path.join(base_dir, 'exam_metadata.json')
    
    metadata = {}
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
        except Exception as e:
            st.error(f"Error loading metadata: {e}")

    if not os.path.exists(exam_dir):
        st.error(f"EXAM directory not found at: {exam_dir}")
    else:
        # --- Vocab Analysis Section ---
        vocab_file = os.path.join(base_dir, 'exam_vocab.json')
        if os.path.exists(vocab_file):
            with st.expander("üìä Exam Vocabulary Analysis (Tangocho)", expanded=False):
                st.info("Top frequent words extracted from actual exam papers. Master these!")
                
                try:
                    with open(vocab_file, "r", encoding="utf-8") as f:
                        exam_vocab = json.load(f)
                    
                    # Subject selector
                    subjects = list(exam_vocab.keys())
                    if subjects:
                        selected_subject = st.selectbox("Select Subject for Vocabulary", subjects)
                        
                        if selected_subject:
                            words = exam_vocab[selected_subject]
                            
                            # Display as a dataframe or cloud
                            # Create a nice dataframe
                            df_vocab = pd.DataFrame(words)
                            df_vocab.columns = ["Word", "Frequency"]
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.dataframe(df_vocab, use_container_width=True, height=400)
                                
                            with col2:
                                if not df_vocab.empty:
                                    st.markdown("### Top Keywords")
                                    # Create a bar chart
                                    fig = px.bar(
                                        df_vocab.head(20), 
                                        x='Frequency', 
                                        y='Word', 
                                        orientation='h',
                                        title=f"Top 20 Words in {selected_subject}",
                                        color='Frequency',
                                        color_continuous_scale='Viridis'
                                    )
                                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"Error loading vocabulary: {e}")
        
        st.divider()

        files = [f for f in os.listdir(exam_dir) if f.lower().endswith('.pdf')]
        
        if not files:
            st.warning("No PDF exam papers found.")
        else:
            st.write(f"Found {len(files)} exam papers.")
            
            # Sort by filename to keep subjects grouped (01, 02, ...)
            for f in sorted(files):
                info = metadata.get(f, {})
                display_title = f"**{f}**"
                sub_info = ""
                
                if info:
                    # Construct nice title
                    # e.g. R7 Short-Answer (Tanto) I - Corporate Law (‰ºÅÊ•≠Ê≥ï)
                    year = info.get('year', '')
                    exam_type = info.get('type', '')
                    subject = info.get('subject', '')
                    
                    # Create a clean badge-like string
                    display_title = f"**{subject}** - {year} {exam_type}"
                    sub_info = f"Filename: {f}"
                
                with st.container():
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"üìÑ {display_title}")
                        if sub_info:
                            st.caption(sub_info)
                    with col2:
                        if st.button("Open", key=f"open_exam_{f}"):
                            try:
                                file_path = os.path.join(exam_dir, f)
                                if os.name == 'nt':
                                    os.startfile(file_path)
                                    st.toast(f"Opening {f}...", icon="üöÄ")
                                else:
                                    st.warning("File opening is only supported on Windows locally.")
                            except Exception as e:
                                st.error(f"Error opening file: {e}")
                    st.divider()
            
            st.info("üí° Tip: Use these papers to practice time management.")

elif page == "Study Timer":
    st.header("Study Timer")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Log Study Session")
        with st.form("timer_form"):
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective"])
            duration = st.number_input("Duration (minutes)", min_value=1, value=60)
            date_val = st.date_input("Date", value=date.today())
            submitted = st.form_submit_button("Log Session")
            
            if submitted:
                new_log = {
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'duration': duration
                }
                st.session_state.data["logs"].append(new_log)
                save_data(st.session_state.data)
                st.success("Session logged!")
                
    with col2:
        st.subheader("Recent Logs")
        if st.session_state.data["logs"]:
            df_logs = pd.DataFrame(st.session_state.data["logs"])
            st.dataframe(df_logs.sort_values('date', ascending=False))
            
            total_mins = df_logs['duration'].sum()
            hours = total_mins // 60
            mins = total_mins % 60
            st.metric("Total Study Time", f"{hours}h {mins}m")
        else:
            st.info("No logs yet.")

elif page == "Mock Exams":
    st.header("Mock Exam Schedule")
    df_exams = pd.DataFrame(mock_exams)
    st.table(df_exams)

elif page == "Scores":
    st.header("Score Tracker")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        with st.form("score_form"):
            name = st.text_input("Exam/Drill Name")
            date_val = st.date_input("Date", value=date.today())
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective", "Total"])
            val = st.number_input("Score (%)", min_value=0, max_value=100, value=70)
            submitted = st.form_submit_button("Save Score")
            
            if submitted:
                new_score = {
                    'name': name,
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'val': val
                }
                st.session_state.data["scores"].append(new_score)
                save_data(st.session_state.data)
                st.success("Score saved!")
                
    with col2:
        if st.session_state.data["scores"]:
            df = pd.DataFrame(st.session_state.data["scores"])
            st.subheader("History")
            st.dataframe(df.sort_values('date', ascending=False))
            
            # Line Chart
            st.subheader("Trend")
            fig = go.Figure()
            for sub in df['subject'].unique():
                sub_df = df[df['subject'] == sub].sort_values('date')
                fig.add_trace(go.Scatter(x=sub_df['date'], y=sub_df['val'], mode='lines+markers', name=sub))
            fig.update_layout(yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No scores recorded yet.")

elif page == "Drills":
    st.header("Drills ‚úèÔ∏è")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("Select Topic")
        subject = st.radio("Subject", ["Financial", "Management", "Audit", "Company"])
        
        st.subheader("Select Level")
        level = st.radio("Level", ["Level 1 (Basic)", "Level 2 (Standard)", "Level 3 (Advanced)", "Vocabulary (Important Words)"])
        level_map = {
            "Level 1 (Basic)": 1, 
            "Level 2 (Standard)": 2, 
            "Level 3 (Advanced)": 3,
            "Vocabulary (Important Words)": "vocab"
        }
        selected_level = level_map[level]
        
        if selected_level == "vocab":
            st.info("üí° Hint: These are key English terms often found in global accounting standards (IFRS/US GAAP).")
    
        # Load generated questions if available and not already loaded
        if 'generated_questions' not in st.session_state:
            try:
                with open('questions.json', 'r', encoding='utf-8') as f:
                    st.session_state.generated_questions = json.load(f)
            except FileNotFoundError:
                st.session_state.generated_questions = {}

        if st.button("Start / Restart Quiz"):
            import random
            st.session_state.quiz_state['active'] = True
            st.session_state.quiz_state['subject'] = subject
            st.session_state.quiz_state['level'] = selected_level
            st.session_state.quiz_state['q_index'] = 0
            st.session_state.quiz_state['score'] = 0
            st.session_state.quiz_state['show_feedback'] = False
            st.session_state.quiz_state['selected_option'] = None
            
            # Select questions based on level
            if selected_level == "vocab":
                vocab_list = vocab_data.get(subject, [])
                if vocab_list:
                    vocab_questions = []
                    for v in vocab_list:
                        vocab_questions.append({
                            'q': f"„ÄêÈáçË¶ÅË™ûÂè•„Äë „Äå{v['term']}„Äç „ÅÆÊÑèÂë≥„Å®„Åó„Å¶ÊúÄ„ÇÇÈÅ©Âàá„Å™„ÇÇ„ÅÆ„ÅØÔºü",
                            'options': [v['desc'], "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: ÈÄÜ„ÅÆÊÑèÂë≥Ôºâ", "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: ÁÑ°Èñ¢‰øÇ„Å™ÂÆöÁæ©Ôºâ", "ÔºàË™§„Çä„ÅÆÈÅ∏ÊäûËÇ¢: È°û‰ººÁî®Ë™û„ÅÆÂÆöÁæ©Ôºâ"],
                            'correct': 0,
                            'explanation': f"**{v['term']} ({v['jp']})**\n\n{v['desc']}",
                            'type': 'vocab'
                        })
                    # Shuffle options for each question
                    for q in vocab_questions:
                        correct_opt = q['options'][0]
                        random.shuffle(q['options'])
                        q['correct'] = q['options'].index(correct_opt)
                    
                    st.session_state.quiz_state['questions'] = vocab_questions
                else:
                    st.warning(f"No vocabulary data for {subject} yet.")
                    st.session_state.quiz_state['active'] = False
            
            elif selected_level == 2 or selected_level == 3:
                # Use generated questions for Level 2/3
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level_gen_qs = [q for q in gen_qs if q.get('level') == selected_level]
                
                if level_gen_qs:
                     # Pick 10 random questions
                    if len(level_gen_qs) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(level_gen_qs, 10)
                    else:
                        st.session_state.quiz_state['questions'] = level_gen_qs
                else:
                    st.warning(f"No generated questions for {subject} Level {selected_level} yet.")
                    st.session_state.quiz_state['active'] = False

            else:
                # Level 1 (Static questions)
                raw_questions = drill_questions.get(subject, [])
                # Filter for Level 1 or undefined (legacy)
                filtered_questions = [q for q in raw_questions if q.get('level', 1) == 1]
                
                if filtered_questions:
                    st.session_state.quiz_state['questions'] = filtered_questions
                else:
                    st.warning(f"No questions found for {subject} Level 1.")
                    st.session_state.quiz_state['active'] = False
                
    with col2:
        qs = st.session_state.quiz_state
        if qs['active']:
            current_q = qs['questions'][qs['q_index']]
            total_q = len(qs['questions'])
            
            st.subheader(f"Question {qs['q_index'] + 1} / {total_q}")
            st.markdown(f"**{current_q['q']}**")
            
            # Options
            options = current_q['options']
            
            # If feedback is shown, disable interaction or show result
            if qs['show_feedback']:
                for idx, opt in enumerate(options):
                    if idx == current_q['correct']:
                        st.markdown(f"<div class='correct-answer'>{opt} (Correct)</div>", unsafe_allow_html=True)
                    elif idx == qs['selected_option']:
                        st.markdown(f"<div class='incorrect-answer'>{opt} (Your Answer)</div>", unsafe_allow_html=True)
                    else:
                        st.text(opt)
                
                st.markdown("### Explanation")
                st.info(current_q['explanation'])
                
                if qs['q_index'] < total_q - 1:
                    if st.button("Next Question"):
                        qs['q_index'] += 1
                        qs['show_feedback'] = False
                        qs['selected_option'] = None
                        st.rerun()
                else:
                    score = qs['score']
                    st.success(f"Quiz Completed! Score: {score} / {total_q}")
                    
                    if st.button("Finish & Claim XP"):
                        # XP Logic
                        earned_xp = score * 10
                        current_xp = st.session_state.data.get('xp', 0)
                        current_level = st.session_state.data.get('level', 1)
                        
                        new_xp = current_xp + earned_xp
                        required_xp = current_level * 100
                        
                        leveled_up = False
                        while new_xp >= required_xp:
                            new_xp -= required_xp
                            current_level += 1
                            required_xp = current_level * 100
                            leveled_up = True
                        
                        st.session_state.data['xp'] = new_xp
                        st.session_state.data['level'] = current_level
                        
                        # Save score history
                        st.session_state.data["scores"].append({
                            'name': f"Drill: {qs.get('subject', 'General')} Lv{qs.get('level', '?')}",
                            'date': date.today().strftime("%Y-%m-%d"),
                            'subject': qs.get('subject', 'General'),
                            'val': (score / total_q) * 100 if total_q > 0 else 0
                        })
                        save_data(st.session_state.data)
                        
                        if leveled_up:
                            st.balloons()
                            st.success(f"LEVEL UP! You are now Level {current_level}!")
                        else:
                            st.success(f"Earned {earned_xp} XP!")
                            
                        qs['active'] = False
                        st.rerun()
                        
            else:
                choice = st.radio("Choose Answer:", options, index=None, key=f"q_{qs['q_index']}")
                if st.button("Submit Answer"):
                    if choice:
                        selected_idx = options.index(choice)
                        qs['selected_option'] = selected_idx
                        qs['show_feedback'] = True
                        if selected_idx == current_q['correct']:
                            qs['score'] += 1
                        st.rerun()
                    else:
                        st.warning("Please select an option.")
        else:
            st.info("Select a subject and level from the sidebar to start.")

elif page == "Survival Mode ‚ö°":
    st.header("‚ö° Survival Mode")
    st.markdown("### Challenge your limits! 3 Strikes and you're out.")
    
    # Initialize State
    if 'survival' not in st.session_state:
        st.session_state.survival = {
            'active': False,
            'lives': 3,
            'streak': 0,
            'score': 0,
            'q': None,
            'feedback': False,
            'user_ans': None,
            'target_streak': "Unlimited"
        }
    
    ss = st.session_state.survival
    
    # Load Questions Logic
    if 'all_questions' not in st.session_state:
        all_qs = []
        # Static
        for sub, qs in drill_questions.items():
            for q in qs:
                # Create a copy to avoid modifying original
                q_copy = q.copy()
                q_copy['subject'] = sub
                all_qs.append(q_copy)
        # Generated
        json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
        if os.path.exists(json_path):
             try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gen_qs = json.load(f)
                    for sub, qs in gen_qs.items():
                        for q in qs:
                            q_copy = q.copy()
                            q_copy['subject'] = sub
                            all_qs.append(q_copy)
             except:
                 pass
        st.session_state.all_questions = all_qs
    
    if not ss['active']:
        st.subheader("Select Challenge Mode")
        streak_target = st.radio("Target Streak", ["Unlimited", 1, 5, 10], horizontal=True, format_func=lambda x: "‚àû Unlimited" if x == "Unlimited" else f"Target: {x} üî•")

        if st.button("üöÄ Start Challenge", use_container_width=True):
            ss['active'] = True
            ss['lives'] = 3
            ss['streak'] = 0
            ss['score'] = 0
            ss['q'] = None
            ss['feedback'] = False
            ss['target_streak'] = streak_target
            st.rerun()
            
    else:
        # Metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("Lives", "‚ù§Ô∏è" * ss['lives'])
        target_display = "‚àû" if ss.get('target_streak', "Unlimited") == "Unlimited" else ss['target_streak']
        c2.metric("Streak", f"üî• {ss['streak']} / {target_display}")
        c3.metric("Score", ss['score'])
        
        target = ss.get('target_streak', "Unlimited")
        is_win = target != "Unlimited" and ss['streak'] >= target

        if ss['lives'] <= 0 or is_win:
            if is_win:
                st.balloons()
                st.success(f"üéâ MISSION ACCOMPLISHED! You reached a {ss['streak']} streak!")
            else:
                st.error("üíÄ GAME OVER")
            
            st.markdown(f"### Final Score: {ss['score']}")
            
            # Save High Score
            if ss['score'] > 0:
                st.session_state.data["scores"].append({
                    'name': f"Survival Mode ‚ö° (Target {target})",
                    'date': date.today().strftime("%Y-%m-%d"),
                    'subject': 'Survival',
                    'val': ss['score'] # Just storing score
                })
                save_data(st.session_state.data)
            
            if st.button("Try Again", use_container_width=True):
                ss['active'] = False
                st.rerun()
        else:
            # Get Question
            if ss['q'] is None:
                import random
                if st.session_state.all_questions:
                    q_data = random.choice(st.session_state.all_questions)
                    # Shuffle options
                    opts = q_data['options'].copy()
                    correct_text = q_data['options'][q_data['correct']]
                    random.shuffle(opts)
                    
                    ss['q'] = {
                        'q': q_data['q'],
                        'options': opts,
                        'correct_idx': opts.index(correct_text),
                        'explanation': q_data['explanation'],
                        'subject': q_data.get('subject', 'General')
                    }
                else:
                    st.error("No questions found!")
                    st.stop()
            
            q = ss['q']
            
            st.markdown(f"**[{q['subject']}]** {q['q']}")
            
            if not ss['feedback']:
                # Use a form to prevent reload on radio selection
                with st.form(key=f"surv_form_{ss['score']}_{ss['lives']}"):
                    ans = st.radio("Select Answer:", q['options'])
                    submit = st.form_submit_button("Submit Answer")
                    
                    if submit:
                        ss['user_ans'] = q['options'].index(ans)
                        ss['feedback'] = True
                        
                        if ss['user_ans'] == q['correct_idx']:
                            # Bonus XP for streak
                            bonus = ss['streak'] * 2
                            points = 10 + bonus
                            ss['score'] += points
                            ss['streak'] += 1
                            st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + points
                            st.toast(f"Correct! +{points} XP", icon="‚úÖ")
                            
                            # Check Win
                            target = ss.get('target_streak', "Unlimited")
                            if target != "Unlimited" and ss['streak'] >= target:
                                st.rerun()
                        else:
                            ss['lives'] -= 1
                            ss['streak'] = 0
                            st.toast("Wrong Answer!", icon="‚ùå")
                        
                        st.rerun()
            else:
                # Show Feedback
                if ss['user_ans'] == q['correct_idx']:
                    st.success("‚úÖ Correct!")
                else:
                    st.error(f"‚ùå Wrong! Correct: {q['options'][q['correct_idx']]}")
                
                st.info(f"**Explanation:**\n\n{q['explanation']}")
                
                if st.button("Next Question ‚û°", use_container_width=True):
                    ss['q'] = None
                    ss['feedback'] = False
                    st.rerun()

elif page == "Roadmap":
    st.header("üó∫Ô∏è CPA Exam Strategy Roadmap (2026-2027)")
    
    # 1. Countdown Section
    today = date.today()
    tanto_date = date(2027, 5, 23) # Estimated
    ronbun_date = date(2027, 8, 20) # Estimated
    
    days_tanto = (tanto_date - today).days
    days_ronbun = (ronbun_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Days to May Short Exam", f"{days_tanto} Days", "Target: Pass")
    col2.metric("Days to Aug Essay Exam", f"{days_ronbun} Days", "Final Goal")
    col3.metric("Current Phase", "Foundation (2026)", "Build Habits")
    
    st.divider()

    # 2. Tabs
    tab1, tab2, tab3 = st.tabs(["üìä Visual Schedule (Gantt)", "üóìÔ∏è Monthly Strategy", "‚è∞ Daily Routine"])
    
    with tab1:
        st.subheader("Strategic Timeline")
        # Gantt Chart Data
        df_gantt = pd.DataFrame([
            dict(Task="Foundation (Fin/Mgmt)", Start='2026-02-01', Finish='2026-06-30', Phase='Phase 0: Foundation'),
            dict(Task="Audit & Company Law", Start='2026-04-01', Finish='2026-09-30', Phase='Phase 0: Foundation'),
            dict(Task="Tax Law & Electives", Start='2026-07-01', Finish='2026-12-31', Phase='Phase 0: Foundation'),
            dict(Task="Dec Short (Practice)", Start='2026-10-01', Finish='2026-12-13', Phase='Phase 0: Foundation'),
            dict(Task="Short Exam Mastery", Start='2027-01-01', Finish='2027-05-23', Phase='Phase 1: Short Exam'),
            dict(Task="Essay Sprint", Start='2027-05-24', Finish='2027-08-20', Phase='Phase 2: Essay Sprint'),
        ])
        
        # Create Gantt
        fig = px.timeline(df_gantt, x_start="Start", x_end="Finish", y="Task", color="Phase", 
                          title="CPA Exam 1.5 Year Plan",
                          color_discrete_sequence=px.colors.qualitative.Prism)
        fig.update_yaxes(autorange="reversed") # Task order top-to-bottom
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("üí° **Golden Route**: Pass May Short -> Pass August Essay in one go.")

    with tab2:
        st.subheader("Detailed Monthly Strategy")
        
        with st.expander("Phase 0: Foundation (2026)", expanded=True):
            st.markdown("""
            *   **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics (Calculations).
            *   **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
            *   **Jul - Sep**: **CRITICAL** Start Tax Law & Electives (Management/Statistics).
            *   **Oct - Dec**: **Dec Short Exam Challenge**. Aim for 60%+ even if you fail.
            """)
            
        with st.expander("Phase 1: Short Exam Mastery (Jan - May 2027)"):
            st.markdown("""
            *   **Jan - Mar**: Solidify basics. Aim for 75%+ in drills. Focus on weak areas.
            *   **Apr**: Mock Exams (TAC/Ohara). Analyze errors thoroughly.
            *   **May**: Peak conditioning. Rote memorization of text (Audit/Company Law). **PASS EXAM**.
            """)
            
        with st.expander("Phase 2: Essay Sprint (Jun - Aug 2027)"):
            st.markdown("""
            *   **Jun**: Revive Tax/Elective knowledge (often forgotten during Short prep).
            *   **Jul**: Output training (Writing). Learn "Key Phrases" for theory questions.
            *   **Aug**: Final adjustments. Health management is key. **PASS EXAM**.
            """)

    with tab3:
        st.subheader("‚è∞ Ideal Daily Routine (Student/Full-time Study)")
        
        schedule_data = [
            {"Time": "07:00 - 08:00", "Activity": "Wake up / Light Breakfast / Review Vocab"},
            {"Time": "08:00 - 11:00", "Activity": "üß† **Deep Work 1**: Financial Accounting (Calc) - 3h"},
            {"Time": "11:00 - 12:00", "Activity": "Lunch / Nap (20m)"},
            {"Time": "12:00 - 15:00", "Activity": "üß† **Deep Work 2**: Management Accounting / Theory - 3h"},
            {"Time": "15:00 - 16:00", "Activity": "Gym / Walk / Break"},
            {"Time": "16:00 - 19:00", "Activity": "üß† **Deep Work 3**: Corporate Law / Audit - 3h"},
            {"Time": "19:00 - 20:00", "Activity": "Dinner / Relax"},
            {"Time": "20:00 - 22:00", "Activity": "üìñ **Review**: Weak areas / Next day planning - 2h"},
            {"Time": "22:00 - 23:00", "Activity": "Wind down / Sleep"},
        ]
        st.table(pd.DataFrame(schedule_data))
        st.success("Target: **10+ Hours/Day** of high-quality study.")

elif page == "Big 4 Job Hunting":
    st.header("üè¢ Big 4 CPA Job Hunting Strategy")
    st.markdown("Strategy guide and comparison for the major audit firms in Japan.")

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["Strategy & Timeline", "Big 4 Comparison", "Tech & Data Science Advantage ü§ñ", "Boston Career Forum üá∫üá∏", "Interview & Case Prep üìù"])

    with tab1:
        st.subheader("üìÖ Job Hunting Timeline (Typical)")
        st.info("The job hunting season for CPA candidates peaks immediately after the August Essay Exam.")
        
        timeline_data = [
            {"Period": "August (Late)", "Activity": "Essay Exam Ends", "Details": "Rest for a few days, then prepare for briefings."},
            {"Period": "September", "Activity": "Firm Briefings (Setsumeikai)", "Details": "Attend online/offline sessions. Key for networking."},
            {"Period": "October", "Activity": "Entry Sheet (ES) Submission", "Details": "Prepare resumes. Focus on 'Why this firm?'"},
            {"Period": "November (Mid)", "Activity": "Results Announcement", "Details": "Official passing results released."},
            {"Period": "November (Late)", "Activity": "Interviews & Offers", "Details": "Intensive interview period (1-2 weeks). Offers issued quickly."}
        ]
        st.table(pd.DataFrame(timeline_data))

        st.subheader("üí° Key Strategies")
        st.markdown("""
        *   **Start Early**: Don't wait for the results. Attend briefings in September.
        *   **Differentiate**: All Big 4 do audit. Focus on culture, specific clients (e.g., Tech, Auto), or non-audit opportunities (IPO, Advisory).
        *   **Networking**: Use alumni connections (OB/OG Visits) if possible.
        """)

    with tab2:
        st.subheader("üìä Big 4 Audit Firms vs. Tech Giants Comparison")
        
        # Personalized Ranking Section
        st.markdown("### üèÜ Personalized Ranking for You (ML/DS Master's Student)")
        st.info("""
        Based on your **CPA Goal** + **ML/Data Science Strength**, here is your recommended priority:
        
        1.  ü•á **PwC Aarata / EY ShinNihon**: Best balance of **Digital Audit** innovation and **CPA License** support. Both have dedicated "Digital" tracks for auditors.
        2.  ü•à **Deloitte Tohmatsu**: Massive scale and data access. Great for "Audit Analytics" but slightly more traditional hierarchy.
        3.  ü•â **Accenture / IBM**: **Top Tier for Tech**, but ‚ö†Ô∏è **WARNING**: You likely **cannot** complete the CPA practical experience (Jitsumu Hoshu) requirement here. Great for *after* getting your CPA, or if you pivot to Consulting.
        """)

        # Radar Chart
        st.subheader("Visual Comparison (Illustrative)")
        categories = ['Tech/AI Focus', 'Global Network', 'Domestic Scale', 'IPO/Venture', 'Work-Life Balance']

        fig = go.Figure()

        # Tohmatsu (Deloitte)
        fig.add_trace(go.Scatterpolar(
            r=[4, 5, 5, 5, 3],
            theta=categories,
            fill='toself',
            name='Tohmatsu (Deloitte)'
        ))
        # AZSA (KPMG)
        fig.add_trace(go.Scatterpolar(
            r=[3, 4, 5, 3, 4],
            theta=categories,
            fill='toself',
            name='AZSA (KPMG)'
        ))
        # EY ShinNihon
        fig.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 3, 3],
            theta=categories,
            fill='toself',
            name='EY ShinNihon'
        ))
        # PwC Aarata
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 3, 2, 4],
            theta=categories,
            fill='toself',
            name='PwC Aarata'
        ))
        # Accenture (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 2, 2],
            theta=categories,
            fill='toself',
            name='Accenture (Ref)'
        ))
        # IBM (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 4, 1, 4],
            theta=categories,
            fill='toself',
            name='IBM (Ref)'
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5]
                )),
            showlegend=True,
            height=500,
            margin=dict(l=40, r=40, t=20, b=20)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("üè¢ Firm Details")
        firms_data = [
            {
                "Firm Name (JP)": "ÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫„Éà„Éº„Éû„ÉÑ (Tohmatsu)",
                "Network": "Deloitte",
                "Key Strengths": "Largest scale, aggressive growth, strong in IPOs and Venture support.",
                "Culture": "Meritocratic, Sports-oriented, High energy.",
                "Link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"
            },
            {
                "Firm Name (JP)": "ÊúâÈôêË≤¨‰ªª „ÅÇ„Åö„ÅïÁõ£ÊüªÊ≥ï‰∫∫ (AZSA)",
                "Network": "KPMG",
                "Key Strengths": "Balanced portfolio, strong domestic manufacturing clients.",
                "Culture": "Conservative, Collaborative, 'Gentlemanly'.",
                "Link": "https://home.kpmg/jp/ja/home/careers.html"
            },
            {
                "Firm Name (JP)": "EYÊñ∞Êó•Êú¨ÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫ (EY ShinNihon)",
                "Network": "EY",
                "Key Strengths": "Long history, large number of listed clients, strong Digital Audit focus.",
                "Culture": "Traditional yet transforming, Diversity focus.",
                "Link": "https://www.ey.com/ja_jp/careers/audit"
            },
            {
                "Firm Name (JP)": "PwC„ÅÇ„Çâ„ÅüÊúâÈôêË≤¨‰ªªÁõ£ÊüªÊ≥ï‰∫∫ (PwC Aarata)",
                "Network": "PwC",
                "Key Strengths": "Global integration, strong advisory connection, newer organizational style.",
                "Culture": "Global, Flat hierarchy, Innovative.",
                "Link": "https://www.pwc.com/jp/ja/careers/audit.html"
            },
            {
                "Firm Name (JP)": "„Ç¢„ÇØ„Çª„É≥„ÉÅ„É•„Ç¢ (Accenture)",
                "Network": "Accenture",
                "Key Strengths": "Absolute leader in DX/IT Consulting. High salary.",
                "Culture": "Up or Out (Evolving), High performance, Tech-first.",
                "Link": "https://www.accenture.com/jp-ja/careers"
            },
            {
                "Firm Name (JP)": "Êó•Êú¨IBM (IBM Japan)",
                "Network": "IBM",
                "Key Strengths": "Deep research (Watson), Hybrid Cloud, Legacy stability.",
                "Culture": "Engineering-driven, Mature, Good work-life balance.",
                "Link": "https://www.ibm.com/jp-ja/employment"
            }
        ]
        
        # Display as a styled table or cards
        for firm in firms_data:
            with st.expander(f"{firm['Firm Name (JP)']} ({firm['Network']})", expanded=True):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**Strengths:** {firm['Key Strengths']}")
                    st.markdown(f"**Culture:** {firm['Culture']}")
                with col2:
                    st.link_button("Recruit Page", firm['Link'])
    
    with tab3:
        st.subheader("ü§ñ Leveraging Data Science & ML in CPA Job Hunting")
        st.markdown("""
        **Profile:** Double Degree Master's Student (Keio üáØüáµ & Leibniz Hannover üá©üá™) | **Major:** Mechanical Engineering
        
        **Your Technical Arsenal:**
        *   **Advanced ML:** Graph Neural Networks (GNNs), PyTorch, Bayesian Inference (MCMC/TMCMC).
        *   **Engineering:** Finite Element Analysis (FEA), Structural Health Monitoring.
        *   **Languages:** Python, MATLAB, TypeScript.
        
        Your background is a **massive differentiator** in the modern audit industry. All Big 4 firms are heavily investing in "Audit Transformation" and "Digital Audit".
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üéØ Target Roles")
            st.success("**1. Digital Audit Specialist**")
            st.markdown("Work at the intersection of Audit and Tech. Use Python/SQL to analyze full population data instead of sampling.")
            
            st.success("**2. AI Governance / Algorithm Assurance**")
            st.markdown("Audit AI models! With your GNN/Bayesian background, you can audit complex *algorithms* themselves, not just the financial numbers.")
            
            st.success("**3. Financial Advisory (FAS) - Forensics**")
            st.markdown("Your experience in 'Defect Localization' translates perfectly to **Fraud Detection** (finding anomalies in massive datasets).")

        with col2:
            st.markdown("### üí° Strategic Actions")
            st.info("**Resume / Entry Sheet (ES)**")
            st.markdown("*   **Highlight Research**: Explicitly mention your GNN work for Aerospace/CFRP. It shows you can handle *complex, unstructured data*.")
            st.markdown("*   **Keywords**: `PyTorch`, `Bayesian Inference`, `Uncertainty Quantification`, `End-to-End Pipelines`.")
            
            st.info("**Interview Questions to Ask**")
            st.markdown("*   *\"How can I apply Bayesian methods to audit risk assessment?\"*\n*   *\"Does your firm analyze unstructured data (like contracts/images) using GNNs or NLP?\"*")
            
            st.info("**Firm-Specific Tech Vibes**")
            st.markdown("""
            *   **EY**: Very strong brand in "Digital Audit". Has "EY Digital" specific recruiting tracks.
            *   **PwC**: Strong on "Tech-enablement". "Digital Upskilling" for all staff is a key slogan.
            *   **Deloitte**: "Audit Analytics" is a core part of their massive scale.
            *   **KPMG**: "Digital Innovation" focus, often collaborative with their consulting arm.
            """)

    with tab4:
        st.subheader("üá∫üá∏ Boston Career Forum (BCF)")
        st.markdown("The world's largest job fair for Japanese-English bilinguals. **Crucial for Master's students.**")
        
        st.info("üí° **Why BCF for You?**\n*   **Speed**: Offers (Naitei) often given in 3 days (Fri-Sun).\n*   **Positions**: Big 4 hires for **Advisory/Consulting** heavily here, not just Audit.\n*   **Timing**: Held in November, aligning perfectly with post-essay exam period.")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üìÖ Timeline")
            st.markdown("""
            *   **Aug-Sep**: Registration & Resume Upload.
            *   **Sep-Oct**: Online Applications & Skype Interviews (Pre-event).
            *   **Nov (Event)**: Walk-ins (Risky) vs. Scheduled Interviews (Safe).
            """)
        with col2:
            st.markdown("### üéØ Strategy")
            st.markdown("""
            *   **Pre-Event is King**: Secure interviews *before* flying to Boston.
            *   **Target**: Big 4 (US & Japan offices), Consulting (MBB/Accenture), Tech.
            *   **Dinner Invitations**: If you do well, you get invited to dinner. This is effectively the final interview.
            """)
        st.link_button("BCF Official Site", "https://careerforum.net/en/event/bos/")

    with tab5:
        st.subheader("üìù Interview & Case Prep: The 'Master' Level")
        
        st.info("üí° **Goal**: Move beyond 'prepared answers'. Show **Intellectual Curiosity** and **Professional Maturity**.")

        # --- Interactive Mock Interview ---
        st.markdown("### ü§ñ Mock Interview Simulator")
        mock_mode = st.radio("Select Mode:", ["Behavioral (HR/Partner)", "Technical (Audit/Accounting)", "Case/Logic (Consulting)"], horizontal=True)
        
        if st.button("üé≤ Generate Question"):
            import random
            
            if "Behavioral" in mock_mode:
                q_bank = [
                    {"q": "Why do you want to be a CPA instead of an Engineer?", "hint": "Connect 'Reliability' in Engineering to 'Assurance' in Audit."},
                    {"q": "Why our firm specifically? (Why not others?)", "hint": "Mention specific culture, clients (Tech/Auto), or digital initiatives."},
                    {"q": "Tell me about a time you failed.", "hint": "Focus on the **Lesson Learned** and **Improvement**, not the failure itself."},
                    {"q": "How do you handle disagreement with a team member?", "hint": "Emphasize **Listening**, **Data-driven discussion**, and **Shared Goals**."},
                    {"q": "What is your career plan for the next 5-10 years?", "hint": "Be ambitious but realistic. 'Digital Audit Specialist' -> 'Project Manager'."},
                    {"q": "Describe your research in simple terms to a 10-year-old.", "hint": "Tests communication skills. Avoid jargon. Use analogies."}
                ]
            elif "Technical" in mock_mode:
                q_bank = [
                    {"q": "What is the difference between 'Audit' and 'Advisory'?", "hint": "Audit = Assurance (Past/Present). Advisory = Consulting (Future/Improvement)."},
                    {"q": "Explain 'Materiality' in Audit.", "hint": "The threshold above which a misstatement would influence decision making."},
                    {"q": "How would you audit a company with massive data volumes?", "hint": "ITAC (IT Application Controls) + Data Analytics (Full population testing)."},
                    {"q": "What are the risks of using AI in financial reporting?", "hint": "Black box logic, Bias, Hallucinations, Lack of audit trail."},
                    {"q": "Explain the concept of 'Going Concern'.", "hint": "The assumption that a company will continue operating in the foreseeable future."}
                ]
            else: # Case
                q_bank = [
                    {"q": "Estimate the number of smartphones sold in Japan annually.", "hint": "Pop (125M) x Penetration (80%) / Replacement Cycle (3 years)."},
                    {"q": "A client's profit is down 20%. How do you analyze it?", "hint": "Revenue vs Cost. Price x Vol. Fixed vs Variable. External vs Internal."},
                    {"q": "Should a Japanese auto-maker enter the EV market in India?", "hint": "Market Size, Competition, Regulation, Infrastructure, Capabilities."},
                    {"q": "How would you use AI to improve audit efficiency?", "hint": "Automated document review, Anomaly detection in journals, Chatbot for inquiries."}
                ]
            
            selected = random.choice(q_bank)
            st.session_state['mock_q'] = selected
            st.session_state['show_hint'] = False
        
        if 'mock_q' in st.session_state:
            st.markdown(f"#### ‚ùì Q: {st.session_state['mock_q']['q']}")
            
            if st.button("Show Hint / Direction"):
                st.session_state['show_hint'] = not st.session_state.get('show_hint', False)
                
            if st.session_state.get('show_hint', False):
                st.success(f"üí° **Direction**: {st.session_state['mock_q']['hint']}")
        
        st.divider()

        # --- Detailed Guide ---
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üó£Ô∏è Core Competency Questions (STAR Method)")
            with st.expander("1. Self-Introduction & Why CPA?", expanded=True):
                st.markdown("""
                **The 'Engineer to Auditor' Narrative**:
                *   "I research **Defect Localization** in aerospace structures using **AI**. My job is to find 'hidden cracks' before they cause failure."
                *   "I realized **Audit** is the same concept but for **Business Structures**. I want to use my tech skills to find 'financial cracks' and ensure stability."
                *   **Why**: "Engineering is precise. Accounting is the language of business. I want to combine **Precision + Business Logic**."
                """)
            
            with st.expander("2. Handling Conflict / Teamwork"):
                st.markdown("""
                *   **Situation**: "In a joint research project with 3 others..."
                *   **Task**: "We disagreed on the simulation method (Speed vs Accuracy)."
                *   **Action**: "I didn't argue opinion. I proposed a **small-scale benchmark test** to compare data."
                *   **Result**: "Data showed my method was 2x faster with 99% accuracy. Team agreed based on evidence."
                *   **Key**: You are **Data-Driven** and **Collaborative**.
                """)

        with col2:
            st.markdown("### üôã‚Äç‚ôÇÔ∏è Reverse Questions (Gyakushitsumon)")
            st.info("Asking good questions is more important than giving good answers.")
            
            with st.expander("Level 1: The 'Safe' Questions"):
                st.markdown("""
                *   "What does a typical day look like for a first-year associate?"
                *   "How is the team structure for a typical audit engagement?"
                *   "What kind of training support is available for CPA exam (Jitsumu Hoshu)?"
                """)
                
            with st.expander("Level 2: The 'Interest' Questions"):
                st.markdown("""
                *   "I am interested in the Digital Audit sector. How early can I get involved in data analytics projects?"
                *   "What differentiates a 'High Performer' from an average one in your firm?"
                *   "Can you tell me about the most challenging project you've worked on recently?"
                """)
                
            with st.expander("Level 3: The 'Killer' Questions (Partner Level)"):
                st.markdown("""
                *   "With the rise of AI, how do you see the **business model of Audit** changing in 5 years? Will it shift from 'Time-Charge' to 'Value-Based'?"
                *   "How is the firm preparing for the auditing of **Non-Financial Information** (ESG/Sustainability)? I believe my engineering background could be useful there."
                *   "I want to be a bridge between the Tech team and the Audit team. Is there a career path for a 'Hybrid' professional?"
                """)


elif page == "Company Directory üè¢":
    st.header("üè¢ Company Directory for CPA Candidates")
    st.markdown("A curated list of potential employers in Japan for CPA holders, ranging from Audit to Tech.")

    tab1, tab2, tab3 = st.tabs(["Audit (Big 4 & Mid)", "Consulting & FAS", "Tech & Enterprise"])

    with tab1:
        st.subheader("Big 4 Audit Firms (The Standard Path)")
        big4 = [
            {"name": "Deloitte Touche Tohmatsu", "desc": "Largest scale, aggressive growth. Strong in IPO support.", "link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"},
            {"name": "KPMG AZSA", "desc": "Balanced portfolio, strong manufacturing clients. 'Gentleman' culture.", "link": "https://home.kpmg/jp/ja/home/careers.html"},
            {"name": "EY ShinNihon", "desc": "Longest history, most listed clients. Strong Digital Audit focus.", "link": "https://www.ey.com/ja_jp/careers/audit"},
            {"name": "PwC Aarata / Kyoto", "desc": "Global integration, innovative. PwC Kyoto is famous for high profitability.", "link": "https://www.pwc.com/jp/ja/careers/audit.html"}
        ]
        for c in big4:
            with st.expander(f"ü¶Å {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

        st.divider()
        st.subheader("Mid-Tier Audit Firms (ÂáÜÂ§ßÊâã)")
        st.info("üí° **Why Mid-Tier?** Faster promotion, broader experience (you do everything), better work-life balance.")
        mid_tier = [
            {"name": "Grant Thornton Taiyo (Â§™ÈôΩ)", "desc": "Largest mid-tier. Very growing. Good alternative to Big 4.", "link": "https://www.grantthornton.jp/recruit/"},
            {"name": "Crowe Toyo (Êù±ÈôΩ)", "desc": "Strong in domestic IPOs. Traditional but stable.", "link": "https://www.toyo-audit.or.jp/recruit/"},
            {"name": "BDO Sanyu (‰∏âÂÑ™)", "desc": "Friendly culture. Good international network via BDO.", "link": "https://www.bdo.or.jp/sanyu/recruit/"},
            {"name": "RSM Seiwa (Ê∏ÖÂíå)", "desc": "Mid-sized, focus on healthcare and mid-cap clients.", "link": "https://www.seiwa-audit.or.jp/recruit/"}
        ]
        for c in mid_tier:
            with st.expander(f"üêØ {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab2:
        st.subheader("FAS (Financial Advisory Services)")
        st.info("üí° **High Expertise**: M&A, Valuation, Forensics. Often requires CPA + English/Tech.")
        fas = [
            {"name": "Deloitte Tohmatsu Financial Advisory (DTFA)", "link": "https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/dtfa/dtfa-recruit.html"},
            {"name": "KPMG FAS", "link": "https://home.kpmg/jp/ja/home/careers/fas.html"},
            {"name": "PwC Advisory", "link": "https://www.pwc.com/jp/ja/careers/advisory.html"},
            {"name": "EY Strategy and Transactions", "link": "https://www.ey.com/ja_jp/careers/strategy-and-transactions"}
        ]
        for c in fas:
            st.link_button(f"üíº {c['name']}", c['link'])

        st.divider()
        st.subheader("Consulting Firms")
        st.markdown("Finance transformation, ERP implementation, Strategy.")
        consulting = [
            {"name": "Accenture (Strategy & Consulting)", "desc": "Top tier for DX/IT. High salary, hard work.", "link": "https://www.accenture.com/jp-ja/careers"},
            {"name": "BayCurrent Consulting", "desc": "Rapidly growing Japanese firm. High salary.", "link": "https://www.baycurrent.co.jp/recruit/"},
            {"name": "Nomura Research Institute (NRI)", "desc": "Stable, high salary, strong domestic presence.", "link": "https://www.nri.com/jp/career"},
            {"name": "ABeam Consulting", "desc": "Strong in SAP/ERP. Good for CPAs liking systems.", "link": "https://www.abeam.com/jp/ja/careers"}
        ]
        for c in consulting:
            with st.expander(f"üß† {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab3:
        st.subheader("Tech & Enterprise (CFO Track)")
        st.info("üí° **Business Side**: FP&A, Accounting Manager, IPO Prep.")
        
        tech = [
            {"name": "Google / Amazon / MS (Japan)", "desc": "FP&A roles. Very high English requirement. Competitive.", "link": "https://careers.google.com/"},
            {"name": "Rakuten Group", "desc": "English official language. Massive FinTech ecosystem.", "link": "https://corp.rakuten.co.jp/careers/"},
            {"name": "Line Yahoo", "desc": "Major domestic tech player. Strong benefits.", "link": "https://www.lycorp.co.jp/ja/recruit/"},
            {"name": "Mercari", "desc": "Modern tech culture. Good for ambitious finance pros.", "link": "https://careers.mercari.com/"}
        ]
        st.markdown("#### Tech / Global")
        for c in tech:
            st.markdown(f"**{c['name']}**: {c['desc']} [Link]({c['link']})")

        st.divider()
        st.markdown("#### Trading Companies (Sogo Shosha)")
        shosha = ["Mitsubishi Corp", "Mitsui & Co", "Itochu", "Sumitomo Corp", "Marubeni"]
        st.write(", ".join(shosha))
        st.caption("Extremely competitive. High salary. Global rotations.")


elif page == "Future üöÄ":
    st.header("üöÄ 100-Year Life & Career Plan: The 'Founder' Trajectory")
    st.markdown("Your roadmap from **Master's Student** to **Tech CEO**. A comprehensive simulation of career, wealth, and life milestones.")

    tab1, tab2, tab3, tab4 = st.tabs(["‚è≥ 100-Year Timeline", "üí∞ Wealth & Salary Sim", "ü¶Ñ Entrepreneurship Blueprint", "üíç Life & Family"])

    with tab1:
        st.subheader("The Century Plan (Age 24 - 100)")
        
        timeline_events = [
            {"Age": 24, "Year": 2026, "Phase": "Foundation", "Event": "Master's (Germany/Japan) + CPA Study Start", "Status": "Current"},
            {"Age": 25, "Year": 2027, "Phase": "Foundation", "Event": "Pass CPA Exam (May/Aug) üèÜ", "Status": "Goal"},
            {"Age": 26, "Year": 2028, "Phase": "Foundation", "Event": "Graduation & Join Big 4 (Digital Audit/FAS)", "Status": "Planned"},
            {"Age": 29, "Year": 2031, "Phase": "Growth", "Event": "Promoted to Senior Associate. Lead ML Projects.", "Status": "Planned"},
            {"Age": 30, "Year": 2032, "Phase": "Life", "Event": "Marriage üíç (Target)", "Status": "Life"},
            {"Age": 32, "Year": 2034, "Phase": "Growth", "Event": "Manager Promotion. Deep expertise in AI Governance.", "Status": "Planned"},
            {"Age": 35, "Year": 2037, "Phase": "Launch", "Event": "üöÄ FOUND YOUR COMPANY (AI Audit Firm). Disruption.", "Status": "Dream"},
            {"Age": 40, "Year": 2042, "Phase": "Scale", "Event": "Global Expansion. AI-First Assurance.", "Status": "Dream"},
            {"Age": 45, "Year": 2047, "Phase": "Exit", "Event": "IPO or Strategic Partnership. Financial Freedom.", "Status": "Dream"},
            {"Age": 50, "Year": 2052, "Phase": "Invest", "Event": "Angel Investor for Deep Tech. University Lecturer.", "Status": "Vision"},
            {"Age": 60, "Year": 2062, "Phase": "Legacy", "Event": "Establish Scholarship Foundation.", "Status": "Vision"},
            {"Age": 80, "Year": 2082, "Phase": "Wisdom", "Event": "Write Memoirs. Mentor next gen.", "Status": "Vision"},
            {"Age": 100, "Year": 2102, "Phase": "Complete", "Event": "Die Empty. No regrets.", "Status": "Final"}
        ]
        
        df_timeline = pd.DataFrame(timeline_events)
        st.dataframe(df_timeline, use_container_width=True)
        
        # Visual Timeline
        fig_timeline = px.scatter(df_timeline, x="Year", y="Age", color="Phase", text="Event", title="Life Trajectory", size_max=60)
        fig_timeline.update_traces(textposition='top center')
        fig_timeline.update_layout(height=500)
        st.plotly_chart(fig_timeline, use_container_width=True)

    with tab2:
        st.subheader("üí∞ Financial Simulation: Salary & Asset Growth")
        st.info("Simulating the 'J-Curve' effect of Entrepreneurship vs. Linear Corporate Growth.")
        
        # Simulation Data
        years = list(range(2026, 2060))
        ages = list(range(24, 58))
        
        # Salary Logic
        salary_corp = []
        assets_corp = []
        current_asset = 100  # Initial 1M JPY
        
        for age in ages:
            if age < 26: sal = 0  # Student
            elif age < 30: sal = 600  # Junior
            elif age < 35: sal = 1000 # Manager
            elif age < 40: sal = 1500 # Senior Manager
            else: sal = 2000 # Partner level
            salary_corp.append(sal)
            current_asset += (sal * 0.3) # Save 30%
            current_asset *= 1.04 # 4% Investment return
            assets_corp.append(current_asset)

        # Founder Logic
        salary_founder = []
        assets_founder = []
        founder_asset = 100
        
        for age in ages:
            if age < 35: # Same as corp until 35
                sal = salary_corp[ages.index(age)]
                founder_asset = assets_corp[ages.index(age)]
            elif age == 35: # STARTUP LAUNCH
                sal = 400 # Drop salary to survive
                founder_asset -= 500 # Initial Investment
            elif age < 40: # Early Stage
                sal = 600
                founder_asset += (sal * 0.1) # Low saving
            elif age == 45: # EXIT EVENT
                sal = 5000
                founder_asset += 50000 # 500M JPY Exit
            else: # Investor
                sal = 0
                founder_asset *= 1.05 # 5% return on massive capital
            
            salary_founder.append(sal)
            assets_founder.append(founder_asset)

        # Plot
        df_sim = pd.DataFrame({
            "Year": years,
            "Age": ages,
            "Corp Asset (Safe Path)": assets_corp,
            "Founder Asset (Risk Path)": assets_founder
        })
        
        fig_sim = px.line(df_sim, x="Age", y=["Corp Asset (Safe Path)", "Founder Asset (Risk Path)"], 
                          title="Asset Accumulation Simulation (Unit: 10k JPY)", markers=True)
        st.plotly_chart(fig_sim, use_container_width=True)
        
        st.warning("‚ö†Ô∏è **The Founder Gap**: Notice the dip at age 35. That is the 'Valley of Death'. You need ~10M JPY liquidity before launching.")

    with tab3:
        st.subheader("ü¶Ñ Entrepreneurship Blueprint: 'Next-Gen AI Audit Firm'")
        
        st.info("üí° **Why AI Audit Firm > SaaS?**")
        st.markdown("""
        *   **SaaS Weakness**: High churn, low barrier to entry, "race to the bottom" pricing. Anyone can build a tool.
        *   **Audit Strength**: **Regulatory Moat**. Only licensed firms can sign off on financial statements. High switching costs.
        *   **The Opportunity**: Build a **Tech-Enabled Audit Firm** (Service + Tech) that operates at 10x efficiency of Big 4, undercutting their fees while maintaining higher margins.
        """)

        st.markdown("""
        **Vision**: Replace the "Army of Associates" with **Autonomous AI Agents**. Focus on high-level judgement and client relationships.
        
        **Phase 1: The "Insider" (Age 26-34)**
        *   **Goal**: Become a domain expert (CPA License is the Key). Understand *exactly* where the inefficiencies are in Big 4.
        *   **Action**: Lead "Digital Transformation" projects. Learn the *regulatory constraints* inside out.
        
        **Phase 2: The "Prototype" (Age 34-35)**
        *   **Goal**: Build the "AI Auditor" (Internal Tool).
        *   **Tech**: RAG (Retrieval Augmented Generation) for accounting standards, GNNs for transaction anomaly detection.
        *   **Team**: You (CTO/CEO) + Experienced Audit Partner (for credibility/signing).
        
        **Phase 3: The "Disruption" (Age 35+)**
        *   **Target**: Mid-cap public companies (tired of high Big 4 fees).
        *   **Product**: **"AI-First Statutory Audit"**. 
        *   **Value Prop**: "Faster audit, lower fees, deeper insights." Not just a software tool, but the *full service*.
        """)

    with tab4:
        st.subheader("üíç Life, Family & Happiness")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üë®‚Äçüë©‚Äçüëß Family Goals")
            st.write("*   **Age 30**: Marriage (Partner who understands the startup grind).")
            st.write("*   **Age 32**: First Child.")
            st.write("*   **Age 35**: Second Child (Coincides with Startup Launch - Tough!).")
            st.write("*   **Policy**: Weekends are for family. No work on Sundays.")
            
        with col2:
            st.markdown("### ‚úàÔ∏è Experiences")
            st.write("*   **20s**: Backpacking Europe/Asia (Cheap travel).")
            st.write("*   **30s**: Family trips to Hawaii/Okinawa.")
            st.write("*   **40s**: World Cruise (Post-Exit).")
            st.write("*   **Hobbies**: Hiking, Coding, Wine Tasting.")


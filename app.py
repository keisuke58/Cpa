import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date, timedelta
import json
import os

# Set page config
st.set_page_config(page_title="CPA Perfect Platform 2027", layout="wide", page_icon="ğŸ“š")

# Data Persistence
DATA_FILE = "cpa_data.json"

def load_data():
    defaults = {"scores": [], "logs": [], "xp": 0, "level": 1, "badges": [], "wrong_answers": [], "retry": []}
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                # Merge defaults for backward compatibility
                for k, v in defaults.items():
                    if k not in data:
                        data[k] = v
                return data
            except:
                return defaults
    return defaults

def save_data(data):
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Initialize Session State
if 'data' not in st.session_state:
    st.session_state.data = load_data()

if 'quiz_state' not in st.session_state:
    st.session_state.quiz_state = {
        'active': False,
        'subject': None,
        'level': None,
        'q_index': 0,
        'score': 0,
        'show_feedback': False,
        'selected_option': None
    }

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4e8cff;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
    }
    .correct-answer {
        background-color: #d1fae5;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #10b981;
        color: #065f46;
    }
    .incorrect-answer {
        background-color: #fee2e2;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ef4444;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

# Mock Data
mock_exams = [
    {'date': '2026-11-15', 'type': 'Short', 'name': 'Dec Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2026-12-13', 'type': 'Short', 'name': 'Official Dec Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-04-25', 'type': 'Short', 'name': 'May Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-05-23', 'type': 'Short', 'name': 'Official May Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-07-10', 'type': 'Essay', 'name': 'Essay Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-08-20', 'type': 'Essay', 'name': 'Official Aug Essay Exam', 'provider': 'CPAAOB', 'status': 'Target'}
]

default_official_schedule = [
    # Short I (Dec) 2026
    {'date': '2026-12-13', 'category': 'Exam', 'event': 'çŸ­ç­”å¼ ç¬¬Iå›ï¼ˆ12æœˆï¼‰ è©¦é¨“', 'notes': 'ä¼æ¥­æ³•/ç®¡ç†/ç›£æŸ»/è²¡å‹™ï¼ˆ500ç‚¹æº€ç‚¹ï¼‰'},
    {'date': '2027-01-20', 'category': 'Result', 'event': 'çŸ­ç­”å¼ ç¬¬Iå› åˆæ ¼ç™ºè¡¨ï¼ˆç›®å®‰ï¼‰', 'notes': 'å…¬å¼ç™ºè¡¨æ™‚åˆ»ã«å¾“ã†ãƒ»ç›®å®‰æ—¥ä»˜'},
    # Short II (May) 2027
    {'date': '2027-05-23', 'category': 'Exam', 'event': 'çŸ­ç­”å¼ ç¬¬IIå›ï¼ˆ5æœˆï¼‰ è©¦é¨“', 'notes': 'ç›®æ¨™ï¼šåŒå¹´ã®è«–æ–‡ã¸'},
    {'date': '2027-06-20', 'category': 'Result', 'event': 'çŸ­ç­”å¼ ç¬¬IIå› åˆæ ¼ç™ºè¡¨ï¼ˆç›®å®‰ï¼‰', 'notes': 'å…¬å¼ç™ºè¡¨æ™‚åˆ»ã«å¾“ã†ãƒ»ç›®å®‰æ—¥ä»˜'},
    # Essay 2027
    {'date': '2027-08-20', 'category': 'Exam', 'event': 'è«–æ–‡å¼ è©¦é¨“', 'notes': '2æ—¥é–“ç§‘ç›®ãƒ»é…ç‚¹ã«æ³¨æ„'},
    {'date': '2027-11-15', 'category': 'Result', 'event': 'è«–æ–‡å¼ åˆæ ¼ç™ºè¡¨ï¼ˆç›®å®‰ï¼‰', 'notes': 'ä¾‹å¹´11æœˆé ƒç™ºè¡¨ãƒ»ç›®å®‰æ—¥ä»˜'}
]

official_schedule = st.session_state.data.get('official_schedule', default_official_schedule)
# Vocabulary Data
def load_vocab_data():
    vocab_path = "assets/vocab.json"
    if os.path.exists(vocab_path):
        with open(vocab_path, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except:
                return {}
    return {}

vocab_data = load_vocab_data()

def load_formulas_data():
    p = os.path.join(os.path.dirname(os.path.abspath(__file__)), "assets", "formulas.json")
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

formulas_data = load_formulas_data()

def save_formulas_data(data):
    p = os.path.join(os.path.dirname(os.path.abspath(__file__)), "assets", "formulas.json")
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False

def seed_top10_examples():
    top10 = {
        "Future Value (Single Sum)": {
            "example_ja": "ä¾‹: PV=1,000ã€r=5%ã€n=3å¹´ â‡’ FV = 1,000Ã—(1.05)^3 â‰ˆ 1,157.63",
            "example_en": "Example: PV=1,000, r=5%, n=3 â‡’ FV = 1,000Ã—(1.05)^3 â‰ˆ 1,157.63",
            "problem_ja": "å•é¡Œ: PV=200ã€r=8%ã€n=4å¹´ ã®å°†æ¥ä¾¡å€¤FVã¯ï¼Ÿ",
            "problem_en": "Problem: Find FV for PV=200, r=8%, n=4.",
            "solution_ja": "è§£ç­”: FV = 200Ã—(1.08)^4 â‰ˆ 272.1",
            "solution_en": "Solution: FV = 200Ã—(1.08)^4 â‰ˆ 272.1"
        },
        "Present Value (Single Sum)": {
            "example_ja": "ä¾‹: FV=1,000ã€r=6%ã€n=2å¹´ â‡’ PV = 1,000 Ã· (1.06)^2 â‰ˆ 890.0",
            "example_en": "Example: FV=1,000, r=6%, n=2 â‡’ PV = 1,000/(1.06)^2 â‰ˆ 890.0",
            "problem_ja": "å•é¡Œ: FV=500ã€r=10%ã€n=3å¹´ ã®ç¾åœ¨ä¾¡å€¤PVã¯ï¼Ÿ",
            "problem_en": "Problem: Find PV for FV=500, r=10%, n=3.",
            "solution_ja": "è§£ç­”: PV â‰ˆ 500 Ã· 1.331 â‰ˆ 375.7",
            "solution_en": "Solution: PV â‰ˆ 500/1.331 â‰ˆ 375.7"
        },
        "Present Value of Annuity": {
            "example_ja": "ä¾‹: P=100ã€r=5%ã€n=4 â‡’ PVA = 100Ã—[1 âˆ’ (1.05)^(âˆ’4)] Ã· 0.05 â‰ˆ 354.6",
            "example_en": "Example: P=100, r=5%, n=4 â‡’ PVA â‰ˆ 354.6",
            "problem_ja": "å•é¡Œ: P=50ã€r=6%ã€n=3 ã®å¹´é‡‘ç¾åœ¨ä¾¡å€¤PVAã¯ï¼Ÿ",
            "problem_en": "Problem: Find PVA for P=50, r=6%, n=3.",
            "solution_ja": "è§£ç­”: PVA â‰ˆ 50Ã—[1 âˆ’ (1.06)^(âˆ’3)] Ã· 0.06 â‰ˆ 133.7",
            "solution_en": "Solution: PVA â‰ˆ 50Ã—[1 âˆ’ 1.06^(âˆ’3)]/0.06 â‰ˆ 133.7"
        },
        "Contribution Margin": {
            "example_ja": "ä¾‹: å£²ä¸Š1,000ã€å¤‰å‹•è²»600 â‡’ é™ç•Œåˆ©ç›ŠCM = 400",
            "example_en": "Example: Sales=1,000, Variable=600 â‡’ CM=400",
            "problem_ja": "å•é¡Œ: å˜ä¾¡20ã€å¤‰å‹•è²»/å˜ä½12ã€æ•°é‡200 â‡’ é™ç•Œåˆ©ç›Šã¯ï¼Ÿ",
            "problem_en": "Problem: Price=20, Var/unit=12, Units=200 â‡’ CM?",
            "solution_ja": "è§£ç­”: å˜ä½CM=8ã€åˆè¨ˆCM=8Ã—200=1,600",
            "solution_en": "Solution: Unit CM=8; Total CM=8Ã—200=1,600"
        },
        "Break-even Units": {
            "example_ja": "ä¾‹: å›ºå®šè²»1,200ã€å˜ä¾¡20ã€å¤‰å‹•è²»12 â‡’ BEQ=1,200Ã·(20âˆ’12)=150å˜ä½",
            "example_en": "Example: Fixed=1,200, Price=20, Var=12 â‡’ BEQ=150 units",
            "problem_ja": "å•é¡Œ: å›ºå®šè²»5,000ã€å˜ä¾¡50ã€å¤‰å‹•è²»30 â‡’ BEQã¯ï¼Ÿ",
            "problem_en": "Problem: Fixed=5,000, Price=50, Var=30 â‡’ BEQ?",
            "solution_ja": "è§£ç­”: BEQ=5,000 Ã· (50âˆ’30)=250å˜ä½",
            "solution_en": "Solution: BEQ=5,000/(50âˆ’30)=250 units"
        },
        "Net Present Value": {
            "example_ja": "ä¾‹: CF0=-1,000ã€CF1-3=400ã€r=8% â‡’ NPV â‰ˆ 30.8ï¼ˆæ­£ã€æ¡ç”¨ï¼‰",
            "example_en": "Example: CF0=-1,000, CF1-3=400, r=8% â‡’ NPV â‰ˆ 30.8",
            "problem_ja": "å•é¡Œ: CF0=-2,000ã€CF1-4=600ã€r=10% â‡’ NPVã¯ï¼Ÿ",
            "problem_en": "Problem: CF0=-2,000, CF1-4=600, r=10% â‡’ NPV?",
            "solution_ja": "è§£ç­”: 600Ã—[(1âˆ’1.1^(âˆ’4))/0.1]âˆ’2,000 â‰ˆ -98.1",
            "solution_en": "Solution: 600Ã—[(1âˆ’1.1^(âˆ’4))/0.1]âˆ’2,000 â‰ˆ -98.1"
        },
        "WACC": {
            "example_ja": "ä¾‹: w_e=0.6, w_d=0.4, k_e=10%, k_d=5%, T=30% â‡’ WACC=7.4%",
            "example_en": "Example: we=0.6, wd=0.4, ke=10%, kd=5%, T=30% â‡’ WACC=7.4%",
            "problem_ja": "å•é¡Œ: w_e=0.7, w_d=0.3, k_e=12%, k_d=4%, T=25% â‡’ WACCã¯ï¼Ÿ",
            "problem_en": "Problem: we=0.7, wd=0.3, ke=12%, kd=4%, T=25% â‡’ WACC?",
            "solution_ja": "è§£ç­”: 0.7Ã—0.12 + 0.3Ã—0.04Ã—(1âˆ’0.25)=9.3%",
            "solution_en": "Solution: 0.7Ã—0.12 + 0.3Ã—0.04Ã—(1âˆ’0.25)=9.3%"
        },
        "CAPM Cost of Equity": {
            "example_ja": "ä¾‹: Rf=2%ã€Î²=1.2ã€(Rmâˆ’Rf)=5% â‡’ k_e=8%",
            "example_en": "Example: Rf=2%, Î²=1.2, (Rmâˆ’Rf)=5% â‡’ ke=8%",
            "problem_ja": "å•é¡Œ: Rf=1%ã€Î²=0.8ã€Rm=6% â‡’ k_eã¯ï¼Ÿ",
            "problem_en": "Problem: Rf=1%, Î²=0.8, Rm=6% â‡’ ke?",
            "solution_ja": "è§£ç­”: MRP=5%ã€k_e=1%+0.8Ã—5%=5%",
            "solution_en": "Solution: MRP=5%, ke=1%+0.8Ã—5%=5%"
        },
        "ROE": {
            "example_ja": "ä¾‹: å½“æœŸç´”åˆ©ç›Š120ã€å¹³å‡è‡ªå·±è³‡æœ¬1,000 â‡’ ROE=12%",
            "example_en": "Example: NI=120, Avg Equity=1,000 â‡’ ROE=12%",
            "problem_ja": "å•é¡Œ: å½“æœŸç´”åˆ©ç›Š80ã€å¹³å‡è‡ªå·±è³‡æœ¬400 â‡’ ROEã¯ï¼Ÿ",
            "problem_en": "Problem: NI=80, Avg Equity=400 â‡’ ROE?",
            "solution_ja": "è§£ç­”: 80 Ã· 400 = 20%",
            "solution_en": "Solution: 80/400 = 20%"
        },
        "DuPont ROE": {
            "example_ja": "ä¾‹: NPM=10%ã€TAT=1.5ã€EM=2 â‡’ ROE=30%",
            "example_en": "Example: NPM=10%, TAT=1.5, EM=2 â‡’ ROE=30%",
            "problem_ja": "å•é¡Œ: NPM=8%ã€TAT=1.2ã€EM=1.8 â‡’ ROEã¯ï¼Ÿ",
            "problem_en": "Problem: NPM=8%, TAT=1.2, EM=1.8 â‡’ ROE?",
            "solution_ja": "è§£ç­”: 0.08Ã—1.2Ã—1.8=0.1728 â‡’ 17.28%",
            "solution_en": "Solution: 0.08Ã—1.2Ã—1.8=0.1728 â‡’ 17.28%"
        }
    }
    # Also seed for Annuity Due PV/FV if present
    top10.update({
        "Annuity Due PV": {
            "example_ja": "ä¾‹: P=100ã€r=5%ã€n=3 â‡’ PVA_due = 100Ã—[(1âˆ’1.05^(âˆ’3))/0.05]Ã—(1.05) â‰ˆ 286.98",
            "example_en": "Example: P=100, r=5%, n=3 â‡’ PVA_due â‰ˆ 286.98",
            "problem_ja": "å•é¡Œ: P=50ã€r=6%ã€n=4 ã®å¹´é‡‘ç¾ä¾¡ï¼ˆæœŸé¦–æ‰•ã„ï¼‰ã¯ï¼Ÿ",
            "problem_en": "Problem: Find annuity-due present value for P=50, r=6%, n=4.",
            "solution_ja": "è§£ç­”: PVA_due = 50Ã—[(1âˆ’1.06^(âˆ’4))/0.06]Ã—1.06 â‰ˆ 183.6",
            "solution_en": "Solution: PVA_due = 50Ã—[(1âˆ’1.06^(âˆ’4))/0.06]Ã—1.06 â‰ˆ 183.6"
        },
        "Annuity Due FV": {
            "example_ja": "ä¾‹: P=100ã€r=5%ã€n=3 â‡’ FVA_due = 100Ã—[(1.05^3âˆ’1)/0.05]Ã—(1.05) â‰ˆ 331.0",
            "example_en": "Example: P=100, r=5%, n=3 â‡’ FVA_due â‰ˆ 331.0",
            "problem_ja": "å•é¡Œ: P=80ã€r=4%ã€n=5 ã®å¹´é‡‘å°†æ¥ä¾¡å€¤ï¼ˆæœŸé¦–æ‰•ã„ï¼‰ã¯ï¼Ÿ",
            "problem_en": "Problem: Find annuity-due future value for P=80, r=4%, n=5.",
            "solution_ja": "è§£ç­”: FVA_due = 80Ã—[(1.04^5âˆ’1)/0.04]Ã—1.04 â‰ˆ 433.0",
            "solution_en": "Solution: FVA_due = 80Ã—[(1.04^5âˆ’1)/0.04]Ã—1.04 â‰ˆ 433.0"
        }
    })
    changed = False
    for i, item in enumerate(formulas_data):
        name = item.get("name", "")
        if name in top10:
            for k, v in top10[name].items():
                if formulas_data[i].get(k) in (None, "", []):
                    formulas_data[i][k] = v
                    changed = True
    if changed:
        save_formulas_data(formulas_data)

def _sanitize_text(v):
    try:
        if v is None:
            return ""
        # Handle numpy/pandas NaN
        try:
            import pandas as _pd
            if _pd.isna(v):
                return ""
        except Exception:
            pass
        if isinstance(v, str) and v.strip().lower() == "nan":
            return ""
        return v
    except Exception:
        return ""

def seed_all_formulas():
    changed = False
    for i, item in enumerate(formulas_data):
        name = str(item.get("name", "")).strip()
        cat = str(item.get("category", "")).strip()
        ex_ja = _sanitize_text(item.get("example_ja", ""))
        ex_en = _sanitize_text(item.get("example_en", ""))
        pb_ja = _sanitize_text(item.get("problem_ja", ""))
        pb_en = _sanitize_text(item.get("problem_en", ""))
        so_ja = _sanitize_text(item.get("solution_ja", ""))
        so_en = _sanitize_text(item.get("solution_en", ""))
        if not ex_ja and not ex_en and not pb_ja and not pb_en and not so_ja and not so_en:
            nl = name.lower()
            if "eoq" in nl or "economic order quantity" in nl:
                ex_ja = "ä¾‹: å¹´éœ€è¦D=12,000ã€ç™ºæ³¨è²»S=100ã€åœ¨åº«è²»H=2 â‡’ EOQ=âˆš(2Ã—12,000Ã—100/2)â‰ˆ1,095"
                ex_en = "Example: D=12,000/yr, S=100/order, H=2/unit/yr â‡’ EOQâ‰ˆ1,095"
                pb_ja = "å•é¡Œ: D=36,000ã€S=80ã€H=4 ã®EOQã¯ï¼Ÿ"
                pb_en = "Problem: Find EOQ for D=36,000, S=80, H=4."
                so_ja = "è§£ç­”: EOQ=âˆš(2Ã—36,000Ã—80/4)=âˆš1,440,000â‰ˆ1,200"
                so_en = "Solution: EOQ=âˆš(2Ã—36,000Ã—80/4)=âˆš1,440,000â‰ˆ1,200"
            elif "reorder point" in nl or "rop" in nl:
                ex_ja = "ä¾‹: éœ€è¦æ—¥é‡d=50ã€ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ L=6ã€ å®‰å…¨åœ¨åº«SS=100 â‡’ ROP=50Ã—6+100=400"
                ex_en = "Example: d=50/day, L=6 days, SS=100 â‡’ ROP=400"
                pb_ja = "å•é¡Œ: d=80ã€L=5ã€SS=60 ã®ROPã¯ï¼Ÿ"
                pb_en = "Problem: Find ROP for d=80, L=5, SS=60."
                so_ja = "è§£ç­”: ROP=80Ã—5+60=460"
                so_en = "Solution: ROP=80Ã—5+60=460"
            elif "safety stock" in nl:
                ex_ja = "ä¾‹: ÏƒL=40ã€Z=1.65 â‡’ SS=1.65Ã—40=66"
                ex_en = "Example: ÏƒL=40, Z=1.65 â‡’ SS=66"
                pb_ja = "å•é¡Œ: ÏƒL=30ã€Z=1.96 ã®å®‰å…¨åœ¨åº«ã¯ï¼Ÿ"
                pb_en = "Problem: Find SS for ÏƒL=30, Z=1.96."
                so_ja = "è§£ç­”: SS=1.96Ã—30=58.8â‰ˆ59"
                so_en = "Solution: SS=1.96Ã—30=58.8â‰ˆ59"
            elif "material price variance" in nl or "mpv" in nl:
                ex_ja = "ä¾‹: AQ=1,000kgã€AP=Â¥6ã€SP=Â¥5 â‡’ MPV=1,000Ã—(6âˆ’5)=1,000ä¸åˆ©"
                ex_en = "Example: AQ=1,000kg, AP=6, SP=5 â‡’ MPV=1,000 U"
                pb_ja = "å•é¡Œ: AQ=800ã€AP=Â¥4.8ã€SP=Â¥5.0 ã®MPVã¯ï¼Ÿ"
                pb_en = "Problem: Find MPV for AQ=800, AP=4.8, SP=5.0."
                so_ja = "è§£ç­”: 800Ã—(4.8âˆ’5.0)=âˆ’160 æœ‰åˆ©"
                so_en = "Solution: 800Ã—(4.8âˆ’5.0)=âˆ’160 F"
            elif "material quantity variance" in nl or "mqv" in nl or "usage variance" in nl:
                ex_ja = "ä¾‹: SP=Â¥5ã€AQ=1,100kgã€SQ=1,000kg â‡’ MQV=5Ã—(1,100âˆ’1,000)=500ä¸åˆ©"
                ex_en = "Example: SP=5, AQ=1,100, SQ=1,000 â‡’ MQV=500 U"
                pb_ja = "å•é¡Œ: SP=Â¥4ã€AQ=950ã€SQ=1,000 ã®MQVã¯ï¼Ÿ"
                pb_en = "Problem: Find MQV for SP=4, AQ=950, SQ=1,000."
                so_ja = "è§£ç­”: 4Ã—(950âˆ’1,000)=âˆ’200 æœ‰åˆ©"
                so_en = "Solution: 4Ã—(950âˆ’1,000)=âˆ’200 F"
            elif "labor rate variance" in nl or "lrv" in nl:
                ex_ja = "ä¾‹: AH=1,200hã€AR=Â¥12ã€SR=Â¥10 â‡’ LRV=1,200Ã—(12âˆ’10)=2,400ä¸åˆ©"
                ex_en = "Example: AH=1,200h, AR=12, SR=10 â‡’ LRV=2,400 U"
                pb_ja = "å•é¡Œ: AH=900ã€AR=Â¥9.5ã€SR=Â¥10 ã®LRVã¯ï¼Ÿ"
                pb_en = "Problem: Find LRV for AH=900, AR=9.5, SR=10."
                so_ja = "è§£ç­”: 900Ã—(9.5âˆ’10)=âˆ’450 æœ‰åˆ©"
                so_en = "Solution: 900Ã—(9.5âˆ’10)=âˆ’450 F"
            elif "labor efficiency variance" in nl or "lev" in nl:
                ex_ja = "ä¾‹: SR=Â¥10ã€AH=1,200hã€SH=1,000h â‡’ LEV=10Ã—(1,200âˆ’1,000)=2,000ä¸åˆ©"
                ex_en = "Example: SR=10, AH=1,200, SH=1,000 â‡’ LEV=2,000 U"
                pb_ja = "å•é¡Œ: SR=Â¥12ã€AH=800ã€SH=850 ã®LEVã¯ï¼Ÿ"
                pb_en = "Problem: Find LEV for SR=12, AH=800, SH=850."
                so_ja = "è§£ç­”: 12Ã—(800âˆ’850)=âˆ’600 æœ‰åˆ©"
                so_en = "Solution: 12Ã—(800âˆ’850)=âˆ’600 F"
            elif "straight-line" in nl or "å®šé¡" in nl:
                ex_ja = "ä¾‹: åŸä¾¡1,000ã€æ®‹å­˜100ã€è€ç”¨å¹´æ•°5 â‡’ å¹´é¡=(1,000âˆ’100)/5=180"
                ex_en = "Example: Cost=1,000, Salvage=100, Life=5 â‡’ Annual=180"
                pb_ja = "å•é¡Œ: åŸä¾¡800ã€æ®‹å­˜0ã€è€ç”¨å¹´æ•°4 ã®å¹´é¡ã¯ï¼Ÿ"
                pb_en = "Problem: Find annual SL depreciation for Cost=800, Salvage=0, Life=4."
                so_ja = "è§£ç­”: 800/4=200"
                so_en = "Solution: 800/4=200"
            elif "declining" in nl or "double-declining" in nl or "å®šç‡" in nl:
                ex_ja = "ä¾‹: åŸä¾¡1,000ã€è€ç”¨å¹´æ•°5ã€ç‡=40% â‡’ 1å¹´ç›®=400ã€2å¹´ç›®=(1,000âˆ’400)Ã—0.4=240"
                ex_en = "Example: Cost=1,000, Life=5, Rate=40% â‡’ Y1=400, Y2=240"
                pb_ja = "å•é¡Œ: åŸä¾¡900ã€å¯¿å‘½3ã€ç‡=2/3 ã®1å¹´ç›®æ¸›ä¾¡ã¯ï¼Ÿ"
                pb_en = "Problem: Cost=900, Life=3, Rate=2/3: Year 1 depreciation?"
                so_ja = "è§£ç­”: 900Ã—(2/3)=600"
                so_en = "Solution: 900Ã—(2/3)=600"
            elif "sum-of-the-years" in nl or "syd" in nl:
                ex_ja = "ä¾‹: åŸä¾¡1,000ã€æ®‹å­˜100ã€å¯¿å‘½5ã€åˆè¨ˆ=15 â‡’ 1å¹´ç›®=(5/15)Ã—900=300"
                ex_en = "Example: Cost=1,000, Salvage=100, Life=5, Sum=15 â‡’ Y1=300"
                pb_ja = "å•é¡Œ: åŸä¾¡600ã€æ®‹å­˜60ã€å¯¿å‘½4ã€åˆè¨ˆ=10 ã®2å¹´ç›®ã¯ï¼Ÿ"
                pb_en = "Problem: Cost=600, Salvage=60, Life=4, Sum=10: Year 2?"
                so_ja = "è§£ç­”: (3/10)Ã—540=162"
                so_en = "Solution: (3/10)Ã—540=162"
            elif "units of production" in nl or "production-output" in nl:
                ex_ja = "ä¾‹: åŸä¾¡1,000ã€æ®‹å­˜100ã€ç·è¦‹ç©50,000u â‡’ ç‡=(900/50,000)=0.018/u"
                ex_en = "Example: Cost=1,000, Salvage=100, Total 50,000u â‡’ Rate=0.018/u"
                pb_ja = "å•é¡Œ: å½“æœŸç”Ÿç”£4,000u ã®æ¸›ä¾¡ã¯ï¼Ÿ"
                pb_en = "Problem: Find depreciation for 4,000 units."
                so_ja = "è§£ç­”: 0.018Ã—4,000=72"
                so_en = "Solution: 0.018Ã—4,000=72"
            elif "profitability index" in nl or " pi " in nl or nl.endswith(" pi"):
                ex_ja = "ä¾‹: æµå…¥PV=1,200ã€åˆæœŸæŠ•è³‡=1,000 â‡’ PI=1.2ï¼ˆæ¡ç”¨ï¼‰"
                ex_en = "Example: PV inflows=1,200, Initial=1,000 â‡’ PI=1.2 (accept)"
                pb_ja = "å•é¡Œ: PVæµå…¥=900ã€æŠ•è³‡=1,000 ã®PIã¯ï¼Ÿæ¡å¦ã¯ï¼Ÿ"
                pb_en = "Problem: PV inflows=900, investment=1,000 â‡’ PI? Accept?"
                so_ja = "è§£ç­”: 0.9ã€1æœªæº€ã®ãŸã‚ä¸æ¡ç”¨"
                so_en = "Solution: 0.9; below 1, reject"
            elif "payback" in nl:
                ex_ja = "ä¾‹: åˆæœŸæŠ•è³‡1,000ã€æ¯å¹´CF=250 â‡’ å›åæœŸé–“=4å¹´"
                ex_en = "Example: Initial 1,000, annual CF=250 â‡’ Payback=4 years"
                pb_ja = "å•é¡Œ: åˆæœŸæŠ•è³‡1,200ã€å¹´CF=300 â‡’ å›åæœŸé–“ã¯ï¼Ÿ"
                pb_en = "Problem: Initial 1,200, annual CF=300 â‡’ Payback?"
                so_ja = "è§£ç­”: 1,200/300=4å¹´"
                so_en = "Solution: 1,200/300=4 years"
            elif "perpetuity" in nl and "growing" not in nl:
                ex_ja = "ä¾‹: C=100ã€r=5% â‡’ PV=100/0.05=2,000"
                ex_en = "Example: C=100, r=5% â‡’ PV=100/0.05=2,000"
                pb_ja = "å•é¡Œ: C=60ã€r=4% ã®æ°¸ä¹…å¹´é‡‘PVã¯ï¼Ÿ"
                pb_en = "Problem: C=60, r=4% â‡’ PV?"
                so_ja = "è§£ç­”: 60/0.04=1,500"
                so_en = "Solution: 60/0.04=1,500"
            elif ("growing perpetuity" in nl) or ("gordon" in nl) or ("ddm" in nl) or ("dividend discount" in nl):
                ex_ja = "ä¾‹: D1=2ã€k=8%ã€g=3% â‡’ P0=2/(0.08âˆ’0.03)=40"
                ex_en = "Example: D1=2, k=8%, g=3% â‡’ P0=2/(0.08âˆ’0.03)=40"
                pb_ja = "å•é¡Œ: D1=3ã€k=10%ã€g=4% ã®P0ã¯ï¼Ÿ"
                pb_en = "Problem: D1=3, k=10%, g=4% â‡’ P0?"
                so_ja = "è§£ç­”: 3/(0.10âˆ’0.04)=50"
                so_en = "Solution: 3/(0.10âˆ’0.04)=50"
            elif "current ratio" in nl:
                ex_ja = "ä¾‹: æµå‹•è³‡ç”£=500ã€æµå‹•è² å‚µ=250 â‡’ 2.0å€"
                ex_en = "Example: CA=500, CL=250 â‡’ 2.0x"
                pb_ja = "å•é¡Œ: CA=360ã€CL=300 ã®æµå‹•æ¯”ç‡ã¯ï¼Ÿ"
                pb_en = "Problem: CA=360, CL=300 â‡’ current ratio?"
                so_ja = "è§£ç­”: 360/300=1.2å€"
                so_en = "Solution: 360/300=1.2x"
            elif "quick ratio" in nl or "acid-test" in nl:
                ex_ja = "ä¾‹: å½“åº§è³‡ç”£=300ã€æµå‹•è² å‚µ=200 â‡’ 1.5å€"
                ex_en = "Example: Quick assets=300, CL=200 â‡’ 1.5x"
                pb_ja = "å•é¡Œ: QA=180ã€CL=240 ã®å½“åº§æ¯”ç‡ã¯ï¼Ÿ"
                pb_en = "Problem: QA=180, CL=240 â‡’ quick ratio?"
                so_ja = "è§£ç­”: 180/240=0.75å€"
                so_en = "Solution: 180/240=0.75x"
            elif "debt-to-equity" in nl or "debt to equity" in nl or "d/e" in nl:
                ex_ja = "ä¾‹: è² å‚µ=600ã€è‡ªå·±è³‡æœ¬=400 â‡’ D/E=1.5"
                ex_en = "Example: Debt=600, Equity=400 â‡’ D/E=1.5"
                pb_ja = "å•é¡Œ: è² å‚µ=750ã€è‡ªå·±è³‡æœ¬=500 ã®D/Eã¯ï¼Ÿ"
                pb_en = "Problem: Debt=750, Equity=500 â‡’ D/E?"
                so_ja = "è§£ç­”: 750/500=1.5"
                so_en = "Solution: 750/500=1.5"
            elif "times interest earned" in nl or "interest coverage" in nl:
                ex_ja = "ä¾‹: EBIT=300ã€åˆ©æ¯=60 â‡’ TIE=5å€"
                ex_en = "Example: EBIT=300, Interest=60 â‡’ TIE=5x"
                pb_ja = "å•é¡Œ: EBIT=240ã€åˆ©æ¯=80 ã®TIEã¯ï¼Ÿ"
                pb_en = "Problem: EBIT=240, Interest=80 â‡’ TIE?"
                so_ja = "è§£ç­”: 240/80=3å€"
                so_en = "Solution: 240/80=3x"
            elif "inventory turnover" in nl:
                ex_ja = "ä¾‹: å£²ä¸ŠåŸä¾¡=1,200ã€å¹³å‡åœ¨åº«=300 â‡’ å›è»¢=4.0"
                ex_en = "Example: COGS=1,200, Avg Inv=300 â‡’ Turnover=4.0"
                pb_ja = "å•é¡Œ: COGS=900ã€å¹³å‡åœ¨åº«=225 â‡’ å›è»¢ã¯ï¼Ÿ"
                pb_en = "Problem: COGS=900, Avg Inv=225 â‡’ turnover?"
                so_ja = "è§£ç­”: 900/225=4.0"
                so_en = "Solution: 900/225=4.0"
            elif "days sales outstanding" in nl or "dso" in nl or "receivables turnover" in nl:
                ex_ja = "ä¾‹: å£²æ›å›è»¢=12 â‡’ DSOâ‰ˆ365/12â‰ˆ30.4æ—¥"
                ex_en = "Example: AR turnover=12 â‡’ DSOâ‰ˆ365/12â‰ˆ30.4 days"
                pb_ja = "å•é¡Œ: ARå›è»¢=10 ã®DSOã¯ï¼Ÿ"
                pb_en = "Problem: AR turnover=10 â‡’ DSO?"
                so_ja = "è§£ç­”: 365/10=36.5æ—¥"
                so_en = "Solution: 365/10=36.5 days"
            elif "days inventory outstanding" in nl or "dio" in nl:
                ex_ja = "ä¾‹: åœ¨åº«å›è»¢=8 â‡’ DIOâ‰ˆ365/8â‰ˆ45.6æ—¥"
                ex_en = "Example: Inventory turnover=8 â‡’ DIOâ‰ˆ365/8â‰ˆ45.6 days"
                pb_ja = "å•é¡Œ: åœ¨åº«å›è»¢=5 ã®DIOã¯ï¼Ÿ"
                pb_en = "Problem: Inventory turnover=5 â‡’ DIO?"
                so_ja = "è§£ç­”: 365/5=73æ—¥"
                so_en = "Solution: 365/5=73 days"
            elif "cash conversion cycle" in nl or "ccc" in nl:
                ex_ja = "ä¾‹: DIO=50ã€DSO=35ã€DPO=40 â‡’ CCC=45æ—¥"
                ex_en = "Example: DIO=50, DSO=35, DPO=40 â‡’ CCC=45 days"
                pb_ja = "å•é¡Œ: DIO=60ã€DSO=30ã€DPO=50 ã®CCCã¯ï¼Ÿ"
                pb_en = "Problem: DIO=60, DSO=30, DPO=50 â‡’ CCC?"
                so_ja = "è§£ç­”: 60+30âˆ’50=40æ—¥"
                so_en = "Solution: 60+30âˆ’50=40 days"
            elif "gross margin" in nl or "operating margin" in nl or "net profit margin" in nl:
                ex_ja = "ä¾‹: åˆ©ç›Š=120ã€å£²ä¸Š=1,000 â‡’ ãƒãƒ¼ã‚¸ãƒ³=12%"
                ex_en = "Example: Profit=120, Sales=1,000 â‡’ margin=12%"
                pb_ja = "å•é¡Œ: åˆ©ç›Š=90ã€å£²ä¸Š=750 ã®ãƒãƒ¼ã‚¸ãƒ³ã¯ï¼Ÿ"
                pb_en = "Problem: Profit=90, Sales=750 â‡’ margin?"
                so_ja = "è§£ç­”: 90/750=12%"
                so_en = "Solution: 90/750=12%"
            elif "present value" in name.lower() or "future value" in name.lower() or "annuity" in name.lower():
                ex_ja = f"ä¾‹: ä»®ã« r=5%ã€æœŸé–“ n=3ã€é©åˆ‡ãªé‡‘é¡ã‚’ä»£å…¥ã—ã¦è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚"
                ex_en = f"Example: Assume r=5%, n=3; plug suitable amounts and compute."
                pb_ja = f"å•é¡Œ: {name} ã‚’ç”¨ã„ã¦é‡‘é¡ã‚’æ±‚ã‚ã‚ˆã€‚"
                pb_en = f"Problem: Use {name} to find the requested amount."
                so_ja = f"è§£ç­”: æ•°å¼ã«ä»£å…¥ã—ã€å››æ¨äº”å…¥ã—ã¦æ•°å€¤ã‚’ç¤ºã™ã€‚"
                so_en = f"Solution: Substitute into the formula and present the rounded value."
            elif "wacc" in name.lower() or "capm" in name.lower() or "npv" in name.lower() or "irr" in name.lower():
                ex_ja = "ä¾‹: Rf, Î², MRP ã¾ãŸã¯ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼åˆ— ã¨ å‰²å¼•ç‡ ã‚’ä»®å®šã—ã¦è¨ˆç®—ã€‚"
                ex_en = "Example: Assume Rf, Î², MRP or CF series and a discount rate to compute."
                pb_ja = f"å•é¡Œ: {name} ã‚’è¨ˆç®—ã—ã€æ¡å¦ã‚’åˆ¤æ–­ã›ã‚ˆï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰ã€‚"
                pb_en = f"Problem: Compute {name} and decide accept/reject if applicable."
                so_ja = "è§£ç­”: ä¸ãˆã‚‰ã‚ŒãŸæ•°å€¤ã‚’ä»£å…¥ã—ã€å¼ã«å¾“ã£ã¦ç®—å‡ºã€‚"
                so_en = "Solution: Substitute the provided values and evaluate per the formula."
            elif "roe" in name.lower() or "roa" in name.lower() or "ratio" in name.lower():
                ex_ja = "ä¾‹: åˆ†å­ã¨åˆ†æ¯ã®æ•°å€¤ã‚’ä»®å®šã—ã€æ¯”ç‡ã‚’ç®—å‡ºã€‚"
                ex_en = "Example: Assume numerator and denominator values and compute the ratio."
                pb_ja = f"å•é¡Œ: {name} ã‚’è¨ˆç®—ã—ã€è§£é‡ˆã‚’è¿°ã¹ã‚ˆã€‚"
                pb_en = f"Problem: Calculate {name} and interpret the result."
                so_ja = "è§£ç­”: ä»£å…¥ã—ã¦ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã§è¡¨ç¤ºã€‚"
                so_en = "Solution: Substitute values and present as a percentage."
            elif "break-even" in name.lower() or "contribution" in name.lower() or "variance" in name.lower():
                ex_ja = "ä¾‹: å˜ä¾¡ãƒ»å¤‰å‹•è²»ãƒ»å›ºå®šè²»ï¼ˆã¾ãŸã¯å®Ÿç¸¾ã¨æ¨™æº–ï¼‰ã‚’ä»®å®šã—ã¦æŒ‡æ¨™ã‚’è¨ˆç®—ã€‚"
                ex_en = "Example: Assume price, variable, fixed costs (or actual vs. standard) and compute."
                pb_ja = f"å•é¡Œ: {name} ã‚’ç®—å‡ºã—ã€æ„æ€æ±ºå®šã‚’ç¤ºã›ã€‚"
                pb_en = f"Problem: Compute {name} and state the decision implication."
                so_ja = "è§£ç­”: æŒ‡å®šå¼ã«ä»£å…¥ã—ã€å˜ä½æ•°ã¾ãŸã¯å·®é¡ã‚’å°å‡ºã€‚"
                so_en = "Solution: Substitute into the specified formula and derive units or variance."
            else:
                ex_ja = f"ä¾‹: ã€Œ{name}ã€ã®ç°¡å˜ãªæ•°å€¤ä¾‹ã‚’è¨˜å…¥ã€‚"
                ex_en = f"Example: Provide a simple numeric example for \"{name}\"."
                pb_ja = "å•é¡Œ: æ•°å€¤ã‚’è¨­å®šã—ã€æœªçŸ¥æ•°ã‚’æ±‚ã‚ã‚ˆã€‚"
                pb_en = "Problem: Set numbers and solve for the unknown."
                so_ja = "è§£ç­”: å¼ã¸ä»£å…¥ã—è¨ˆç®—çµæœã‚’æç¤ºã€‚"
                so_en = "Solution: Substitute into the formula and show the result."
            formulas_data[i]["example_ja"] = ex_ja
            formulas_data[i]["example_en"] = ex_en
            formulas_data[i]["problem_ja"] = pb_ja
            formulas_data[i]["problem_en"] = pb_en
            formulas_data[i]["solution_ja"] = so_ja
            formulas_data[i]["solution_en"] = so_en
            changed = True
        else:
            if not ex_ja:
                formulas_data[i]["example_ja"] = ex_ja
            if not ex_en:
                formulas_data[i]["example_en"] = ex_en
            if not pb_ja:
                formulas_data[i]["problem_ja"] = pb_ja
            if not pb_en:
                formulas_data[i]["problem_en"] = pb_en
            if not so_ja:
                formulas_data[i]["solution_ja"] = so_ja
            if not so_en:
                formulas_data[i]["solution_en"] = so_en
    if changed:
        save_formulas_data(formulas_data)

def _is_missing_text(v):
    try:
        if v is None:
            return True
        try:
            import pandas as _pd
            if _pd.isna(v):
                return True
        except Exception:
            pass
        if isinstance(v, str) and v.strip().lower() == "nan":
            return True
        if isinstance(v, str) and v.strip() == "":
            return True
        return False
    except Exception:
        return True

def seed_latex_formulas():
    mapping = {
        "future value (single sum)": r"FV = PV\\times(1+r)^{n}",
        "present value (single sum)": r"PV = \\dfrac{FV}{(1+r)^{n}}",
        "present value of annuity": r"PVA = P\\times\\dfrac{1-(1+r)^{-n}}{r}",
        "future value of annuity": r"FVA = P\\times\\dfrac{(1+r)^{n}-1}{r}",
        "fv of annuity": r"FVA = P\\times\\dfrac{(1+r)^{n}-1}{r}",
        "pv of annuity": r"PVA = P\\times\\dfrac{1-(1+r)^{-n}}{r}",
        "present value (annuity due)": r"PVA_{\\text{due}} = P\\times\\dfrac{1-(1+r)^{-n}}{r}\\times(1+r)",
        "future value (annuity due)": r"FVA_{\\text{due}} = P\\times\\dfrac{(1+r)^{n}-1}{r}\\times(1+r)",
        "annuity due pv": r"PVA_{\\text{due}} = P\\times\\dfrac{1-(1+r)^{-n}}{r}\\times(1+r)",
        "annuity due fv": r"FVA_{\\text{due}} = P\\times\\dfrac{(1+r)^{n}-1}{r}\\times(1+r)",
        "pv of growing annuity": r"PV = P\\times\\dfrac{1 - \\left(\\dfrac{1+g}{1+r}\\right)^{n}}{r-g}",
        "pv of growing perpetuity": r"PV = \\dfrac{C_1}{r-g}",
        "present value of growing perpetuity": r"PV = \\dfrac{C_1}{r-g}",
        "growing annuity": r"PV = P\\times\\dfrac{1 - \\left(\\dfrac{1+g}{1+r}\\right)^{n}}{r-g}",
        "continuous compounding fv": r"FV = PV\\,e^{rt}",
        "continuous compounding pv": r"PV = FV\\,e^{-rt}",
        "contribution margin": r"CM = \\text{Sales} - \\text{Variable Costs}",
        "break-even units": r"Q_{BE} = \\dfrac{\\text{Fixed Costs}}{\\text{Price} - \\text{Variable Cost per Unit}}",
        "net present value": r"NPV = \\sum_{t=0}^{n} \\dfrac{CF_{t}}{(1+r)^{t}}",
        "wacc": r"WACC = w_e k_e + w_d k_d (1-T) + w_p k_p",
        "capm cost of equity": r"k_e = R_f + \\beta\\,(R_m - R_f)",
        "roe": r"ROE = \\dfrac{\\text{Net Income}}{\\text{Average Equity}}",
        "dupont roe": r"ROE = \\text{NPM}\\times\\text{TAT}\\times\\text{EM}",
        "irr": r"0 = \\sum_{t=0}^{n} \\dfrac{CF_{t}}{(1+IRR)^{t}}",
        "profitability index": r"PI = \\dfrac{\\text{PV of Inflows}}{\\text{Initial Investment}}",
        "payback period": r"\\text{Payback} = \\dfrac{\\text{Initial Investment}}{\\text{Annual Cash Flow}}",
        "present value of perpetuity": r"PV = \\dfrac{C}{r}",
        "gordon growth (ddm)": r"P_0 = \\dfrac{D_1}{k-g}",
        "pv of growing ddm": r"P_0 = \\dfrac{D_1}{k-g}",
        "current ratio": r"CR = \\dfrac{CA}{CL}",
        "quick ratio": r"QR = \\dfrac{\\text{Quick Assets}}{CL}",
        "debt-to-equity": r"\\dfrac{\\text{Debt}}{\\text{Equity}}",
        "times interest earned": r"TIE = \\dfrac{EBIT}{\\text{Interest}}",
        "inventory turnover": r"\\text{Turnover} = \\dfrac{COGS}{\\text{Average Inventory}}",
        "days sales outstanding": r"DSO = \\dfrac{365}{\\text{Receivables Turnover}}",
        "days inventory outstanding": r"DIO = \\dfrac{365}{\\text{Inventory Turnover}}",
        "cash conversion cycle": r"CCC = DIO + DSO - DPO",
        "gross profit margin": r"GPM = \\dfrac{\\text{Gross Profit}}{\\text{Sales}}",
        "operating margin": r"OM = \\dfrac{\\text{Operating Income}}{\\text{Sales}}",
        "net profit margin": r"NPM = \\dfrac{\\text{Net Income}}{\\text{Sales}}",
        "economic order quantity (eoq)": r"EOQ = \\sqrt{\\dfrac{2DS}{H}}",
        "reorder point": r"ROP = d\\times L + SS",
        "safety stock": r"SS = Z\\times\\sigma_{L}",
        "capm": r"k_e = R_f + \\beta\\,(R_m - R_f)",
        "effective annual rate": r"EAR = (1 + i/m)^{m} - 1",
        "future value of annuity (ordinary)": r"FVA = P\\times\\dfrac{(1+r)^{n}-1}{r}",
        "future value (annuity)": r"FVA = P\\times\\dfrac{(1+r)^{n}-1}{r}",
        "blackâ€“scholes d1": r"d_1 = \\dfrac{\\ln(S/K) + (r + \\tfrac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}}",
        "blackâ€“scholes d2": r"d_2 = d_1 - \\sigma\\sqrt{T}",
        "blackâ€“scholes call price": r"C = S\\,N(d_1) - K e^{-rT} N(d_2)",
        "blackâ€“scholes put price": r"P = K e^{-rT} N(-d_2) - S\\,N(-d_1)",
        "call delta (bsm)": r"\\Delta_{call} = N(d_1)",
        "vega (bsm)": r"\\text{Vega} = S\\,\\phi(d_1)\\sqrt{T}",
        "receivables turnover": r"\\dfrac{\\text{Sales}}{\\overline{AR}}",
        "payables turnover": r"\\dfrac{COGS}{\\overline{AP}}"
    }
    changed = False
    for i, item in enumerate(formulas_data):
        nm = str(item.get("name", "")).strip().lower()
        cur = item.get("latex", "")
        if _is_missing_text(cur):
            # exact match
            if nm in mapping:
                formulas_data[i]["latex"] = mapping[nm]
                changed = True
            else:
                # substring fallback
                for key, tex in mapping.items():
                    if key in nm or nm in key:
                        formulas_data[i]["latex"] = tex
                        changed = True
                        break
    if changed:
        save_formulas_data(formulas_data)

seed_top10_examples()
seed_all_formulas()
seed_latex_formulas()

drill_questions = {
    'Financial': [
        {
            'level': 1,
            'q': "ç¾é‡‘é é‡‘: è²¸å€Ÿå¯¾ç…§è¡¨ã®ã€Œç¾é‡‘ã€ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç´™å¹£ (Bank notes)", "ç¡¬è²¨ (Coins)", "éƒµä¾¿åˆ‡æ‰‹ (Postage stamps)", "å½“åº§é é‡‘ (Demand deposits)"],
            'correct': 2,
            'explanation': "éƒµä¾¿åˆ‡æ‰‹ã¯ã€Œè²¯è”µå“ã€ã¾ãŸã¯ã€Œé€šä¿¡è²»ã€ã¨ã—ã¦å‡¦ç†ã•ã‚Œã€ç¾é‡‘ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚ç¾é‡‘ã«ã¯é€šè²¨ã€å°åˆ‡æ‰‹ã€å½“åº§é é‡‘ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›ä¾¡å„Ÿå´: è³‡ç”£ã®åˆ©ç”¨é‡ã«åŸºã¥ã„ã¦æ¸›ä¾¡å„Ÿå´è²»ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å®šé¡æ³• (Straight-line)", "å®šç‡æ³• (Declining-balance)", "ç”Ÿç”£é«˜æ¯”ä¾‹æ³• (Production-output)", "ç´šæ•°æ³• (Sum-of-the-years'-digits)"],
            'correct': 2,
            'explanation': "ç”Ÿç”£é«˜æ¯”ä¾‹æ³•ã¯ã€ç·è¦‹ç©ç”Ÿç”£é‡ã«å¯¾ã™ã‚‹å½“æœŸã®å®Ÿéš›ç”Ÿç”£é‡ã®å‰²åˆã«åŸºã¥ã„ã¦è²»ç”¨ã‚’é…åˆ†ã™ã‚‹æ–¹æ³•ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ£šå¸è³‡ç”£: ç‰©ä¾¡ä¸Šæ˜‡å±€é¢ã«ãŠã„ã¦ã€å½“æœŸç´”åˆ©ç›ŠãŒæœ€ã‚‚å¤§ãããªã‚‹è©•ä¾¡æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å…ˆå…¥å…ˆå‡ºæ³• (FIFO)", "å¾Œå…¥å…ˆå‡ºæ³• (LIFO)", "ç§»å‹•å¹³å‡æ³• (Weighted Average)", "å€‹åˆ¥æ³• (Specific Identification)"],
            'correct': 0,
            'explanation': "å…ˆå…¥å…ˆå‡ºæ³•(FIFO)ã§ã¯ã€éå»ã®ï¼ˆå®‰ã„ï¼‰åœ¨åº«ãŒå…ˆã«å£²ä¸ŠåŸä¾¡ã¨ãªã‚Šã€æœŸæœ«åœ¨åº«ã«ç›´è¿‘ã®ï¼ˆé«˜ã„ï¼‰å˜ä¾¡ãŒæ®‹ã‚‹ãŸã‚ã€å£²ä¸ŠåŸä¾¡ãŒå°ã•ããªã‚Šåˆ©ç›ŠãŒå¤§ãããªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è³‡ç”£é™¤å»å‚µå‹™: è³‡ç”£é™¤å»å‚µå‹™ã¯å½“åˆä½•ã‚’ã‚‚ã£ã¦æ¸¬å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["é™¤å»è²»ç”¨ã®å°†æ¥ä¾¡å€¤", "é™¤å»è²»ç”¨ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤", "è³‡ç”£ã®å–å¾—åŸä¾¡", "è³‡ç”£ã®å…¬æ­£ä¾¡å€¤"],
            'correct': 1,
            'explanation': "è³‡ç”£é™¤å»å‚µå‹™ã¯ã€å°†æ¥ç™ºç”Ÿã™ã‚‹ã¨è¦‹è¾¼ã¾ã‚Œã‚‹é™¤å»è²»ç”¨ã®ã€Œå‰²å¼•ç¾åœ¨ä¾¡å€¤ã€ã§ç®—å®šã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸€èˆ¬åŸå‰‡: ä¼æ¥­ä¼šè¨ˆåŸå‰‡ã®ã€ŒçœŸå®Ÿæ€§ã®åŸå‰‡ã€ã«ãŠã‘ã‚‹ã€ŒçœŸå®Ÿã€ã®æ„å‘³ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµ¶å¯¾çš„çœŸå®Ÿ", "ç›¸å¯¾çš„çœŸå®Ÿ", "å½¢å¼çš„çœŸå®Ÿ", "æ³•çš„çœŸå®Ÿ"],
            'correct': 1,
            'explanation': "ä¼æ¥­ä¼šè¨ˆã¯è¤‡æ•°ã®ä¼šè¨ˆå‡¦ç†ã®åŸå‰‡ãƒ»æ‰‹ç¶šã®é¸æŠé©ç”¨ã‚’èªã‚ã¦ã„ã‚‹ãŸã‚ã€æ±‚ã‚ã‚‰ã‚Œã‚‹ã®ã¯ã€Œç›¸å¯¾çš„çœŸå®Ÿã€ã§ã‚ã‚‹ã¨è§£ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›æä¼šè¨ˆ: å›ºå®šè³‡ç”£ã®ã€Œå›åå¯èƒ½ä¾¡é¡ã€ã¨ã¯ã€ã©ã®ã‚ˆã†ã«ç®—å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹é«˜ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹ä½ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã®ã¿", "ä½¿ç”¨ä¾¡å€¤ã®ã¿"],
            'correct': 0,
            'explanation': "å›åå¯èƒ½ä¾¡é¡ã¯ã€è³‡ç”£ã®ã€Œæ­£å‘³å£²å´ä¾¡é¡ã€ã¨ã€Œä½¿ç”¨ä¾¡å€¤ã€ã®ã„ãšã‚Œã‹é«˜ã„æ–¹ã®é‡‘é¡ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ãƒªãƒ¼ã‚¹ä¼šè¨ˆ: ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹å–å¼•ã«ãŠã„ã¦ã€å€Ÿæ‰‹ãŒè¨ˆä¸Šã™ã‚‹è³‡ç”£ã®é¡ã¯åŸå‰‡ã¨ã—ã¦ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["ãƒªãƒ¼ã‚¹æ–™ç·é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤ã¨è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ç­‰ã®ã„ãšã‚Œã‹ä½ã„é¡", "è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤"],
            'correct': 1,
            'explanation': "é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹ã§ã¯ã€ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®ç¾åœ¨ä¾¡å€¤ã¨ã€è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ï¼ˆç¾é‡‘è³¼å…¥ä¾¡é¡ï¼‰ã®ã„ãšã‚Œã‹ä½ã„é¡ã§è³‡ç”£è¨ˆä¸Šã—ã¾ã™ã€‚"
        },
        {
            'level': 2,
            'q': "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸: é–“æ¥æ³•ã«ãŠã„ã¦ã€ç¨å¼•å‰å½“æœŸç´”åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹éš›ã€æ¸›ä¾¡å„Ÿå´è²»ã¯ã©ã†èª¿æ•´ã—ã¾ã™ã‹ï¼Ÿ",
            'options': ["åŠ ç®—ã™ã‚‹", "æ¸›ç®—ã™ã‚‹", "èª¿æ•´ã—ãªã„", "å–¶æ¥­å¤–åç›Šã¨ã—ã¦æ‰±ã†"],
            'correct': 0,
            'explanation': "æ¸›ä¾¡å„Ÿå´è²»ã¯ç¾é‡‘æ”¯å‡ºã‚’ä¼´ã‚ãªã„è²»ç”¨ï¼ˆéè³‡é‡‘æç›Šï¼‰ã§ã‚ã‚‹ãŸã‚ã€åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‚’æ±‚ã‚ã‚‹éš›ã¯ã€ŒåŠ ç®—ã€ã—ã¦æˆ»ã—ã¾ã™ã€‚"
        },
        {
            'level': 3,
            'q': "ç¨åŠ¹æœä¼šè¨ˆ: ç¹°å»¶ç¨é‡‘è³‡ç”£ã®å›åå¯èƒ½æ€§ã‚’åˆ¤æ–­ã™ã‚‹éš›ã€ä¼šç¤¾åˆ†é¡ãŒã€Œåˆ†é¡2ã€ã®ä¼æ¥­ã«ãŠã„ã¦ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªä¸€æ™‚å·®ç•°ã¯ã„ã¤ã¾ã§è¨ˆä¸Šå¯èƒ½ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´ä»¥å†…", "5å¹´ä»¥å†…", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå…¨æœŸé–“", "è¨ˆä¸Šã§ããªã„"],
            'correct': 2,
            'explanation': "ã€Œåˆ†é¡2ï¼ˆæ¥­ç¸¾ãŒå®‰å®šã—ã¦ã„ã‚‹ä¼æ¥­ï¼‰ã€ã®å ´åˆã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå°†æ¥æ¸›ç®—ä¸€æ™‚å·®ç•°ã«ã¤ã„ã¦ã¯ã€æœŸé–“åˆ¶é™ãªãï¼ˆå…¨æœŸé–“ï¼‰å›åå¯èƒ½æ€§ãŒã‚ã‚‹ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚"
        }
    ],
    'Management': [
        {
            'level': 1,
            'q': "CVPåˆ†æ: æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡", "å›ºå®šè²» Ã· å¤‰å‹•è²»ç‡", "å¤‰å‹•è²» Ã· å£²ä¸Šé«˜", "åˆ©ç›Š Ã· å£²ä¸Šé«˜"],
            'correct': 0,
            'explanation': "æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ ï¼ å›ºå®šè²» Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡ã®åˆ†é¡: ã€Œç´ ä¾¡ (Prime Cost)ã€ã‚’æ§‹æˆã™ã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç›´æ¥ææ–™è²» ï¼‹ ç›´æ¥åŠ´å‹™è²»", "ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»", "ç›´æ¥ææ–™è²» ï¼‹ è£½é€ é–“æ¥è²»", "è²©å£²è²»åŠã³ä¸€èˆ¬ç®¡ç†è²»"],
            'correct': 0,
            'explanation': "ç´ ä¾¡ï¼ˆPrime Costï¼‰ã¯ã€ç›´æ¥ææ–™è²»ã¨ç›´æ¥åŠ´å‹™è²»ã®åˆè¨ˆã§ã™ã€‚ï¼ˆåŠ å·¥è²» ï¼ ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»ï¼‰"
        },
        {
            'level': 1,
            'q': "æ¨™æº–åŸä¾¡è¨ˆç®—: å®Ÿéš›æ¶ˆè²»é‡ãŒæ¨™æº–æ¶ˆè²»é‡ã‚’ä¸Šå›ã£ãŸå ´åˆã«ç™ºç”Ÿã™ã‚‹å·®ç•°ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æœ‰åˆ©æ•°é‡å·®ç•°", "ä¸åˆ©æ•°é‡å·®ç•°", "æœ‰åˆ©ä¾¡æ ¼å·®ç•°", "ä¸åˆ©ä¾¡æ ¼å·®ç•°"],
            'correct': 1,
            'explanation': "æ¨™æº–ã‚ˆã‚Šã‚‚å¤šãã®æ•°é‡ã‚’æ¶ˆè²»ã—ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ã‚³ã‚¹ãƒˆå¢—ã¨ãªã‚‹ãŸã‚ã€Œä¸åˆ©å·®ç•°ï¼ˆUnfavorableï¼‰ã€ã¨ãªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›´æ¥åŸä¾¡è¨ˆç®—: å›ºå®šè£½é€ é–“æ¥è²»ã¯ã©ã®ã‚ˆã†ã«å‡¦ç†ã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["è£½å“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "æœŸé–“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "è³‡ç”£ã¨ã—ã¦è¨ˆä¸Š", "è² å‚µã¨ã—ã¦è¨ˆä¸Š"],
            'correct': 1,
            'explanation': "ç›´æ¥åŸä¾¡è¨ˆç®—ã§ã¯ã€å›ºå®šè£½é€ é–“æ¥è²»ã¯ç™ºç”Ÿæ™‚ã«ã€ŒæœŸé–“åŸä¾¡ã€ã¨ã—ã¦å…¨é¡è²»ç”¨å‡¦ç†ã•ã‚Œã¾ã™ï¼ˆCVPåˆ†æã«æœ‰ç”¨ï¼‰ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡è¨ˆç®—åŸºæº–: åŸä¾¡è¨ˆç®—åŸºæº–ã«ãŠã„ã¦ã€åŸä¾¡è¨ˆç®—ã®ç›®çš„ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è²¡å‹™è«¸è¡¨ã®ä½œæˆ", "åŸä¾¡ç®¡ç†", "äºˆç®—çµ±åˆ¶", "å¾“æ¥­å“¡çµ¦ä¸ã®è¨ˆç®—"],
            'correct': 3,
            'explanation': "åŸä¾¡è¨ˆç®—åŸºæº–ã«ã¯ã€è²¡å‹™è«¸è¡¨ä½œæˆã€ä¾¡æ ¼è¨ˆç®—ã€åŸä¾¡ç®¡ç†ã€äºˆç®—ç®¡ç†ã€åŸºæœ¬è¨ˆç”»ç­–å®šã®5ã¤ã®ç›®çš„ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€çµ¦ä¸è¨ˆç®—ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "ABC (æ´»å‹•åŸºæº–åŸä¾¡è¨ˆç®—): è£½é€ é–“æ¥è²»ã‚’è£½å“ã«é…è³¦ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹åŸºæº–ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            'options': ["æ“æ¥­åº¦", "ã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ (æ´»å‹•åŸä¾¡è¦å› )", "ç›´æ¥ä½œæ¥­æ™‚é–“", "æ©Ÿæ¢°ç¨¼åƒæ™‚é–“"],
            'correct': 1,
            'explanation': "ABCã§ã¯ã€è£½é€ é–“æ¥è²»ã‚’æ´»å‹•ã”ã¨ã«æŠŠæ¡ã—ã€ãã‚Œãã‚Œã®æ´»å‹•ã®ç™ºç”Ÿè¦å› ã§ã‚ã‚‹ã€Œã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã€ã«åŸºã¥ã„ã¦è£½å“ã«é…è³¦ã—ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æŠ•è³‡ã®çµŒæ¸ˆæ€§è¨ˆç®—: ROI (æŠ•ä¸‹è³‡æœ¬åˆ©ç›Šç‡) ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["åˆ©ç›Š Ã· å£²ä¸Šé«˜", "å£²ä¸Šé«˜ Ã· æŠ•ä¸‹è³‡æœ¬", "åˆ©ç›Š Ã· æŠ•ä¸‹è³‡æœ¬", "æŠ•ä¸‹è³‡æœ¬ Ã· åˆ©ç›Š"],
            'correct': 2,
            'explanation': "ROI (Return On Investment) ã¯ã€åˆ©ç›Šã‚’æŠ•ä¸‹è³‡æœ¬ã§å‰²ã£ã¦ç®—å‡ºã—ã¾ã™ï¼ˆROI = å£²ä¸Šé«˜åˆ©ç›Šç‡ Ã— è³‡æœ¬å›è»¢ç‡ï¼‰ã€‚"
        },
        {
            'level': 2,
            'q': "CVPåˆ†æ: å›ºå®šè²»1,000ã€å¤‰å‹•è²»ç‡0.6ã€ç›®æ¨™åˆ©ç›Š200ã®å ´åˆã€ç›®æ¨™å£²ä¸Šé«˜ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["2,000", "3,000", "2,500", "1,200"],
            'correct': 1,
            'explanation': "ç›®æ¨™å£²ä¸Šé«˜ ï¼ (å›ºå®šè²» ï¼‹ ç›®æ¨™åˆ©ç›Š) Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ (1000 + 200) Ã· 0.4 ï¼ 3000 ã§ã™ã€‚"
        }
    ],
    'Audit': [
        {
            'level': 1,
            'q': "ç›£æŸ»ãƒªã‚¹ã‚¯: ç›£æŸ»ãƒªã‚¹ã‚¯ãƒ»ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆè¦ç´ ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºæœ‰ãƒªã‚¹ã‚¯ Ã— çµ±åˆ¶ãƒªã‚¹ã‚¯ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯", "ãƒ“ã‚¸ãƒã‚¹ãƒªã‚¹ã‚¯ Ã— ç›£æŸ»ãƒªã‚¹ã‚¯", "é‡è¦æ€§ Ã— ãƒªã‚¹ã‚¯", "æŠ½å‡ºãƒªã‚¹ã‚¯ Ã— éæŠ½å‡ºãƒªã‚¹ã‚¯"],
            'correct': 0,
            'explanation': "ç›£æŸ»ãƒªã‚¹ã‚¯ ï¼ é‡è¦ãªè™šå½è¡¨ç¤ºãƒªã‚¹ã‚¯ï¼ˆå›ºæœ‰ãƒªã‚¹ã‚¯Ã—çµ±åˆ¶ãƒªã‚¹ã‚¯ï¼‰ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç‹¬ç«‹æ€§: ã€Œå¤–è¦³çš„ç‹¬ç«‹æ€§ã€ã‚’æãªã†è¦å› ã¨ãªã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ä¿æœ‰", "èª å®Ÿã§ã‚ã‚‹ã“ã¨", "å°‚é–€èƒ½åŠ›ã‚’æœ‰ã™ã‚‹ã“ã¨", "å€«ç†è¦å®šã®éµå®ˆ"],
            'correct': 0,
            'explanation': "è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ã‚„é‡è¦ãªçµŒæ¸ˆçš„åˆ©å®³é–¢ä¿‚ã‚’æœ‰ã™ã‚‹ã“ã¨ã¯ã€å¤–è¦³çš„ç‹¬ç«‹æ€§ï¼ˆç¬¬ä¸‰è€…ã‹ã‚‰è¦‹ã¦ç‹¬ç«‹ã—ã¦ã„ã‚‹ã¨è¦‹ãˆã‚‹ã“ã¨ï¼‰ã‚’æãªã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»æ„è¦‹: è²¡å‹™è«¸è¡¨å…¨ä½“ã«é‡è¦ãªè™šå½è¡¨ç¤ºãŒã‚ã‚Šã€ã‹ã¤ãã®å½±éŸ¿ãŒåºƒç¯„ã§ã‚ã‚‹å ´åˆã«è¡¨æ˜ã•ã‚Œã‚‹æ„è¦‹ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç„¡é™å®šé©æ­£æ„è¦‹", "é™å®šä»˜é©æ­£æ„è¦‹", "ä¸é©æ­£æ„è¦‹", "æ„è¦‹ä¸è¡¨æ˜"],
            'correct': 2,
            'explanation': "é‡è¦ã‹ã¤åºƒç¯„ï¼ˆPervasiveï¼‰ãªè™šå½è¡¨ç¤ºãŒã‚ã‚‹å ´åˆã¯ã€ã€Œä¸é©æ­£æ„è¦‹ï¼ˆAdverse Opinionï¼‰ã€ãŒè¡¨æ˜ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "å†…éƒ¨çµ±åˆ¶: å†…éƒ¨çµ±åˆ¶ã®æ•´å‚™ãƒ»é‹ç”¨è²¬ä»»ã¯èª°ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            'options': ["ç›£æŸ»äºº", "çµŒå–¶è€…", "æ ªä¸»", "æ”¿åºœ"],
            'correct': 1,
            'explanation': "å†…éƒ¨çµ±åˆ¶ã‚’æ•´å‚™ã—é‹ç”¨ã™ã‚‹è²¬ä»»ã¯ã€ŒçµŒå–¶è€…ã€ã«ã‚ã‚Šã¾ã™ã€‚ç›£æŸ»äººã¯ãã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡ãƒ»å ±å‘Šã™ã‚‹ç«‹å ´ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»è¨¼æ‹ : ä¸€èˆ¬çš„ã«æœ€ã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã‚‹ç›£æŸ»è¨¼æ‹ ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµŒå–¶è€…ã¸ã®è³ªå•", "è¦³å¯Ÿ", "å¤–éƒ¨ç¢ºèª", "ç¤¾å†…æ–‡æ›¸"],
            'correct': 2,
            'explanation': "å¤–éƒ¨ã®ç¬¬ä¸‰è€…ã‹ã‚‰ç›´æ¥å…¥æ‰‹ã™ã‚‹ã€Œç¢ºèªï¼ˆExternal Confirmationï¼‰ã€ã¯ã€ä¸€èˆ¬ã«ç¤¾å†…è¨¼æ‹ ã‚ˆã‚Šã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸æ­£å¯¾å¿œ: ã€Œä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã€ã®3è¦ç´ ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼", "æ©Ÿä¼š", "å§¿å‹¢ãƒ»æ­£å½“åŒ–", "ç½°å‰‡"],
            'correct': 3,
            'explanation': "ä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã¯ã€ã€Œå‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã€ã€Œæ©Ÿä¼šã€ã€Œå§¿å‹¢ãƒ»æ­£å½“åŒ–ã€ã®3è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å ±å‘Šæ›¸: ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã„ã¤ã§ã‚ã‚‹ã¹ãã§ã™ã‹ï¼Ÿ",
            'options': ["æ±ºç®—æ—¥", "ç›£æŸ»äººãŒç›£æŸ»æ„è¦‹ã‚’å½¢æˆã™ã‚‹ã®ã«ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥", "æ ªä¸»ç·ä¼šé–‹å‚¬æ—¥", "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æå‡ºæ—¥"],
            'correct': 1,
            'explanation': "ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã€ç›£æŸ»äººãŒæ„è¦‹è¡¨æ˜ã®åŸºç¤ã¨ãªã‚‹ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥ï¼ˆç›£æŸ»çµ‚äº†æ—¥ï¼‰ã¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        }
    ],
    'Company': [
        {
            'level': 1,
            'q': "è¨­ç«‹: æ ªå¼ä¼šç¤¾ã®è¨­ç«‹ã«ãŠã‘ã‚‹æœ€ä½è³‡æœ¬é‡‘ã®é¡ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["1,000ä¸‡å††", "300ä¸‡å††", "1å††", "0å††"],
            'correct': 2,
            'explanation': "ç¾åœ¨ã®ä¼šç¤¾æ³•ã§ã¯ã€æœ€ä½è³‡æœ¬é‡‘åˆ¶åº¦ã¯æ’¤å»ƒã•ã‚Œã¦ãŠã‚Šã€è³‡æœ¬é‡‘1å††ã‹ã‚‰è¨­ç«‹ãŒå¯èƒ½ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è‡ªå·±æ ªå¼: æ ªå¼ä¼šç¤¾ã¯è‡ªå·±æ ªå¼ã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã‹ï¼Ÿ",
            'options': ["å®Œå…¨ã«ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹", "è²¡æºè¦åˆ¶ç­‰ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã‚‹", "è‡ªç”±ã«èªã‚ã‚‰ã‚Œã‚‹", "è§£æ•£æ™‚ã®ã¿èªã‚ã‚‰ã‚Œã‚‹"],
            'correct': 1,
            'explanation': "è‡ªå·±æ ªå¼ã®å–å¾—ã¯ã€åˆ†é…å¯èƒ½é¡ã®ç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚„æ ªä¸»ç·ä¼šæ±ºè­°ãªã©ã®è¦åˆ¶ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ©Ÿé–¢è¨­è¨ˆ: å–ç· å½¹ä¼šè¨­ç½®ä¼šç¤¾ã«ãŠã‘ã‚‹å–ç· å½¹ã®æœ€ä½äººæ•°ã¯ä½•äººã§ã™ã‹ï¼Ÿ",
            'options': ["1äºº", "2äºº", "3äºº", "5äºº"],
            'correct': 2,
            'explanation': "å–ç· å½¹ä¼šã‚’è¨­ç½®ã™ã‚‹å ´åˆã€å–ç· å½¹ã¯3äººä»¥ä¸Šå¿…è¦ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ç·ä¼š: ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ",
            'options': ["è­°æ±ºæ¨©ã®éåŠæ•°", "è­°æ±ºæ¨©ã®3åˆ†ã®1", "è­°æ±ºæ¨©ã®3åˆ†ã®2", "å…¨æ ªä¸»"],
            'correct': 0,
            'explanation': "ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã€Œè­°æ±ºæ¨©ã®éåŠæ•°ã€ã§ã™ï¼ˆå®šæ¬¾ã§3åˆ†ã®1ã¾ã§ç·©å’Œå¯ï¼‰ã€‚æ±ºè­°è¦ä»¶ã¯å‡ºå¸­æ ªä¸»ã®è­°æ±ºæ¨©ã®3åˆ†ã®2ä»¥ä¸Šã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å½¹: ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦ä½•å¹´ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´", "2å¹´", "4å¹´", "10å¹´"],
            'correct': 2,
            'explanation': "ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦4å¹´ã§ã™ã€‚å®šæ¬¾ã«ã‚ˆã£ã¦ã‚‚çŸ­ç¸®ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ã®æ¨©åˆ©: å˜ç‹¬æ ªä¸»æ¨©ï¼ˆ1æ ªã§ã‚‚ä¿æœ‰ã—ã¦ã„ã‚Œã°è¡Œä½¿ã§ãã‚‹æ¨©åˆ©ï¼‰ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æ ªä¸»ç·ä¼šæ‹›é›†è«‹æ±‚æ¨©", "å¸³ç°¿é–²è¦§è«‹æ±‚æ¨©", "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©", "å–ç· å½¹è§£ä»»è«‹æ±‚æ¨©"],
            'correct': 2,
            'explanation': "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©ã‚„è­°æ±ºæ¨©ã¯ã€1æ ªã‹ã‚‰èªã‚ã‚‰ã‚Œã‚‹å˜ç‹¬æ ªä¸»æ¨©ã§ã™ã€‚å¸³ç°¿é–²è¦§æ¨©ãªã©ã¯ä¸€å®šã®æ ªå¼æ•°ãƒ»æœŸé–“ãŒå¿…è¦ãªå°‘æ•°æ ªä¸»æ¨©ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "äº‹æ¥­è­²æ¸¡: æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã¨ãªã‚‹äº‹æ¥­è­²æ¸¡ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["äº‹æ¥­ã®å…¨éƒ¨ã¾ãŸã¯é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡", "é‡è¦ãªè³‡ç”£ã®å‡¦åˆ†", "å¤šé¡ã®å€Ÿè²¡", "æ”¯é…äººã®é¸ä»»"],
            'correct': 0,
            'explanation': "äº‹æ¥­ã®å…¨éƒ¨ã®è­²æ¸¡ã€ã¾ãŸã¯äº‹æ¥­ã®é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡ï¼ˆè­²æ¸¡è³‡ç”£ãŒç·è³‡ç”£ã®1/5è¶…ãªã©ï¼‰ã«ã¯ã€æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã§ã™ã€‚"
        }
    ]
}

# Load generated questions
json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
if os.path.exists(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            generated_questions = json.load(f)
            for subject, questions in generated_questions.items():
                if subject in drill_questions:
                    drill_questions[subject].extend(questions)
                else:
                    drill_questions[subject] = questions
    except Exception as e:
        st.error(f"Failed to load generated questions: {e}")

# Load Study Materials (Syllabus)
def load_study_materials():
    # Looking for 'studying' folder in 'platform' directory (moved inside)
    materials_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'studying')
    syllabus = {}
    extra_pdfs = []
    
    if not os.path.exists(materials_dir):
        return {}, []
        
    for filename in os.listdir(materials_dir):
        if filename.endswith('.xlsx') and not filename.startswith('~$'): # Ignore temp files
            try:
                # Extract subject from filename (e.g., "1-è²¡å‹™ä¼šè¨ˆè«–ã‚³ãƒ¼ã‚¹.xlsx" -> "è²¡å‹™ä¼šè¨ˆè«–")
                parts = filename.split('-')
                if len(parts) > 1:
                    subject_name = parts[1].replace('ã‚³ãƒ¼ã‚¹.xlsx', '')
                else:
                    subject_name = filename.replace('.xlsx', '')
                
                # Read Excel
                file_path = os.path.join(materials_dir, filename)
                df = pd.read_excel(file_path, header=1)
                
                # Fill merged cells (NaN) with previous value
                if 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚«ãƒ†ã‚´ãƒª'].ffill()
                if 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'].ffill()
                
                # Filter relevant columns
                if 'è¬›åº§å' in df.columns:
                    items = []
                    for _, row in df.iterrows():
                        if pd.notna(row['è¬›åº§å']):
                            items.append({
                                'category': row.get('ã‚«ãƒ†ã‚´ãƒª', ''),
                                'subcategory': row.get('ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª', ''),
                                'title': row['è¬›åº§å'],
                                'duration': row.get('å†ç”Ÿæ™‚é–“/æ¨™æº–æ™‚é–“', '')
                            })
                    
                    # Find corresponding PDF
                    pdf_path = os.path.join(materials_dir, filename.replace('.xlsx', '.pdf'))
                    has_pdf = os.path.exists(pdf_path)
                    
                    syllabus[subject_name] = {
                        'items': items,
                        'pdf_path': pdf_path if has_pdf else None,
                        'excel_path': file_path
                    }
            except Exception as e:
                print(f"Error loading {filename}: {e}")
    
    # Load extra PDFs from 'PDF' subdirectory
    pdf_dir = os.path.join(materials_dir, 'PDF')
    if os.path.exists(pdf_dir):
        for f in os.listdir(pdf_dir):
            if f.lower().endswith('.pdf'):
                extra_pdfs.append({
                    'name': f,
                    'path': os.path.join(pdf_dir, f)
                })
                
    # Also load standalone PDFs in the root of 'studying' that are not paired with an Excel file
    # Get list of PDF paths already associated with courses
    paired_pdfs = set()
    for subject_data in syllabus.values():
        if subject_data['pdf_path']:
            paired_pdfs.add(os.path.normpath(subject_data['pdf_path']))
            
    for filename in os.listdir(materials_dir):
        if filename.lower().endswith('.pdf'):
            full_path = os.path.join(materials_dir, filename)
            if os.path.normpath(full_path) not in paired_pdfs:
                extra_pdfs.append({
                    'name': filename,
                    'path': full_path
                })
                
    return syllabus, extra_pdfs

study_materials, extra_pdfs = load_study_materials()

roadmap_md = """
# CPA 1.5 Year Strategy Roadmap

## Phase 0: Foundation (2026)
* **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics.
* **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
* **Jul - Sep**: **CRITICAL** Start Tax Law & Electives.
* **Oct - Dec**: **Dec Short Exam Challenge**. Aim to pass!

## Phase 1: Short Exam Mastery (Jan - May 2027)
* **Jan - Mar**: Solidify basics. 75%+ in drills.
* **Apr - May**: Peak conditioning. Rote memorization.

## Phase 2: Essay Sprint (Jun - Aug 2027)
* **Jun**: Revive Tax/Elective knowledge.
* **Jul**: Output training (Writing).
* **Aug**: Final adjustments.
"""

# Navigation
st.sidebar.title("CPA Platform 2027")

# User Profile in Sidebar
with st.sidebar.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        st.markdown("### ğŸ“")
    with col2:
        curr_level = st.session_state.data.get('level', 1)
        st.write(f"**Level {curr_level}**")
    
    curr_xp = st.session_state.data.get('xp', 0)
    next_level_xp = curr_level * 100
    progress = min(curr_xp / next_level_xp, 1.0)
    st.progress(progress)
    st.caption(f"XP: {curr_xp} / {next_level_xp}")

st.sidebar.markdown("---")

# Quick Links
st.sidebar.markdown("""
    <style>
    .big-rocket-button {
        display: inline-block;
        width: 100%;
        padding: 12px;
        background: linear-gradient(135deg, #FF4B4B 0%, #FF0000 100%);
        color: white !important;
        text-align: center;
        font-size: 18px;
        font-weight: 900;
        border-radius: 12px;
        text-decoration: none !important;
        box-shadow: 0 4px 15px rgba(255, 0, 0, 0.4);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        border: 2px solid rgba(255, 255, 255, 0.2);
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .big-rocket-button:hover {
        background: linear-gradient(135deg, #FF0000 0%, #D00000 100%);
        transform: translateY(-2px) scale(1.02);
        box-shadow: 0 6px 20px rgba(255, 0, 0, 0.6);
        border-color: rgba(255, 255, 255, 0.5);
    }
    .big-rocket-button:active {
        transform: translateY(1px);
        box-shadow: 0 2px 10px rgba(255, 0, 0, 0.3);
    }
    </style>
    <a href="https://member.studying.jp/top/" target="_blank" class="big-rocket-button">
        ğŸš€ STUDYING
    </a>
    """, unsafe_allow_html=True)

st.sidebar.markdown("---")
with st.sidebar.expander("ğŸ“… Official Schedule (Edit)"):
    if 'schedule_edit' not in st.session_state:
        st.session_state.schedule_edit = [dict(item) for item in official_schedule]
    edit_rows = []
    for idx, item in enumerate(st.session_state.schedule_edit):
        d = st.date_input(f"Date {idx+1}", value=pd.to_datetime(item.get('date')).date(), key=f"sch_d_{idx}")
        c = st.selectbox(f"Category {idx+1}", options=["Exam", "Result"], index=0 if item.get('category','Exam')=='Exam' else 1, key=f"sch_c_{idx}")
        e = st.text_input(f"Event {idx+1}", value=item.get('event',''), key=f"sch_e_{idx}")
        n = st.text_input(f"Notes {idx+1}", value=item.get('notes',''), key=f"sch_n_{idx}")
        edit_rows.append({'date': d.strftime("%Y-%m-%d"), 'category': c, 'event': e, 'notes': n})
        st.markdown("---")
    if st.button("Add Row"):
        st.session_state.schedule_edit.append({'date': date.today().strftime("%Y-%m-%d"), 'category': 'Exam', 'event': '', 'notes': ''})
        st.rerun()
    if st.button("Save Schedule", type="primary"):
        st.session_state.data['official_schedule'] = edit_rows
        save_data(st.session_state.data)
        st.toast("Official schedule saved", icon="âœ…")
        official_schedule = edit_rows
page = st.sidebar.radio("Navigation", ["Dashboard ğŸ“Š", "My Syllabus ğŸ“š", "Vocabulary ğŸ“–", "Formulas ğŸ“", "Old Exams ğŸ“„", "Study Timer â±ï¸", "Mock Exams ğŸ“", "Scores ğŸ“ˆ", "Wrong Answers ğŸ“•", "Drills ğŸ”§", "Exam Mode â²ï¸", "Survival Mode âš¡", "Analytics ğŸ“Š", "Roadmap ğŸ—ºï¸", "Big 4 Job Hunting ğŸ’¼", "Company Directory ğŸ¢", "Future ğŸš€"])

if page == "Dashboard ğŸ“Š":
    st.header("Dashboard ğŸš€")
    
    # --- Top Metrics Row ---
    st.subheader("ğŸ“Š At a Glance")
    today = date.today()
    
    # Calculate Metrics
    # 1. Study Time Today
    logs_df = pd.DataFrame(st.session_state.data.get("logs", []))
    minutes_today = 0
    if not logs_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_logs = logs_df[logs_df['date'] == today_str]
        minutes_today = today_logs['duration'].sum()
    
    # 2. Quizzes Today
    scores_df = pd.DataFrame(st.session_state.data.get("scores", []))
    quizzes_today = 0
    avg_score_today = 0
    if not scores_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_scores = scores_df[scores_df['date'] == today_str]
        quizzes_today = len(today_scores)
        if quizzes_today > 0:
            avg_score_today = today_scores['val'].mean()

    # 3. Total XP
    total_xp = st.session_state.data.get('xp', 0)

    # Streak (consecutive study days up to today)
    streak = 0
    if not logs_df.empty:
        try:
            logs_df_dates = pd.to_datetime(logs_df['date']).dt.date
            logged = set(logs_df_dates[logs_df['duration'] > 0].unique())
            d = today
            while d in logged:
                streak += 1
                d = d - timedelta(days=1)
        except Exception:
            pass

    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Study Time (Today)", f"{minutes_today} min", delta=f"{minutes_today/60:.1f} hrs")
    m2.metric("Quizzes Completed", f"{quizzes_today}", delta=f"Avg: {avg_score_today:.0f}%" if quizzes_today > 0 else None)
    m3.metric("Total XP", f"{total_xp}", delta="Level Up Soon?" if total_xp % 100 > 80 else None)
    
    # 4. Nearest Deadline
    target_short = date(2026, 12, 13)
    days_short = (target_short - today).days
    m4.metric("Next Exam (Dec Short)", f"{days_short} Days", delta="-1 Day", delta_color="inverse")
    
    st.caption(f"ğŸ”¥ Study Streak: {streak} days")
    
    st.markdown("---")

    # --- Main Content Grid ---
    c_main_1, c_main_2 = st.columns([2, 1])
    
    with c_main_1:
        st.subheader("ğŸ—“ï¸ Exam Countdown")
        
        # Enhanced Countdown Cards
        cd1, cd2, cd3 = st.columns(3)
        
        with cd1:
            target = date(2026, 12, 13)
            diff = (target - today).days
            st.info(f"**Dec 2026 Short**\n\n# {max(0, diff)} Days\n\n*Target: 60%*")
            
        with cd2:
            target = date(2027, 5, 23)
            diff = (target - today).days
            st.warning(f"**May 2027 Short**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")
            
        with cd3:
            target = date(2027, 8, 20)
            diff = (target - today).days
            st.error(f"**Aug 2027 Essay**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")

        se = None
        try:
            sched_df = pd.DataFrame(official_schedule)
            if not sched_df.empty:
                sched_df['d'] = pd.to_datetime(sched_df['date']).dt.date
                future = sched_df[sched_df['d'] >= today]
                if not future.empty:
                    se = future.sort_values('d').iloc[0]
        except Exception:
            pass
        if se is not None:
            dd = (se['d'] - today).days
            st.info(f"**Next Official Event**: {se['event']} ({se['category']})\n\n# {dd} Days\n\n{se.get('notes','')}")

        # Weakness Analysis
        st.subheader("ğŸ§  Weak Areas Analysis")
        if not scores_df.empty:
            # Group by subject and calculate mean
            subject_perf = scores_df.groupby('subject')['val'].mean().sort_values()
            weakest_subject = subject_perf.index[0]
            weakest_score = subject_perf.iloc[0]
            
            st.markdown(f"""
            <div style="padding: 15px; border-radius: 10px; background-color: #fff3cd; border: 1px solid #ffeeba; color: #856404;">
                <h4>âš ï¸ Focus Area: {weakest_subject} ({weakest_score:.1f}%)</h4>
                <p>Your performance in <b>{weakest_subject}</b> is lower than other subjects. Consider doing a targeted drill.</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button(f"ğŸ”¥ Start {weakest_subject} Drill Now"):
                # Redirect logic (simulated by setting session state)
                # Note: Direct page switching in Streamlit is tricky without rerun, 
                # but we can set the quiz state to active for this subject
                # Ideally, user goes to Drills tab, but we can hint them.
                st.toast(f"Go to 'Drills' tab and select {weakest_subject}!", icon="ğŸ‘‰")
        else:
            st.info("Complete some drills to identify your weak areas.")

        # Recent Activity Chart (Last 7 Days)
        st.subheader("ğŸ“ˆ Study Consistency (Last 7 Days)")
        if not logs_df.empty:
            # Filter last 7 days
            logs_df['date'] = pd.to_datetime(logs_df['date']).dt.date
            last_7_days = [today - pd.Timedelta(days=i) for i in range(6, -1, -1)]
            
            daily_minutes = []
            for d in last_7_days:
                day_logs = logs_df[logs_df['date'] == d]
                daily_minutes.append(day_logs['duration'].sum())
            
            chart_data = pd.DataFrame({
                "Date": last_7_days,
                "Minutes": daily_minutes
            })
            
            fig_activity = px.bar(chart_data, x="Date", y="Minutes", title="Daily Study Time")
            st.plotly_chart(fig_activity, use_container_width=True)
        else:
            st.info("Log your study sessions to see your consistency chart.")


    with c_main_2:
        # Skill Radar
        st.subheader("Skills")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        radar_scores = [30] * 6 # Default
        
        if not scores_df.empty:
            avg_scores = []
            for sub in subjects:
                sub_df = scores_df[scores_df['subject'] == sub]
                if not sub_df.empty:
                    avg_scores.append(sub_df['val'].mean())
                else:
                    avg_scores.append(30) # Default baseline
            radar_scores = avg_scores
            
        fig = go.Figure(data=go.Scatterpolar(
            r=radar_scores,
            theta=subjects,
            fill='toself',
            name='Current Skill'
        ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])), 
            showlegend=False,
            margin=dict(l=20, r=20, t=20, b=20),
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Daily Tip Card
        st.subheader("ğŸ’¡ Daily Tip")
        tips = [
            "Consistency is key. 30 minutes every day is better than 5 hours once a week.",
            "Focus on 'why', not just 'how'. Understanding the logic helps in applied questions.",
            "Don't ignore the theory. It's 40-50% of the exam.",
            "Review your mistakes. The 'incorrect' options are learning opportunities.",
            "Sleep is part of studying. Memory consolidation happens during sleep.",
            "Use the 'Survival Mode' to build speed and accuracy under pressure!",
            "Audit isn't just memorization; imagine you are the auditor in that situation."
        ]
        import random
        st.info(random.choice(tips))
        
        # Progress
        st.subheader("Phase 0 Progress")
        st.progress(15)
        st.caption("Goal: Foundation Mastery")

elif page == "My Syllabus ğŸ“š":
    st.header("My Study Syllabus ğŸ“š")
    st.info("Based on your uploaded materials in 'studying' folder.")
    
    if not study_materials and not extra_pdfs:
        st.warning("No study materials found in 'studying' folder.")
    else:
        # Progress Tracking
        if 'syllabus_progress' not in st.session_state.data:
            st.session_state.data['syllabus_progress'] = []
            
        completed_items = set(st.session_state.data['syllabus_progress'])
        
        # Callback for checkbox
        def toggle_syllabus(key):
            if key in st.session_state.data['syllabus_progress']:
                st.session_state.data['syllabus_progress'].remove(key)
            else:
                st.session_state.data['syllabus_progress'].append(key)
                # Add XP for completing a lecture!
                st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + 50
                st.toast("Lecture Completed! +50 XP", icon="ğŸ“")
            save_data(st.session_state.data)

        # Tabs for subjects
        if study_materials:
            subjects = list(study_materials.keys())
            tabs = st.tabs(subjects)
            
            for i, subject in enumerate(subjects):
                with tabs[i]:
                    data = study_materials[subject]
                    items = data['items']
                    pdf_path = data['pdf_path']
                    excel_path = data['excel_path']
                    
                    # Header Actions
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        st.subheader(f"{subject} ({len(items)} Lectures)")
                    with c2:
                        if pdf_path:
                            if st.button(f"ğŸ“„ Open PDF", key=f"pdf_{subject}"):
                                try:
                                    os.startfile(pdf_path)
                                    st.toast(f"Opening {subject} PDF...", icon="ğŸš€")
                                except Exception as e:
                                    st.error(f"Cannot open PDF: {e}")
                        
                        if st.button(f"ğŸ“Š Open Excel", key=f"excel_{subject}"):
                            try:
                                os.startfile(excel_path)
                                st.toast(f"Opening {subject} Excel...", icon="ğŸ“Š")
                            except Exception as e:
                                st.error(f"Cannot open Excel: {e}")

                    
                    # Progress Bar for Subject
                    subject_completed = [item['title'] for item in items if f"{subject}|{item['title']}" in completed_items]
                    prog = len(subject_completed) / len(items) if items else 0
                    st.progress(prog)
                    st.caption(f"Progress: {len(subject_completed)} / {len(items)} ({prog:.1%})")
                    
                    # Group by Category/Subcategory
                    df = pd.DataFrame(items)
                    if not df.empty and 'category' in df.columns:
                        for cat, group in df.groupby('category'):
                            with st.expander(f"ğŸ“‚ {cat}", expanded=True):
                                for idx, row in group.iterrows():
                                    title = row['title']
                                    unique_key = f"{subject}|{title}"
                                    is_done = unique_key in completed_items
                                    
                                    c_chk, c_txt, c_time = st.columns([0.5, 4, 1.5])
                                    with c_chk:
                                        # Use subject and index to ensure widget key uniqueness
                                        st.checkbox("", value=is_done, key=f"chk_{subject}_{idx}", on_change=toggle_syllabus, kwargs={'key': unique_key})
                                    
                                    with c_txt:
                                        if is_done:
                                            st.markdown(f"~~{title}~~")
                                        else:
                                            st.markdown(f"**{title}**")
                                            if row['subcategory']:
                                                st.caption(f"â”” {row['subcategory']}")
                                                
                                    with c_time:
                                        st.caption(f"â±ï¸ {row['duration']}")

        # Supplemental Resources (Extra PDFs)
        if extra_pdfs:
            st.markdown("---")
            st.subheader("ğŸ“š Supplemental Resources")
            for i, pdf in enumerate(extra_pdfs):
                c1, c2 = st.columns([4, 1])
                with c1:
                    st.markdown(f"ğŸ“„ **{pdf['name']}**")
                with c2:
                    if st.button("Open", key=f"extra_pdf_{i}_{pdf['name']}"):
                        try:
                            os.startfile(pdf['path'])
                            st.toast(f"Opening {pdf['name']}...", icon="ğŸš€")
                        except Exception as e:
                            st.error(f"Cannot open PDF: {e}")

elif page == "Vocabulary ğŸ“–":
    st.header("Vocabulary Mastery ğŸ“–")
    st.info("Master the essential accounting terminology in Japanese and English.")

    # Create Tabs
    tab1, tab2 = st.tabs(["ğŸ“š Word List", "âš¡ Tap & Study (Flashcards)"])

    # --- TAB 1: Word List ---
    with tab1:
        st.subheader("Bilingual Terminology List")
        
        # Subject Selection
        subjects = list(vocab_data.keys())
        selected_subject = st.selectbox("Select Subject", subjects, key="vocab_list_subject")
        
        if selected_subject:
            terms = vocab_data[selected_subject]
            st.write(f"Found {len(terms)} terms for **{selected_subject}**.")
            
            for term in terms:
                with st.expander(f"**{term['term']}** ({term['jp']})"):
                    st.markdown(f"**ğŸ‡¯ğŸ‡µ Definition:** {term['desc']}")
                    st.markdown(f"**ğŸ‡ºğŸ‡¸ Definition:** {term.get('desc_en', 'No English definition available.')}")

    # --- TAB 2: Flashcards ---
    with tab2:
        st.subheader("âš¡ Flashcard Mode")
        st.markdown("Tap to flip the card, swipe (click next) to move to the next word.")
        
        # Initialize Session State for Flashcards
        if 'flashcard_active' not in st.session_state:
            st.session_state.flashcard_active = False
            st.session_state.flashcard_subject = subjects[0]
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False

        # Subject Selection for Flashcards
        fc_subject = st.selectbox("Select Subject for Study", subjects, key="fc_subject_selector")
        
        # Start/Reset Button
        if st.button("Start / Restart Session", type="primary"):
            st.session_state.flashcard_active = True
            st.session_state.flashcard_subject = fc_subject
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False
            st.rerun()

        if st.session_state.flashcard_active:
            current_terms = vocab_data.get(st.session_state.flashcard_subject, [])
            total_cards = len(current_terms)
            
            if total_cards == 0:
                st.warning("No words available for this subject.")
            else:
                current_idx = st.session_state.flashcard_index
                
                # Check if session is finished
                if current_idx >= total_cards:
                    st.balloons()
                    st.success(f"ğŸ‰ You've completed all {total_cards} words for {st.session_state.flashcard_subject}!")
                    if st.button("Start Over"):
                        st.session_state.flashcard_index = 0
                        st.session_state.flashcard_flipped = False
                        st.rerun()
                else:
                    word_data = current_terms[current_idx]
                    
                    # Progress Bar
                    progress = (current_idx + 1) / total_cards
                    st.progress(progress)
                    st.caption(f"Card {current_idx + 1} of {total_cards}")

                    # Card Container
                    card_container = st.container()
                    
                    # Card Logic
                    with card_container:
                        # Styling
                        st.markdown("""
                        <style>
                        .flashcard {
                            border: 2px solid #e0e0e0;
                            border-radius: 15px;
                            padding: 40px;
                            text-align: center;
                            background-color: white;
                            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                            min-height: 200px;
                            display: flex;
                            flex-direction: column;
                            justify-content: center;
                            align-items: center;
                            margin-bottom: 20px;
                        }
                        .flashcard-term { font-size: 28px; font-weight: bold; color: #1e88e5; }
                        .flashcard-jp { font-size: 24px; font-weight: bold; color: #d32f2f; margin-top: 10px;}
                        .flashcard-desc { font-size: 16px; color: #424242; margin-top: 15px; }
                        </style>
                        """, unsafe_allow_html=True)

                        if not st.session_state.flashcard_flipped:
                            # FRONT SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div style="color: #9e9e9e; margin-top: 20px;">(Tap 'Flip' to see meaning)</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            if st.button("ğŸ”„ Flip Card", use_container_width=True):
                                st.session_state.flashcard_flipped = True
                                st.rerun()
                                
                        else:
                            # BACK SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div class="flashcard-jp">{word_data['jp']}</div>
                                <div class="flashcard-desc">ğŸ‡¯ğŸ‡µ {word_data['desc']}</div>
                                <div class="flashcard-desc">ğŸ‡ºğŸ‡¸ {word_data.get('desc_en', '')}</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            col_prev, col_next = st.columns(2)
                            with col_prev:
                                if st.button("â¬…ï¸ Previous", use_container_width=True):
                                    if st.session_state.flashcard_index > 0:
                                        st.session_state.flashcard_index -= 1
                                        st.session_state.flashcard_flipped = False
                                        st.rerun()
                            
                            with col_next:
                                if st.button("Next â¡ï¸", use_container_width=True):
                                    st.session_state.flashcard_index += 1
                                    st.session_state.flashcard_flipped = False
                                    st.rerun()

elif page == "Formulas ğŸ“":
    st.header("Formulas ğŸ“")
    if not formulas_data:
        st.warning("No formulas found.")
    else:
        df_all_formulas = pd.DataFrame(formulas_data)
        st.subheader("Top Picks")
        show_picks = st.checkbox("Show Top Picks", value=True)
        if show_picks:
            cats_all = sorted({str(f.get("category", "General")) for f in formulas_data})
            size = st.radio("Size", [10, 30], horizontal=True)
            top10_names = [
                "Future Value (Single Sum)",
                "Present Value (Single Sum)",
                "Present Value of Annuity",
                "Contribution Margin",
                "Break-even Units",
                "Net Present Value",
                "WACC",
                "CAPM Cost of Equity",
                "ROE",
                "DuPont ROE"
            ]
            top30_names = top10_names + [
                "IRR",
                "Profitability Index",
                "Payback Period",
                "Present Value of Perpetuity",
                "Gordon Growth (DDM)",
                "Current Ratio",
                "Quick Ratio",
                "Debt-to-Equity",
                "Times Interest Earned",
                "Inventory Turnover",
                "Days Sales Outstanding",
                "Days Inventory Outstanding",
                "Cash Conversion Cycle",
                "Gross Profit Margin",
                "Operating Margin",
                "Net Profit Margin",
                "Economic Order Quantity (EOQ)",
                "Reorder Point",
                "Safety Stock",
                "Annuity Due PV",
                "Annuity Due FV",
                "Present Value (Annuity Due)",
                "Future Value (Annuity Due)"
            ]
            pick_names = top10_names if size == 10 else top30_names
            top_df = df_all_formulas[df_all_formulas["name"].isin(pick_names)].copy()
            if top_df.empty and not df_all_formulas.empty:
                top_df = df_all_formulas.head(size).copy()
                pick_names = list(top_df["name"])
            if len(top_df) < size and not df_all_formulas.empty:
                missing = size - len(top_df)
                fallback = df_all_formulas[~df_all_formulas["name"].isin(pick_names)].head(missing)
                top_df = pd.concat([top_df, fallback], ignore_index=True)
                pick_names = list(top_df["name"])
            order_map = {name: i for i, name in enumerate(pick_names)}
            top_cat = st.selectbox("Category Focus", ["All"] + cats_all)
            if top_cat != "All":
                top_df = top_df[top_df["category"] == top_cat]
            if not top_df.empty:
                top_df["rank"] = top_df["name"].map(order_map)
                top_df = top_df.sort_values("rank")
                tab1, tab2, tab3 = st.tabs(["Cards", "Table", "Category Chart"])
                with tab1:
                    cols = st.columns(2)
                    for idx, (_, r) in enumerate(top_df.iterrows()):
                        with cols[idx % 2]:
                            st.markdown(f"**{r.get('name','')}**")
                            st.caption(str(r.get('category', '')))
                            if r.get("latex", ""):
                                st.latex(r.get("latex", ""))
                            elif r.get("formula", ""):
                                st.code(str(r.get("formula", "")))
                with tab2:
                    st.table(top_df[["name", "category", "formula"]].rename(columns={"name": "Name", "category": "Category", "formula": "Formula"}))
                with tab3:
                    try:
                        import plotly.express as px
                        dfc = top_df.groupby("category").size().reset_index(name="count")
                        if not dfc.empty:
                            fig = px.bar(dfc, x="category", y="count", title=f"Top {size} by Category", color="category")
                            fig.update_layout(showlegend=False, xaxis_title="", yaxis_title="Count")
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("No data to chart for the selected filter.")
                    except Exception as e:
                        st.info("Plotly is unavailable for charting.")
            else:
                st.info("No formulas matched the current top selection.")
        st.divider()
        cats = sorted({str(f.get("category", "General")) for f in formulas_data})
        cat_sel = st.multiselect("Category", options=cats, default=[])
        q = st.text_input("Search")
        df_f = pd.DataFrame(formulas_data)
        if not df_f.empty:
            if cat_sel:
                df_f = df_f[df_f["category"].isin(cat_sel)]
            if q:
                ql = q.lower()
                def _has(r):
                    return (ql in str(r.get("name", "")).lower() or
                            ql in str(r.get("formula", "")).lower() or
                            ql in str(r.get("explanation", "")).lower() or
                            ql in str(r.get("variables", "")).lower())
                df_f = df_f[df_f.apply(_has, axis=1)]
        st.write(f"Found {len(df_f)} formulas.")
        for _, row in df_f.iterrows():
            title = row.get("name", "")
            cat = row.get("category", "")
            if cat:
                title = f"{title} [{cat}]"
            with st.expander(title):
                ftxt = row.get("formula", "")
                ltx = row.get("latex", "")
                if ltx:
                    st.latex(ltx)
                elif ftxt:
                    st.markdown(f"**Formula:** {ftxt}")
                vtxt = row.get("variables", "")
                if vtxt:
                    st.markdown(f"**Variables:** {vtxt}")
                etxt = row.get("explanation", "")
                if etxt:
                    st.markdown(etxt)
                ex_ja = _sanitize_text(row.get("example_ja", ""))
                ex_en = _sanitize_text(row.get("example_en", ""))
                if ex_ja or ex_en:
                    st.markdown("**Examples**")
                    if ex_ja:
                        st.markdown(f"ğŸ‡¯ğŸ‡µ {ex_ja}")
                    if ex_en:
                        st.markdown(f"ğŸ‡ºğŸ‡¸ {ex_en}")
                prob_ja = _sanitize_text(row.get("problem_ja", ""))
                prob_en = _sanitize_text(row.get("problem_en", ""))
                sol_ja = _sanitize_text(row.get("solution_ja", ""))
                sol_en = _sanitize_text(row.get("solution_en", ""))
                if prob_ja or prob_en:
                    st.markdown("**Practice Problem**")
                    if prob_ja:
                        st.markdown(f"ğŸ‡¯ğŸ‡µ {prob_ja}")
                    if prob_en:
                        st.markdown(f"ğŸ‡ºğŸ‡¸ {prob_en}")
                    if sol_ja or sol_en:
                        with st.expander("Show Solution"):
                            if sol_ja:
                                st.markdown(f"ğŸ‡¯ğŸ‡µ {sol_ja}")
                            if sol_en:
                                st.markdown(f"ğŸ‡ºğŸ‡¸ {sol_en}")
                with st.expander("Edit Examples / Problem"):
                    with st.form(f"form_edit_{row.get('name','')}"):
                        i_ex_ja = st.text_area("Example (JP)", value=_sanitize_text(ex_ja), height=100)
                        i_ex_en = st.text_area("Example (EN)", value=_sanitize_text(ex_en), height=100)
                        i_pb_ja = st.text_area("Problem (JP)", value=_sanitize_text(prob_ja), height=120)
                        i_pb_en = st.text_area("Problem (EN)", value=_sanitize_text(prob_en), height=120)
                        i_sol_ja = st.text_area("Solution (JP)", value=_sanitize_text(sol_ja), height=120)
                        i_sol_en = st.text_area("Solution (EN)", value=_sanitize_text(sol_en), height=120)
                        submitted = st.form_submit_button("Save")
                        if submitted:
                            key_name = row.get("name", "")
                            updated = False
                            for idx, item in enumerate(formulas_data):
                                if item.get("name", "") == key_name:
                                    formulas_data[idx]["example_ja"] = i_ex_ja
                                    formulas_data[idx]["example_en"] = i_ex_en
                                    formulas_data[idx]["problem_ja"] = i_pb_ja
                                    formulas_data[idx]["problem_en"] = i_pb_en
                                    formulas_data[idx]["solution_ja"] = i_sol_ja
                                    formulas_data[idx]["solution_en"] = i_sol_en
                                    updated = True
                                    break
                            if updated and save_formulas_data(formulas_data):
                                st.toast("Saved examples and problem.", icon="âœ…")
                                st.rerun()
                            else:
                                st.error("Failed to save. Please try again.")
elif page == "Old Exams ğŸ“„":
    st.header("Old Exam Papers ğŸ“„")
    
    # Path to EXAM folder
    # platform/app.py -> platform/EXAM
    base_dir = os.path.dirname(os.path.abspath(__file__))
    exam_dir = os.path.join(base_dir, 'EXAM')
    metadata_file = os.path.join(base_dir, 'exam_metadata.json')
    
    metadata = {}
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
        except Exception as e:
            st.error(f"Error loading metadata: {e}")

    with st.expander("ğŸ“ Exam Infoï¼ˆåˆæ ¼ãƒœãƒ¼ãƒ€ãƒ¼ R4ã€œR8ï¼‰", expanded=True):
        st.markdown("""
        ### çŸ­ç­”å¼ï¼ˆç›¸å¯¾è©•ä¾¡ï¼‰
        - åˆæ ¼åŸºæº–: ç·ç‚¹æ•°ã®70ï¼…ã‚’åŸºæº–ã¨ã—ã¦ã€å¯©æŸ»ä¼šãŒç›¸å½“ã¨èªã‚ãŸå¾—ç‚¹æ¯”ç‡
        - è¶³åˆ‡ã‚Š: 1ç§‘ç›®ã§ã‚‚æº€ç‚¹ã®40ï¼…æœªæº€ãŒã‚ã‚‹å ´åˆã€ä¸åˆæ ¼ã®å¯èƒ½æ€§ã‚ã‚Š
        
        å‚è€ƒï¼šè¿‘å¹´ã®ãƒœãƒ¼ãƒ€ãƒ¼ï¼ˆäºˆå‚™æ ¡ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢é›†è¨ˆï¼ä¸€éƒ¨å‚è€ƒå€¤ï¼‰
        
        | å®Ÿæ–½å¹´ | ç¬¬Iå›ï¼ˆ12æœˆï¼‰ | ç¬¬IIå›ï¼ˆ5æœˆï¼‰ | å‚™è€ƒ |
        |---|---:|---:|---|
        | ä»¤å’Œ8å¹´ (2026) | 72.0% | â€• | æœ€æ–°ï¼ˆç¬¬Iå›ã€çµæœ1æœˆå…¬è¡¨ï¼‰ |
        | ä»¤å’Œ7å¹´ (2025) | 70.4% | 74.0% | æ¨™æº–åŒ–ã®å‹•ã |
        | ä»¤å’Œ6å¹´ (2024) | 68.0% | 78.0% | æ˜“åŒ–ã§é«˜æ°´æº– |
        | ä»¤å’Œ5å¹´ (2023) | 71.0% | 70.2% | 70%å‰å¾Œ |
        | ä»¤å’Œ4å¹´ (2022) | 68.0% | 73.0% | å¤‰å‹•å¤§ |
        
        - å‡ºå…¸ï¼ˆå‚è€ƒå€¤ãƒ»è§£èª¬è¨˜äº‹ï¼‰:
          - ãƒã‚¤ãƒŠãƒ“ä¼šè¨ˆå£«ã€Œç¬¬â…¡å›çŸ­ç­”å¼è©¦é¨“ çµæœé€Ÿå ±ã€: https://cpa.mynavi.jp/column_mt/2024/06/967.html
          - çŸ­ç­”å¼ã®åˆæ ¼åŸºæº–ï¼ˆå…¬å¼ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/kijuntou/05.html
        
        ---
        ä¾‹: 500ç‚¹ Ã— 0.72 = 360ç‚¹
        
        ---
        ### è«–æ–‡å¼ï¼ˆåå·®å€¤æ–¹å¼ï¼‰
        - åˆæ ¼åŸºæº–: ç·ç‚¹æ•°ã®60ï¼…ã‚’åŸºæº–ã¨ã—ã¦ã€å¯©æŸ»ä¼šãŒç›¸å½“ã¨èªã‚ãŸå¾—ç‚¹æ¯”ç‡
        - è¶³åˆ‡ã‚Š: 1ç§‘ç›®ã§ã‚‚å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰ãŒ40ï¼…æœªæº€ã®ã‚‚ã®ãŒã‚ã‚‹å ´åˆã¯ä¸åˆæ ¼
        - å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰ã®ä¸€èˆ¬å¼: 50 + 10 Ã— (å€‹äººã®å¾—ç‚¹ âˆ’ å¹³å‡ç‚¹) / æ¨™æº–åå·®
        
        è¿‘å¹´ã®åˆæ ¼ç‚¹ï¼ˆå…¬è¡¨è³‡æ–™/å ±é“ãƒ™ãƒ¼ã‚¹ï¼‰
        - ä»¤å’Œ6å¹´ (2024): ç´„52.0å‰å¾Œï¼ˆæ¯å¹´å¾®èª¿æ•´ï¼‰
        - ä»¤å’Œ5å¹´ (2023): ç´„51.8å‰å¾Œï¼ˆå¾®èª¿æ•´ï¼‰
        - ä»¤å’Œ4å¹´ (2022): ç´„52.0å‰å¾Œï¼ˆåŸºæº–ã«è¿‘ã„ï¼‰
        - ä»¤å’Œ7å¹´ (2025): å…¬è¡¨ãƒšãƒ¼ã‚¸å‚ç…§ï¼ˆåå·®å€¤æ³•ã®èª¬æ˜ã‚ã‚Šï¼‰
        - ä»¤å’Œ8å¹´ (2026): å…¬è¡¨äºˆå®š
        
        - å‡ºå…¸ï¼ˆå…¬å¼ï¼‰:
          - åˆæ ¼åŸºæº–ã«ã¤ã„ã¦ï¼ˆçŸ­ç­”å¼/è«–æ–‡å¼ã®å…¬å¼åŸºæº–ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/kijuntou/05.html
          - ä»¤å’Œ7å¹´ è«–æ–‡å¼ åˆæ ¼ç‚¹ã®å…¬è¡¨ä¾‹ï¼ˆPDFã€åå·®å€¤æ³•ã®èª¬æ˜å«ã‚€ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/r7shiken/ronbungoukaku_r07/02.pdf
        """)
        # R4-R8 short-answer border mini chart
        try:
            df_borders = pd.DataFrame([
                {"Year": "R4 (2022)", "Session": "I (Dec)", "Border": 68.0},
                {"Year": "R4 (2022)", "Session": "II (May)", "Border": 73.0},
                {"Year": "R5 (2023)", "Session": "I (Dec)", "Border": 71.0},
                {"Year": "R5 (2023)", "Session": "II (May)", "Border": 70.2},
                {"Year": "R6 (2024)", "Session": "I (Dec)", "Border": 68.0},
                {"Year": "R6 (2024)", "Session": "II (May)", "Border": 78.0},
                {"Year": "R7 (2025)", "Session": "I (Dec)", "Border": 70.4},
                {"Year": "R7 (2025)", "Session": "II (May)", "Border": 74.0},
                {"Year": "R8 (2026)", "Session": "I (Dec)", "Border": 72.0},
            ])
            fig_border = px.bar(
                df_borders, x="Year", y="Border", color="Session", barmode="group",
                title="çŸ­ç­”å¼ åˆæ ¼ãƒœãƒ¼ãƒ€ãƒ¼ï¼ˆå‚è€ƒå€¤ï¼‰R4ã€œR8", range_y=[60, 80],
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            fig_border.update_layout(legend_title_text="Session", yaxis_title="Border (%)")
            st.plotly_chart(fig_border, use_container_width=True)
            st.caption("æ³¨: å‚è€ƒå€¤ï¼ˆäºˆå‚™æ ¡ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢é›†è¨ˆãƒ™ãƒ¼ã‚¹ï¼‰ã€‚å…¬å¼ã®ç›¸å¯¾åŸºæº–ã¯ãƒªãƒ³ã‚¯å‚ç…§ã€‚")
        except Exception:
            pass
    
    with st.expander("ğŸ†• ä»¤å’Œ7ãƒ»ä»¤å’Œ8 æƒ…å ±ï¼ˆãƒªãƒ³ã‚¯/äºˆå®šï¼‰", expanded=True):
        st.markdown("""
        - ä»¤å’Œ7å¹´ (2025)  
          - çŸ­ç­”å¼: å…¬å¼æ—¥ç¨‹ãƒ»åˆæ ¼åŸºæº–ã¯ CPAAOB å…¬è¡¨ãƒšãƒ¼ã‚¸ã‚’å‚ç…§  
          - è«–æ–‡å¼: ä¸Šè¨˜ãƒªãƒ³ã‚¯ï¼ˆåå·®å€¤æ–¹å¼ã®èª¬æ˜ä»˜ãï¼‰å‚ç…§
        - ä»¤å’Œ8å¹´ (2026)  
          - çŸ­ç­”å¼/è«–æ–‡å¼: é †æ¬¡å…¬è¡¨äºˆå®šï¼ˆä¾‹å¹´ã©ãŠã‚Šï¼‰
        
        å…¬å¼ãƒãƒ¼ã‚¿ãƒ«  
        - å…¬èªä¼šè¨ˆå£«ãƒ»ç›£æŸ»å¯©æŸ»ä¼šï¼ˆCPAAOBï¼‰è©¦é¨“æƒ…å ±: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/index.html
        """)
    
    with st.expander("ğŸ¯ çŸ­ç­” å¿…è¦å¾—ç‚¹è¨ˆç®—æ©Ÿ", expanded=False):
        # Target presets
        p1, p2, p3 = st.columns(3)
        with p1:
            if st.button("Target 70%"):
                st.session_state["tanto_target_pct"] = 70
                st.rerun()
        with p2:
            if st.button("Target 72%"):
                st.session_state["tanto_target_pct"] = 72
                st.rerun()
        with p3:
            if st.button("Target 78%"):
                st.session_state["tanto_target_pct"] = 78
                st.rerun()

        # Target slider
        col_t1, col_t2 = st.columns(2)
        with col_t1:
            default_target = st.session_state.get("tanto_target_pct", 72)
            target_pct = st.slider("ç›®æ¨™å¾—ç‚¹ç‡(%)", min_value=60, max_value=85, value=default_target, step=1, key="tanto_target_slider")
            target_points = int(500 * target_pct / 100)
            st.metric("å¿…è¦åˆè¨ˆç‚¹(500ç‚¹æº€ç‚¹)", f"{target_points} ç‚¹", f"{target_pct}%")
        with col_t2:
            st.caption("é…ç‚¹: ä¼æ¥­æ³•100ãƒ»ç®¡ç†100ãƒ»ç›£æŸ»100ãƒ»è²¡å‹™200")
        
        # Preset buttons for subject shares
        b1, b2, b3 = st.columns(3)
        with b1:
            if st.button("Preset: Balanced 70/70/70/70"):
                st.session_state["tanto_corp_pct"] = 70
                st.session_state["tanto_mgmt_pct"] = 70
                st.session_state["tanto_audit_pct"] = 70
                st.session_state["tanto_fin_pct"] = 70
                st.rerun()
        with b2:
            if st.button("Preset: Fin-Heavy 65/65/65/78"):
                st.session_state["tanto_corp_pct"] = 65
                st.session_state["tanto_mgmt_pct"] = 65
                st.session_state["tanto_audit_pct"] = 65
                st.session_state["tanto_fin_pct"] = 78
                st.rerun()
        with b3:
            if st.button("Preset: Safety 75/70/70/75"):
                st.session_state["tanto_corp_pct"] = 75
                st.session_state["tanto_mgmt_pct"] = 70
                st.session_state["tanto_audit_pct"] = 70
                st.session_state["tanto_fin_pct"] = 75
                st.rerun()

        # Inputs with keys to allow presets
        if "tanto_corp_pct" not in st.session_state:
            st.session_state["tanto_corp_pct"] = 70
        if "tanto_mgmt_pct" not in st.session_state:
            st.session_state["tanto_mgmt_pct"] = 70
        if "tanto_audit_pct" not in st.session_state:
            st.session_state["tanto_audit_pct"] = 70
        if "tanto_fin_pct" not in st.session_state:
            st.session_state["tanto_fin_pct"] = 70

        c1, c2 = st.columns(2)
        with c1:
            corp_pct = st.number_input("ä¼æ¥­æ³•(%)", min_value=0, max_value=100, value=st.session_state["tanto_corp_pct"], step=1, key="tanto_corp_pct")
            mgmt_pct = st.number_input("ç®¡ç†ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_mgmt_pct"], step=1, key="tanto_mgmt_pct")
        with c2:
            audit_pct = st.number_input("ç›£æŸ»è«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_audit_pct"], step=1, key="tanto_audit_pct")
            fin_pct = st.number_input("è²¡å‹™ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_fin_pct"], step=1, key="tanto_fin_pct")
        total_points = int(corp_pct/100*100 + mgmt_pct/100*100 + audit_pct/100*100 + fin_pct/100*200)
        total_pct = round(total_points / 500 * 100, 1)
        col_r1, col_r2, col_r3 = st.columns(3)
        with col_r1:
            st.metric("åˆè¨ˆå¾—ç‚¹ç‡", f"{total_pct}%")
        with col_r2:
            st.metric("åˆè¨ˆç‚¹", f"{total_points} ç‚¹")
        with col_r3:
            ok = (corp_pct >= 40) and (mgmt_pct >= 40) and (audit_pct >= 40) and (fin_pct >= 40)
            status = "OK" if (total_pct >= target_pct and ok) else "è¦æ”¹å–„"
            st.metric("é”æˆçŠ¶æ³", status)
        if not ok:
            st.warning("è¶³åˆ‡ã‚Šæ³¨æ„: ã„ãšã‚Œã‹ã®ç§‘ç›®ãŒ40%æœªæº€ã§ã™ã€‚")
        elif total_pct < target_pct:
            st.info("åˆè¨ˆãŒç›®æ¨™ã«å±Šã„ã¦ã„ã¾ã›ã‚“ã€‚å¼·åŒ–ç§‘ç›®ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.success("ç›®æ¨™é”æˆãƒ©ã‚¤ãƒ³ã§ã™ã€‚")
    
    with st.expander("ğŸ§® è«–æ–‡ åå·®å€¤è¨ˆç®—æ©Ÿ", expanded=False):
        col_e1, col_e2, col_e3 = st.columns(3)
        with col_e1:
            personal = st.number_input("å€‹äººã®å¾—ç‚¹", min_value=0.0, value=60.0, step=0.1)
        with col_e2:
            mean = st.number_input("å¹³å‡ç‚¹", min_value=0.0, value=55.0, step=0.1)
        with col_e3:
            std = st.number_input("æ¨™æº–åå·®", min_value=0.1, value=7.0, step=0.1)
        deviation = round(50 + 10 * (personal - mean) / std, 2)
        st.metric("å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰", f"{deviation}")
        if deviation < 40:
            st.warning("è¶³åˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã«æ³¨æ„ï¼ˆ40æœªæº€ï¼‰ã€‚")
        elif deviation < 52:
            st.info("åŸºæº–ç›®å®‰ 52 ã«æœªé”ã€‚å­¦ç¿’å¼·åŒ–ãŒå¿…è¦ã§ã™ã€‚")
        else:
            st.success("åˆæ ¼åŸºæº–ç›®å®‰ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")
    
    with st.expander("ğŸ“ åŸºæœ¬å¼ / Basic Formulas", expanded=False):
        st.markdown("""
        - çŸ­ç­” åˆè¨ˆç‚¹: åˆè¨ˆç‚¹ = 100Ã—ä¼æ¥­æ³•% + 100Ã—ç®¡ç†% + 100Ã—ç›£æŸ»% + 200Ã—è²¡å‹™%
        - çŸ­ç­” åˆè¨ˆå¾—ç‚¹ç‡: åˆè¨ˆå¾—ç‚¹ç‡(%) = åˆè¨ˆç‚¹ Ã· 500 Ã— 100
        - çŸ­ç­” åˆæ ¼æ¡ä»¶(ç›®å®‰): å…¨ç§‘ç›®40%ä»¥ä¸Š ã‹ã¤ åˆè¨ˆå¾—ç‚¹ç‡ â‰¥ ç›®æ¨™%
        - é€†ç®—ï¼ˆå¿…è¦ãªè²¡å‹™%ï¼‰: è²¡å‹™% = { (ç›®æ¨™%Ã—500/100) âˆ’ [100Ã—(ä¼æ¥­æ³•%+ç®¡ç†%+ç›£æŸ»%)] } Ã· 200 Ã— 100
        - è«–æ–‡ åå·®å€¤: D = 50 + 10 Ã— (x âˆ’ Î¼)/Ïƒ
        - è«–æ–‡ å¿…è¦å¾—ç‚¹: x = Î¼ + Ïƒ Ã— (D âˆ’ 50)/10
        """)
        col_rev1, col_rev2 = st.columns(2)
        with col_rev1:
            st.subheader("çŸ­ç­” é€†ç®—ï¼ˆå¿…è¦è²¡å‹™%ï¼‰")
            t_pct = st.number_input("ç›®æ¨™å¾—ç‚¹ç‡(%)", min_value=60, max_value=85, value=72, step=1, key="rev_target")
            rc = st.number_input("ä¼æ¥­æ³•(%)", min_value=0, max_value=100, value=70, step=1, key="rev_corp")
            rm = st.number_input("ç®¡ç†ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=70, step=1, key="rev_mgmt")
            ra = st.number_input("ç›£æŸ»è«–(%)", min_value=0, max_value=100, value=70, step=1, key="rev_audit")
            need_fin = ((t_pct/100*500) - (100*(rc+rm+ra))) / 200 * 100
            need_fin_disp = round(need_fin, 1)
            feas = 0 <= need_fin <= 100
            st.metric("å¿…è¦ è²¡å‹™ä¼šè¨ˆè«–(%)", f"{need_fin_disp}%")
            if not feas:
                st.warning("ã“ã®æ¡ä»¶ã§ã¯é”æˆä¸å¯èƒ½ã§ã™ï¼ˆ0ã€œ100%ã®ç¯„å›²å¤–ï¼‰ã€‚")
        with col_rev2:
            st.subheader("è«–æ–‡ å¿…è¦å¾—ç‚¹ï¼ˆé€†ç®—ï¼‰")
            d_target = st.number_input("ç›®æ¨™åå·®å€¤ D", min_value=35.0, max_value=70.0, value=52.0, step=0.1, key="rev_d")
            mu = st.number_input("å¹³å‡ç‚¹ Î¼", min_value=0.0, value=55.0, step=0.1, key="rev_mu")
            sigma = st.number_input("æ¨™æº–åå·® Ïƒ", min_value=0.1, value=7.0, step=0.1, key="rev_sigma")
            need_x = mu + sigma * (d_target - 50) / 10
            st.metric("å¿…è¦å¾—ç‚¹ x", f"{round(need_x, 2)}")

    if not os.path.exists(exam_dir):
        st.error(f"EXAM directory not found at: {exam_dir}")
    else:
        # --- Vocab Analysis Section ---
        vocab_file = os.path.join(base_dir, 'exam_vocab.json')
        if os.path.exists(vocab_file):
            with st.expander("ğŸ“Š Exam Vocabulary Analysis (Tangocho)", expanded=False):
                st.info("Top frequent words extracted from actual exam papers. Master these!")
                
                try:
                    with open(vocab_file, "r", encoding="utf-8") as f:
                        exam_vocab = json.load(f)
                    
                    # Subject selector
                    subjects = list(exam_vocab.keys())
                    if subjects:
                        selected_subject = st.selectbox("Select Subject for Vocabulary", subjects)
                        
                        if selected_subject:
                            words = exam_vocab[selected_subject]
                            
                            # Display as a dataframe or cloud
                            # Create a nice dataframe
                            df_vocab = pd.DataFrame(words)
                            df_vocab.columns = ["Word", "Frequency"]
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.dataframe(df_vocab, use_container_width=True, height=400)
                                
                            with col2:
                                if not df_vocab.empty:
                                    st.markdown("### Top Keywords")
                                    # Create a bar chart
                                    fig = px.bar(
                                        df_vocab.head(20), 
                                        x='Frequency', 
                                        y='Word', 
                                        orientation='h',
                                        title=f"Top 20 Words in {selected_subject}",
                                        color='Frequency',
                                        color_continuous_scale='Viridis'
                                    )
                                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"Error loading vocabulary: {e}")
        
        st.divider()

        files = [f for f in os.listdir(exam_dir) if f.lower().endswith('.pdf')]
        
        if not files:
            st.warning("No PDF exam papers found.")
        else:
            st.write(f"Found {len(files)} exam papers.")
            
            # Sort by filename to keep subjects grouped (01, 02, ...)
            for f in sorted(files):
                info = metadata.get(f, {})
                display_title = f"**{f}**"
                sub_info = ""
                
                if info:
                    # Construct nice title
                    # e.g. R7 Short-Answer (Tanto) I - Corporate Law (ä¼æ¥­æ³•)
                    year = info.get('year', '')
                    exam_type = info.get('type', '')
                    subject = info.get('subject', '')
                    
                    # Create a clean badge-like string
                    display_title = f"**{subject}** - {year} {exam_type}"
                    sub_info = f"Filename: {f}"
                
                with st.container():
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"ğŸ“„ {display_title}")
                        if sub_info:
                            st.caption(sub_info)
                    with col2:
                        if st.button("Open", key=f"open_exam_{f}"):
                            try:
                                file_path = os.path.join(exam_dir, f)
                                if os.name == 'nt':
                                    os.startfile(file_path)
                                    st.toast(f"Opening {f}...", icon="ğŸš€")
                                else:
                                    st.warning("File opening is only supported on Windows locally.")
                            except Exception as e:
                                st.error(f"Error opening file: {e}")
                    st.divider()
            
            st.info("ğŸ’¡ Tip: Use these papers to practice time management.")

elif page == "Study Timer â±ï¸":
    st.header("Study Timer")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Log Study Session")
        with st.form("timer_form"):
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective"])
            duration = st.number_input("Duration (minutes)", min_value=1, value=60)
            date_val = st.date_input("Date", value=date.today())
            submitted = st.form_submit_button("Log Session")
            
            if submitted:
                new_log = {
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'duration': duration
                }
                st.session_state.data["logs"].append(new_log)
                save_data(st.session_state.data)
                st.success("Session logged!")
                
    with col2:
        st.subheader("Recent Logs")
        if st.session_state.data["logs"]:
            df_logs = pd.DataFrame(st.session_state.data["logs"])
            st.dataframe(df_logs.sort_values('date', ascending=False))
            
            total_mins = df_logs['duration'].sum()
            hours = total_mins // 60
            mins = total_mins % 60
            st.metric("Total Study Time", f"{hours}h {mins}m")
        else:
            st.info("No logs yet.")

elif page == "Mock Exams ğŸ“":
    st.header("Exam Schedule")
    t1, t2 = st.tabs(["ğŸ“… Official Schedule", "ğŸ“ Mock Schedule"])
    with t1:
        df_off = pd.DataFrame(official_schedule)
        if not df_off.empty:
            df_off = df_off.sort_values('date')
            st.table(df_off)
            st.caption("æ³¨: åˆæ ¼ç™ºè¡¨æ—¥ã¯ç›®å®‰ã€‚æ­£å¼ãªæ—¥ç¨‹ãƒ»æ™‚åˆ»ã¯CPAAOBã®å…¬è¡¨ã«å¾“ã£ã¦ãã ã•ã„ã€‚")
        else:
            st.info("No official schedule available.")
    with t2:
        df_exams = pd.DataFrame(mock_exams)
        if not df_exams.empty:
            st.table(df_exams)
        else:
            st.info("No mock exams scheduled.")

elif page == "Scores ğŸ“ˆ":
    st.header("Score Tracker")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        with st.form("score_form"):
            name = st.text_input("Exam/Drill Name")
            date_val = st.date_input("Date", value=date.today())
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective", "Total"])
            val = st.number_input("Score (%)", min_value=0, max_value=100, value=70)
            submitted = st.form_submit_button("Save Score")
            
            if submitted:
                new_score = {
                    'name': name,
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'val': val
                }
                st.session_state.data["scores"].append(new_score)
                save_data(st.session_state.data)
                st.success("Score saved!")
                
    with col2:
        if st.session_state.data["scores"]:
            df = pd.DataFrame(st.session_state.data["scores"])
            st.subheader("History")
            st.dataframe(df.sort_values('date', ascending=False))
            st.download_button("Download Scores CSV", data=df.to_csv(index=False).encode('utf-8'), file_name="scores.csv", mime="text/csv")
            
            # Line Chart
            st.subheader("Trend")
            fig = go.Figure()
            for sub in df['subject'].unique():
                sub_df = df[df['subject'] == sub].sort_values('date')
                fig.add_trace(go.Scatter(x=sub_df['date'], y=sub_df['val'], mode='lines+markers', name=sub))
            fig.update_layout(yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No scores recorded yet.")

elif page == "Drills ğŸ”§":
    st.header("Drills âœï¸")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("Select Topic")
        subject = st.radio("Subject", ["Financial", "Management", "Audit", "Company"])
        
        st.subheader("Select Level")
        level = st.radio("Level", ["Level 1 (Basic)", "Level 2 (Standard)", "Level 3 (Advanced)", "Vocabulary (Important Words)"])
        level_map = {
            "Level 1 (Basic)": 1, 
            "Level 2 (Standard)": 2, 
            "Level 3 (Advanced)": 3,
            "Vocabulary (Important Words)": "vocab"
        }
        selected_level = level_map[level]
        
        if selected_level == "vocab":
            st.info("ğŸ’¡ Hint: These are key English terms often found in global accounting standards (IFRS/US GAAP).")
            
            # Add Tangocyo List View
            with st.expander("ğŸ“– View Vocabulary List (Tangocyo)"):
                vocab_list_view = vocab_data.get(subject, [])
                if vocab_list_view:
                    for v in vocab_list_view:
                        st.markdown(f"**{v['term']}** ({v['jp']})")
                        st.markdown(f"- ğŸ‡¯ğŸ‡µ {v['desc']}")
                        st.markdown(f"- ğŸ‡ºğŸ‡¸ {v.get('desc_en', '')}")
                        st.divider()
                else:
                    st.warning("No vocabulary data available.")
    
        # Load generated questions if available and not already loaded
        if 'generated_questions' not in st.session_state:
            try:
                with open('questions.json', 'r', encoding='utf-8') as f:
                    st.session_state.generated_questions = json.load(f)
            except FileNotFoundError:
                st.session_state.generated_questions = {}

        if st.button("Start / Restart Quiz"):
            import random
            st.session_state.quiz_state['active'] = True
            st.session_state.quiz_state['subject'] = subject
            st.session_state.quiz_state['level'] = selected_level
            st.session_state.quiz_state['q_index'] = 0
            st.session_state.quiz_state['score'] = 0
            st.session_state.quiz_state['show_feedback'] = False
            st.session_state.quiz_state['selected_option'] = None
            
            # Select questions based on level
            if selected_level == "vocab":
                vocab_list = vocab_data.get(subject, [])
                if vocab_list:
                    vocab_questions = []
                    for v in vocab_list:
                        vocab_questions.append({
                            'q': f"ã€é‡è¦èªå¥ã€‘ ã€Œ{v['term']}ã€ ã®æ„å‘³ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã¯ï¼Ÿ",
                            'options': [v['desc'], "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é€†ã®æ„å‘³ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: ç„¡é–¢ä¿‚ãªå®šç¾©ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é¡ä¼¼ç”¨èªã®å®šç¾©ï¼‰"],
                            'correct': 0,
                            'explanation': f"**{v['term']} ({v['jp']})**\n\n**ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª:** {v['desc']}\n\n**ğŸ‡ºğŸ‡¸ English:** {v.get('desc_en', 'No English description available.')}",
                            'type': 'vocab'
                        })
                    # Shuffle options for each question
                    for q in vocab_questions:
                        correct_opt = q['options'][0]
                        random.shuffle(q['options'])
                        q['correct'] = q['options'].index(correct_opt)
                    
                    st.session_state.quiz_state['questions'] = vocab_questions
                else:
                    st.warning(f"No vocabulary data for {subject} yet.")
                    st.session_state.quiz_state['active'] = False
            
            elif selected_level == 2 or selected_level == 3:
                # Use generated questions for Level 2/3
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level_gen_qs = [q for q in gen_qs if q.get('level') == selected_level]
                
                if level_gen_qs:
                     # Pick 10 random questions
                    if len(level_gen_qs) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(level_gen_qs, 10)
                    else:
                        st.session_state.quiz_state['questions'] = level_gen_qs
                else:
                    st.warning(f"No generated questions for {subject} Level {selected_level} yet.")
                    st.session_state.quiz_state['active'] = False

            else:
                # Level 1 (Static questions + Generated Level 0)
                raw_questions = drill_questions.get(subject, [])
                # Filter for Level 1 or undefined (legacy)
                static_level1 = [q for q in raw_questions if q.get('level', 1) == 1]
                
                # Fetch Level 0 from generated questions
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level0_gen_qs = [q for q in gen_qs if q.get('level') == 0]
                
                # Merge
                all_level1_questions = static_level1 + level0_gen_qs
                
                if all_level1_questions:
                    # Random sample if too many
                    if len(all_level1_questions) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(all_level1_questions, 10)
                    else:
                        st.session_state.quiz_state['questions'] = all_level1_questions
                else:
                    st.warning(f"No questions found for {subject} Level 1.")
                    st.session_state.quiz_state['active'] = False
                
    with col2:
        qs = st.session_state.quiz_state
        if qs['active']:
            current_q = qs['questions'][qs['q_index']]
            total_q = len(qs['questions'])
            
            st.subheader(f"Question {qs['q_index'] + 1} / {total_q}")
            st.markdown(f"**{current_q['q']}**")
            
            # Options
            options = current_q['options']
            
            # If feedback is shown, disable interaction or show result
            if qs['show_feedback']:
                for idx, opt in enumerate(options):
                    if idx == current_q['correct']:
                        st.markdown(f"<div class='correct-answer'>{opt} (Correct)</div>", unsafe_allow_html=True)
                    elif idx == qs['selected_option']:
                        st.markdown(f"<div class='incorrect-answer'>{opt} (Your Answer)</div>", unsafe_allow_html=True)
                    else:
                        st.text(opt)
                
                st.markdown("### Explanation")
                st.info(current_q['explanation'])
                if qs['selected_option'] is not None and qs['selected_option'] != current_q['correct']:
                    err = st.radio("Tag your error", ["careless", "concept", "guess", "time"], horizontal=True, key=f"err_{qs['q_index']}")
                    if st.button("Save Tag", key=f"save_err_{qs['q_index']}"):
                        idx = getattr(st.session_state, 'last_wrong_idx', None)
                        try:
                            if idx is not None and idx < len(st.session_state.data.get('wrong_answers', [])):
                                st.session_state.data['wrong_answers'][idx]['error_type'] = err
                                save_data(st.session_state.data)
                                st.toast("Tag saved", icon="âœ…")
                            else:
                                st.warning("No recent wrong answer to tag.")
                        except Exception:
                            pass
                
                if qs['q_index'] < total_q - 1:
                    if st.button("Next Question"):
                        qs['q_index'] += 1
                        qs['show_feedback'] = False
                        qs['selected_option'] = None
                        st.rerun()
                else:
                    score = qs['score']
                    st.success(f"Quiz Completed! Score: {score} / {total_q}")
                    
                    if st.button("Finish & Claim XP"):
                        # XP Logic
                        earned_xp = score * 10
                        current_xp = st.session_state.data.get('xp', 0)
                        current_level = st.session_state.data.get('level', 1)
                        
                        new_xp = current_xp + earned_xp
                        required_xp = current_level * 100
                        
                        leveled_up = False
                        while new_xp >= required_xp:
                            new_xp -= required_xp
                            current_level += 1
                            required_xp = current_level * 100
                            leveled_up = True
                        
                        st.session_state.data['xp'] = new_xp
                        st.session_state.data['level'] = current_level
                        
                        # Save score history
                        st.session_state.data["scores"].append({
                            'name': f"Drill: {qs.get('subject', 'General')} Lv{qs.get('level', '?')}",
                            'date': date.today().strftime("%Y-%m-%d"),
                            'subject': qs.get('subject', 'General'),
                            'val': (score / total_q) * 100 if total_q > 0 else 0
                        })
                        save_data(st.session_state.data)
                        
                        if leveled_up:
                            st.balloons()
                            st.success(f"LEVEL UP! You are now Level {current_level}!")
                        else:
                            st.success(f"Earned {earned_xp} XP!")
                            
                        qs['active'] = False
                        st.rerun()
                        
            else:
                choice = st.radio("Choose Answer:", options, index=None, key=f"q_{qs['q_index']}")
                conf = st.select_slider("Confidence (1-5)", options=[1,2,3,4,5], value=3, key=f"conf_{qs['q_index']}")
                if st.button("Submit Answer"):
                    if choice:
                        selected_idx = options.index(choice)
                        qs['selected_option'] = selected_idx
                        qs['show_feedback'] = True
                        if selected_idx != current_q['correct']:
                            wrong_entry = {
                                'date': date.today().strftime("%Y-%m-%d"),
                                'subject': qs.get('subject', 'General'),
                                'level': qs.get('level', None),
                                'q': current_q.get('q', ''),
                                'options': current_q.get('options', []),
                                'correct_idx': current_q.get('correct', None),
                                'selected_idx': selected_idx,
                                'explanation': current_q.get('explanation', ''),
                                'confidence': int(conf)
                            }
                            st.session_state.data.setdefault('wrong_answers', []).append(wrong_entry)
                            st.session_state.last_wrong_idx = len(st.session_state.data['wrong_answers']) - 1
                            save_data(st.session_state.data)
                        if selected_idx == current_q['correct']:
                            qs['score'] += 1
                        st.rerun()
                    else:
                        st.warning("Please select an option.")
        else:
            st.info("Select a subject and level from the sidebar to start.")

elif page == "Wrong Answers ğŸ“•":
    st.header("Wrong Answers")
    wa = st.session_state.data.get('wrong_answers', [])
    if not wa:
        st.info("No wrong answers recorded yet.")
    else:
        df = pd.DataFrame(wa)
        subjects = sorted([s for s in df['subject'].dropna().unique()])
        c1, c2, c3 = st.columns([2, 1, 1])
        with c1:
            sub = st.selectbox("Subject", ["All"] + subjects)
        with c2:
            n = st.number_input("Retry count", min_value=5, max_value=50, value=20)
        with c3:
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button("Download CSV", data=csv, file_name="wrong_answers.csv", mime="text/csv")
        cc1, cc2 = st.columns([1,1])
        with cc1:
            if st.button("Clear All", type="secondary"):
                st.session_state.data['wrong_answers'] = []
                save_data(st.session_state.data)
                st.rerun()
        if sub != "All":
            df = df[df['subject'] == sub]
        st.dataframe(df[['date','subject','level','q']].sort_values('date', ascending=False), use_container_width=True)
        if not df.empty:
            if st.button("Retry 20"):
                import random
                sample = df.sample(min(len(df), n)).to_dict(orient='records')
                qs = []
                for r in sample:
                    opts = r.get('options', [])
                    correct_idx = r.get('correct_idx', None)
                    if opts and correct_idx is not None:
                        qs.append({
                            'q': r.get('q',''),
                            'options': opts,
                            'correct': correct_idx,
                            'explanation': r.get('explanation','')
                        })
                if qs:
                    st.session_state.quiz_state['active'] = True
                    st.session_state.quiz_state['subject'] = sub if sub != "All" else "Mixed"
                    st.session_state.quiz_state['level'] = "Retry"
                    st.session_state.quiz_state['q_index'] = 0
                    st.session_state.quiz_state['score'] = 0
                    st.session_state.quiz_state['show_feedback'] = False
                    st.session_state.quiz_state['selected_option'] = None
                    st.session_state.quiz_state['questions'] = qs
                    st.toast("Retry started", icon="âœ…")
                    st.rerun()

elif page == "Exam Mode â²ï¸":
    st.header("Exam Mode")
    if 'exam' not in st.session_state:
        st.session_state.exam = {'active': False, 'start_ts': None, 'duration_min': 30, 'q_index': 0, 'questions': [], 'answers': [], 'finished': False, 'subject': 'Mixed'}
    ex = st.session_state.exam
    if not ex['active'] and not ex['finished']:
        subject = st.selectbox("Subject", ["Mixed", "Financial", "Management", "Audit", "Company"])
        qcount = st.number_input("Number of Questions", min_value=10, max_value=60, value=20, step=5)
        duration = st.number_input("Time Limit (minutes)", min_value=10, max_value=180, value=60, step=5)
        if st.button("Start Exam", type="primary", use_container_width=True):
            import time, random
            ex['active'] = True
            ex['finished'] = False
            ex['start_ts'] = int(time.time())
            ex['duration_min'] = int(duration)
            ex['q_index'] = 0
            pool = []
            if subject == "Mixed":
                for sub, qs in drill_questions.items():
                    for q in qs:
                        qx = q.copy()
                        qx['subject'] = sub
                        pool.append(qx)
            else:
                for q in drill_questions.get(subject, []):
                    qx = q.copy()
                    qx['subject'] = subject
                    pool.append(qx)
            random.shuffle(pool)
            ex['questions'] = pool[:int(qcount)]
            ex['answers'] = [None] * len(ex['questions'])
            ex['subject'] = subject
            st.rerun()
    elif ex['active'] and not ex['finished']:
        import time
        now = int(time.time())
        elapsed = now - int(ex['start_ts'])
        remain = max(0, ex['duration_min'] * 60 - elapsed)
        mm = remain // 60
        ss = remain % 60
        st.metric("Time Remaining", f"{mm:02d}:{ss:02d}")
        if remain == 0:
            ex['finished'] = True
            ex['active'] = False
            st.rerun()
        q = ex['questions'][ex['q_index']]
        st.markdown(f"**[{q.get('subject','')}] Q{ex['q_index']+1}/{len(ex['questions'])}**")
        st.write(q['q'])
        key = f"exam_{ex['q_index']}"
        sel = st.radio("Select answer", q['options'], index=ex['answers'][ex['q_index']] if ex['answers'][ex['q_index']] is not None else None, key=key)
        if st.button("Save Answer"):
            ex['answers'][ex['q_index']] = q['options'].index(sel) if sel else None
            st.rerun()
        c1, c2, c3 = st.columns(3)
        with c1:
            if st.button("Prev") and ex['q_index'] > 0:
                ex['q_index'] -= 1
                st.rerun()
        with c2:
            if st.button("Next") and ex['q_index'] < len(ex['questions']) - 1:
                ex['q_index'] += 1
                st.rerun()
        with c3:
            if st.button("Finish Now", type="primary"):
                ex['finished'] = True
                ex['active'] = False
                st.rerun()
    else:
        corrects = 0
        for i, q in enumerate(st.session_state.exam['questions']):
            a = st.session_state.exam['answers'][i]
            if a is not None and a == q.get('correct'):
                corrects += 1
        total = max(1, len(st.session_state.exam['questions']))
        percent = round(corrects / total * 100, 1)
        st.success(f"Finished. Score: {corrects}/{total} ({percent}%)")
        earned_xp = corrects * 10
        curr_xp = st.session_state.data.get('xp', 0)
        curr_level = st.session_state.data.get('level', 1)
        new_xp = curr_xp + earned_xp
        req = curr_level * 100
        leveled = False
        while new_xp >= req:
            new_xp -= req
            curr_level += 1
            req = curr_level * 100
            leveled = True
        st.session_state.data['xp'] = new_xp
        st.session_state.data['level'] = curr_level
        st.session_state.data["scores"].append({
            'name': f"Exam Mode ({st.session_state.exam.get('subject','Mixed')})",
            'date': date.today().strftime("%Y-%m-%d"),
            'subject': st.session_state.exam.get('subject','Mixed'),
            'val': percent
        })
        save_data(st.session_state.data)
        if earned_xp > 0:
            if leveled:
                st.balloons()
                st.success(f"+{earned_xp} XP, Level {curr_level}")
            else:
                st.info(f"+{earned_xp} XP added")
        with st.expander("Review"):
            for i, q in enumerate(st.session_state.exam['questions']):
                st.markdown(f"**Q{i+1}.** {q['q']}")
                a = st.session_state.exam['answers'][i]
                for idx, opt in enumerate(q['options']):
                    if idx == q.get('correct'):
                        st.markdown(f"- âœ… {opt}")
                    elif a is not None and idx == a:
                        st.markdown(f"- âŒ {opt}")
                    else:
                        st.markdown(f"- {opt}")
                st.caption(q.get('explanation',''))
                st.divider()
        if st.button("Reset Exam"):
            st.session_state.exam = {'active': False, 'start_ts': None, 'duration_min': 30, 'q_index': 0, 'questions': [], 'answers': [], 'finished': False, 'subject': 'Mixed'}
            st.rerun()

elif page == "Survival Mode âš¡":
    st.header("âš¡ Survival Mode")
    st.markdown("### Challenge your limits! 3 Strikes and you're out.")
    
    # Initialize State
    if 'survival' not in st.session_state:
        st.session_state.survival = {
            'active': False,
            'lives': 3,
            'streak': 0,
            'score': 0,
            'q': None,
            'feedback': False,
            'user_ans': None,
            'target_streak': "Unlimited"
        }
    
    ss = st.session_state.survival
    
    # Load Questions Logic
    if 'all_questions' not in st.session_state:
        all_qs = []
        # Static
        for sub, qs in drill_questions.items():
            for q in qs:
                # Create a copy to avoid modifying original
                q_copy = q.copy()
                q_copy['subject'] = sub
                all_qs.append(q_copy)
        # Generated
        json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
        if os.path.exists(json_path):
             try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gen_qs = json.load(f)
                    for sub, qs in gen_qs.items():
                        for q in qs:
                            q_copy = q.copy()
                            q_copy['subject'] = sub
                            all_qs.append(q_copy)
             except:
                 pass
        st.session_state.all_questions = all_qs
    
    if not ss['active']:
        st.subheader("Select Challenge Mode")
        streak_target = st.radio("Target Streak", ["Unlimited", 1, 5, 10], horizontal=True, format_func=lambda x: "âˆ Unlimited" if x == "Unlimited" else f"Target: {x} ğŸ”¥")

        if st.button("ğŸš€ Start Challenge", use_container_width=True):
            ss['active'] = True
            ss['lives'] = 3
            ss['streak'] = 0
            ss['score'] = 0
            ss['q'] = None
            ss['feedback'] = False
            ss['target_streak'] = streak_target
            st.rerun()
            
    else:
        # Metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("Lives", "â¤ï¸" * ss['lives'])
        target_display = "âˆ" if ss.get('target_streak', "Unlimited") == "Unlimited" else ss['target_streak']
        c2.metric("Streak", f"ğŸ”¥ {ss['streak']} / {target_display}")
        c3.metric("Score", ss['score'])
        
        target = ss.get('target_streak', "Unlimited")
        is_win = target != "Unlimited" and ss['streak'] >= target

        if ss['lives'] <= 0 or is_win:
            if is_win:
                st.balloons()
                st.success(f"ğŸ‰ MISSION ACCOMPLISHED! You reached a {ss['streak']} streak!")
            else:
                st.error("ğŸ’€ GAME OVER")
            
            st.markdown(f"### Final Score: {ss['score']}")
            
            # Save High Score
            if ss['score'] > 0:
                st.session_state.data["scores"].append({
                    'name': f"Survival Mode âš¡ (Target {target})",
                    'date': date.today().strftime("%Y-%m-%d"),
                    'subject': 'Survival',
                    'val': ss['score'] # Just storing score
                })
                save_data(st.session_state.data)
            
            if st.button("Try Again", use_container_width=True):
                ss['active'] = False
                st.rerun()
        else:
            # Get Question
            if ss['q'] is None:
                import random
                if st.session_state.all_questions:
                    q_data = random.choice(st.session_state.all_questions)
                    # Shuffle options
                    opts = q_data['options'].copy()
                    correct_text = q_data['options'][q_data['correct']]
                    random.shuffle(opts)
                    
                    ss['q'] = {
                        'q': q_data['q'],
                        'options': opts,
                        'correct_idx': opts.index(correct_text),
                        'explanation': q_data['explanation'],
                        'subject': q_data.get('subject', 'General')
                    }
                else:
                    st.error("No questions found!")
                    st.stop()
            
            q = ss['q']
            
            st.markdown(f"**[{q['subject']}]** {q['q']}")
            
            if not ss['feedback']:
                # Use a form to prevent reload on radio selection
                with st.form(key=f"surv_form_{ss['score']}_{ss['lives']}"):
                    ans = st.radio("Select Answer:", q['options'])
                    submit = st.form_submit_button("Submit Answer")
                    
                    if submit:
                        ss['user_ans'] = q['options'].index(ans)
                        ss['feedback'] = True
                        
                        if ss['user_ans'] == q['correct_idx']:
                            # Bonus XP for streak
                            bonus = ss['streak'] * 2
                            points = 10 + bonus
                            ss['score'] += points
                            ss['streak'] += 1
                            st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + points
                            st.toast(f"Correct! +{points} XP", icon="âœ…")
                            
                            # Check Win
                            target = ss.get('target_streak', "Unlimited")
                            if target != "Unlimited" and ss['streak'] >= target:
                                st.rerun()
                        else:
                            ss['lives'] -= 1
                            ss['streak'] = 0
                            st.toast("Wrong Answer!", icon="âŒ")
                        
                        st.rerun()
            else:
                # Show Feedback
                if ss['user_ans'] == q['correct_idx']:
                    st.success("âœ… Correct!")
                else:
                    st.error(f"âŒ Wrong! Correct: {q['options'][q['correct_idx']]}")
                
                st.info(f"**Explanation:**\n\n{q['explanation']}")
                
                if st.button("Next Question â¡", use_container_width=True):
                    ss['q'] = None
                    ss['feedback'] = False
                    st.rerun()

elif page == "Analytics ğŸ“Š":
    st.header("Analytics")
    scores_df = pd.DataFrame(st.session_state.data.get("scores", []))
    logs_df = pd.DataFrame(st.session_state.data.get("logs", []))
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Skill Radar")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        radar_scores = [30] * 6
        if not scores_df.empty:
            vals = []
            for sub in subjects:
                sub_df = scores_df[scores_df['subject'] == sub]
                if not sub_df.empty:
                    vals.append(sub_df['val'].mean())
                else:
                    vals.append(30)
            radar_scores = vals
        fig = go.Figure(data=go.Scatterpolar(r=radar_scores, theta=subjects, fill='toself', name='Avg'))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False, height=350)
        st.plotly_chart(fig, use_container_width=True)
    with c2:
        st.subheader("Pacing Histogram")
        if not logs_df.empty:
            logs_df['date'] = pd.to_datetime(logs_df['date'])
            logs_df['minutes'] = logs_df['duration']
            st.plotly_chart(px.histogram(logs_df, x='minutes', nbins=20, title="Study Session Lengths"), use_container_width=True)
        else:
            st.info("No study logs")
    st.subheader("Weekly Heatmap")
    if not logs_df.empty:
        logs_df['date'] = pd.to_datetime(logs_df['date']).dt.date
        df = logs_df.groupby('date')['duration'].sum().reset_index()
        df['dow'] = pd.to_datetime(df['date']).dt.dayofweek
        df['week'] = pd.to_datetime(df['date']).dt.isocalendar().week
        pivot = df.pivot_table(index='dow', columns='week', values='duration', fill_value=0)
        st.dataframe(pivot)
    else:
        st.info("No data for heatmap")
elif page == "Roadmap ğŸ—ºï¸":
    st.header("ğŸ—ºï¸ CPA Exam Strategy Roadmap (2026-2027)")
    
    # 1. Countdown Section
    today = date.today()
    tanto_date = date(2027, 5, 23) # Estimated
    ronbun_date = date(2027, 8, 20) # Estimated
    
    days_tanto = (tanto_date - today).days
    days_ronbun = (ronbun_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Days to May Short Exam", f"{days_tanto} Days", "Target: Pass")
    col2.metric("Days to Aug Essay Exam", f"{days_ronbun} Days", "Final Goal")
    col3.metric("Current Phase", "Foundation (2026)", "Build Habits")
    
    st.divider()

    # 2. Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Visual Schedule (Gantt)", "ğŸ—“ï¸ Monthly Strategy", "â° Daily Routine"])
    
    with tab1:
        st.subheader("Strategic Timeline")
        # Gantt Chart Data
        df_gantt = pd.DataFrame([
            dict(Task="Foundation (Fin/Mgmt)", Start='2026-02-01', Finish='2026-06-30', Phase='Phase 0: Foundation'),
            dict(Task="Audit & Company Law", Start='2026-04-01', Finish='2026-09-30', Phase='Phase 0: Foundation'),
            dict(Task="Tax Law & Electives", Start='2026-07-01', Finish='2026-12-31', Phase='Phase 0: Foundation'),
            dict(Task="Dec Short (Practice)", Start='2026-10-01', Finish='2026-12-13', Phase='Phase 0: Foundation'),
            dict(Task="Short Exam Mastery", Start='2027-01-01', Finish='2027-05-23', Phase='Phase 1: Short Exam'),
            dict(Task="Essay Sprint", Start='2027-05-24', Finish='2027-08-20', Phase='Phase 2: Essay Sprint'),
        ])
        
        # Create Gantt
        fig = px.timeline(df_gantt, x_start="Start", x_end="Finish", y="Task", color="Phase", 
                          title="CPA Exam 1.5 Year Plan",
                          color_discrete_sequence=px.colors.qualitative.Prism)
        fig.update_yaxes(autorange="reversed") # Task order top-to-bottom
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("ğŸ’¡ **Golden Route**: Pass May Short -> Pass August Essay in one go.")
        
        with st.expander("ğŸ“… Official Dates & Announcements"):
            try:
                df_off2 = pd.DataFrame(official_schedule).sort_values('date')
                st.table(df_off2)
                st.caption("æ³¨: åˆæ ¼ç™ºè¡¨æ—¥ã¯ç›®å®‰ã€‚æ­£å¼ãªå…¬è¡¨ã«å¾“ã£ã¦éšæ™‚æ›´æ–°ã€‚")
            except Exception as e:
                st.error(f"Failed to load official schedule: {e}")

    with tab2:
        st.subheader("Detailed Monthly Strategy")
        
        with st.expander("Phase 0: Foundation (2026)", expanded=True):
            st.markdown("""
            *   **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics (Calculations).
            *   **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
            *   **Jul - Sep**: **CRITICAL** Start Tax Law & Electives (Management/Statistics).
            *   **Oct - Dec**: **Dec Short Exam Challenge**. Aim for 60%+ even if you fail.
            """)
            
        with st.expander("Phase 1: Short Exam Mastery (Jan - May 2027)"):
            st.markdown("""
            *   **Jan - Mar**: Solidify basics. Aim for 75%+ in drills. Focus on weak areas.
            *   **Apr**: Mock Exams (TAC/Ohara). Analyze errors thoroughly.
            *   **May**: Peak conditioning. Rote memorization of text (Audit/Company Law). **PASS EXAM**.
            """)
            
        with st.expander("Phase 2: Essay Sprint (Jun - Aug 2027)"):
            st.markdown("""
            *   **Jun**: Revive Tax/Elective knowledge (often forgotten during Short prep).
            *   **Jul**: Output training (Writing). Learn "Key Phrases" for theory questions.
            *   **Aug**: Final adjustments. Health management is key. **PASS EXAM**.
            """)

    with tab3:
        st.subheader("â° Ideal Daily Routine (Student/Full-time Study)")
        
        schedule_data = [
            {"Time": "07:00 - 08:00", "Activity": "Wake up / Light Breakfast / Review Vocab"},
            {"Time": "08:00 - 11:00", "Activity": "ğŸ§  **Deep Work 1**: Financial Accounting (Calc) - 3h"},
            {"Time": "11:00 - 12:00", "Activity": "Lunch / Nap (20m)"},
            {"Time": "12:00 - 15:00", "Activity": "ğŸ§  **Deep Work 2**: Management Accounting / Theory - 3h"},
            {"Time": "15:00 - 16:00", "Activity": "Gym / Walk / Break"},
            {"Time": "16:00 - 19:00", "Activity": "ğŸ§  **Deep Work 3**: Corporate Law / Audit - 3h"},
            {"Time": "19:00 - 20:00", "Activity": "Dinner / Relax"},
            {"Time": "20:00 - 22:00", "Activity": "ğŸ“– **Review**: Weak areas / Next day planning - 2h"},
            {"Time": "22:00 - 23:00", "Activity": "Wind down / Sleep"},
        ]
        st.table(pd.DataFrame(schedule_data))
        st.success("Target: **10+ Hours/Day** of high-quality study.")

elif page == "Big 4 Job Hunting ğŸ’¼":
    st.header("ğŸ¢ Big 4 CPA Job Hunting Strategy")
    st.markdown("Strategy guide and comparison for the major audit firms in Japan.")

    tab1, tab2, tab_depts, tab3, tab4, tab5 = st.tabs(["Strategy & Timeline", "Big 4 Comparison", "Departments (FAS/Tax/...) ğŸ¢", "Tech & Data Science Advantage ğŸ¤–", "Boston Career Forum ğŸ‡ºğŸ‡¸", "Interview & Case Prep ğŸ“"])

    with tab1:
        st.subheader("ğŸ“… Job Hunting Timeline (Typical)")
        st.info("The job hunting season for CPA candidates peaks immediately after the August Essay Exam.")
        
        timeline_data = [
            {"Period": "August (Late)", "Activity": "Essay Exam Ends", "Details": "Rest for a few days, then prepare for briefings."},
            {"Period": "September", "Activity": "Firm Briefings (Setsumeikai)", "Details": "Attend online/offline sessions. Key for networking."},
            {"Period": "October", "Activity": "Entry Sheet (ES) Submission", "Details": "Prepare resumes. Focus on 'Why this firm?'"},
            {"Period": "November (Mid)", "Activity": "Results Announcement", "Details": "Official passing results released."},
            {"Period": "November (Late)", "Activity": "Interviews & Offers", "Details": "Intensive interview period (1-2 weeks). Offers issued quickly."}
        ]
        st.table(pd.DataFrame(timeline_data))

        st.subheader("ğŸ’¡ Key Strategies")
        st.markdown("""
        *   **Start Early**: Don't wait for the results. Attend briefings in September.
        *   **Differentiate**: All Big 4 do audit. Focus on culture, specific clients (e.g., Tech, Auto), or non-audit opportunities (IPO, Advisory).
        *   **Networking**: Use alumni connections (OB/OG Visits) if possible.
        """)

    with tab2:
        st.subheader("ğŸ“Š Big 4 Audit Firms vs. Tech Giants Comparison")
        
        # Personalized Ranking Section
        st.markdown("### ğŸ† Personalized Ranking for You (ML/DS Master's Student)")
        st.info("""
        Based on your **CPA Goal** + **ML/Data Science Strength**, here is your recommended priority:
        
        1.  ğŸ¥‡ **PwC Aarata / EY ShinNihon**: Best balance of **Digital Audit** innovation and **CPA License** support. Both have dedicated "Digital" tracks for auditors.
        2.  ğŸ¥ˆ **Deloitte Tohmatsu**: Massive scale and data access. Great for "Audit Analytics" but slightly more traditional hierarchy.
        3.  ğŸ¥‰ **Accenture / IBM**: **Top Tier for Tech**, but âš ï¸ **WARNING**: You likely **cannot** complete the CPA practical experience (Jitsumu Hoshu) requirement here. Great for *after* getting your CPA, or if you pivot to Consulting.
        """)

        # Radar Chart
        st.subheader("Visual Comparison (Illustrative)")
        categories = ['Tech/AI Focus', 'Global Network', 'Domestic Scale', 'IPO/Venture', 'Work-Life Balance']

        fig = go.Figure()

        # Tohmatsu (Deloitte)
        fig.add_trace(go.Scatterpolar(
            r=[4, 5, 5, 5, 3],
            theta=categories,
            fill='toself',
            name='Tohmatsu (Deloitte)'
        ))
        # AZSA (KPMG)
        fig.add_trace(go.Scatterpolar(
            r=[3, 4, 5, 3, 4],
            theta=categories,
            fill='toself',
            name='AZSA (KPMG)'
        ))
        # EY ShinNihon
        fig.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 3, 3],
            theta=categories,
            fill='toself',
            name='EY ShinNihon'
        ))
        # PwC Aarata
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 3, 2, 4],
            theta=categories,
            fill='toself',
            name='PwC Aarata'
        ))
        # Accenture (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 2, 2],
            theta=categories,
            fill='toself',
            name='Accenture (Ref)'
        ))
        # IBM (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 4, 1, 4],
            theta=categories,
            fill='toself',
            name='IBM (Ref)'
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5]
                )),
            showlegend=True,
            height=500,
            margin=dict(l=40, r=40, t=20, b=20)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("ğŸ¢ Firm Details")
        firms_data = [
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»»ç›£æŸ»æ³•äººãƒˆãƒ¼ãƒãƒ„ (Tohmatsu)",
                "Network": "Deloitte",
                "Key Strengths": "Largest scale, aggressive growth, strong in IPOs and Venture support.",
                "Culture": "Meritocratic, Sports-oriented, High energy.",
                "Link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"
            },
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»» ã‚ãšã•ç›£æŸ»æ³•äºº (AZSA)",
                "Network": "KPMG",
                "Key Strengths": "Balanced portfolio, strong domestic manufacturing clients.",
                "Culture": "Conservative, Collaborative, 'Gentlemanly'.",
                "Link": "https://home.kpmg/jp/ja/home/careers.html"
            },
            {
                "Firm Name (JP)": "EYæ–°æ—¥æœ¬æœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (EY ShinNihon)",
                "Network": "EY",
                "Key Strengths": "Long history, large number of listed clients, strong Digital Audit focus.",
                "Culture": "Traditional yet transforming, Diversity focus.",
                "Link": "https://www.ey.com/ja_jp/careers/audit"
            },
            {
                "Firm Name (JP)": "PwCã‚ã‚‰ãŸæœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (PwC Aarata)",
                "Network": "PwC",
                "Key Strengths": "Global integration, strong advisory connection, newer organizational style.",
                "Culture": "Global, Flat hierarchy, Innovative.",
                "Link": "https://www.pwc.com/jp/ja/careers/audit.html"
            },
            {
                "Firm Name (JP)": "ã‚¢ã‚¯ã‚»ãƒ³ãƒãƒ¥ã‚¢ (Accenture)",
                "Network": "Accenture",
                "Key Strengths": "Absolute leader in DX/IT Consulting. High salary.",
                "Culture": "Up or Out (Evolving), High performance, Tech-first.",
                "Link": "https://www.accenture.com/jp-ja/careers"
            },
            {
                "Firm Name (JP)": "æ—¥æœ¬IBM (IBM Japan)",
                "Network": "IBM",
                "Key Strengths": "Deep research (Watson), Hybrid Cloud, Legacy stability.",
                "Culture": "Engineering-driven, Mature, Good work-life balance.",
                "Link": "https://www.ibm.com/jp-ja/employment"
            }
        ]
        
        # Display as a styled table or cards
        for firm in firms_data:
            with st.expander(f"{firm['Firm Name (JP)']} ({firm['Network']})", expanded=True):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**Strengths:** {firm['Key Strengths']}")
                    st.markdown(f"**Culture:** {firm['Culture']}")
                with col2:
                    st.link_button("Recruit Page", firm['Link'])

    with tab_depts:
        st.subheader("ğŸ¢ Service Lines & Business Units")
        st.markdown("Beyond Audit: Understanding the different career paths within Big 4.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ” Audit & Assurance (ç›£æŸ»ãƒ»ä¿è¨¼)")
            st.info("""
            **The Core Business.**
            *   **Role:** Examining financial statements to ensure accuracy and compliance.
            *   **Pros:** Stability, clear career path, high demand for CPAs.
            *   **Cons:** Can be repetitive, busy season is intense.
            *   **For You:** "Digital Audit" roles are growing fast here.
            """)
            
            st.markdown("### ğŸ’° Financial Advisory (FAS)")
            st.warning("""
            **The "Deal" Makers.**
            *   **Role:** M&A support, Valuations, Due Diligence, Forensic investigations.
            *   **Pros:** High compensation, dynamic work, exposure to high-level strategy.
            *   **Cons:** Very high pressure, long hours, up-or-out culture.
            *   **For You:** **Forensic Technology** (Fraud Detection) is a perfect fit for Data Science skills.
            """)

        with col2:
            st.markdown("### âš–ï¸ Tax (ç¨å‹™)")
            st.info("""
            **The Specialists.**
            *   **Role:** Corporate tax compliance, Transfer Pricing, International Tax.
            *   **Pros:** Deep expertise, high autonomy, stable.
            *   **Cons:** Highly specialized (niche), constant regulatory changes.
            *   **For You:** "Tax Technology" is emerging, but less common for new grads than Audit.
            """)
            
            st.markdown("### ğŸš€ Consulting (ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°)")
            st.success("""
            **The Problem Solvers.**
            *   **Role:** Strategy, IT Implementation, Operations improvement.
            *   **Note:** Usually a separate entity (e.g., Deloitte Tohmatsu Consulting vs. Deloitte Tohmatsu Audit).
            *   **Pros:** Variety of projects, high pay.
            *   **Cons:** Travel, unstable workload, "Jack of all trades" risk.
            """)

    with tab3:
        st.subheader("ğŸ¤– Leveraging Data Science & ML in CPA Job Hunting")
        st.markdown("""
        **Profile:** Double Degree Master's Student (Keio ğŸ‡¯ğŸ‡µ & Leibniz Hannover ğŸ‡©ğŸ‡ª) | **Major:** Mechanical Engineering
        
        **Your Technical Arsenal:**
        *   **Advanced ML:** Graph Neural Networks (GNNs), PyTorch, Bayesian Inference (MCMC/TMCMC).
        *   **Engineering:** Finite Element Analysis (FEA), Structural Health Monitoring.
        *   **Languages:** Python, MATLAB, TypeScript.
        
        Your background is a **massive differentiator** in the modern audit industry. All Big 4 firms are heavily investing in "Audit Transformation" and "Digital Audit".
        """)

        st.markdown("---")
        st.markdown("### ğŸ“š Recommended Reading")
        st.markdown("""
        > **[The State of Generative AI in the Enterprise (Deloitte)](https://www.deloitte.com/global/en/issues/generative-ai/state-of-ai-in-enterprise.html)**  
        > *This report highlights how enterprises are adopting GenAI. Essential reading for interviews to show commercial awareness.*
        """)
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ¯ Target Roles")
            st.success("**1. Digital Audit Specialist**")
            st.markdown("Work at the intersection of Audit and Tech. Use Python/SQL to analyze full population data instead of sampling.")
            
            st.success("**2. AI Governance / Algorithm Assurance**")
            st.markdown("Audit AI models! With your GNN/Bayesian background, you can audit complex *algorithms* themselves, not just the financial numbers.")
            
            st.success("**3. Financial Advisory (FAS) - Forensics**")
            st.markdown("Your experience in 'Defect Localization' translates perfectly to **Fraud Detection** (finding anomalies in massive datasets).")

        with col2:
            st.markdown("### ğŸ’¡ Strategic Actions")
            st.info("**Resume / Entry Sheet (ES)**")
            st.markdown("*   **Highlight Research**: Explicitly mention your GNN work for Aerospace/CFRP. It shows you can handle *complex, unstructured data*.")
            st.markdown("*   **Keywords**: `PyTorch`, `Bayesian Inference`, `Uncertainty Quantification`, `End-to-End Pipelines`.")
            
            st.info("**Interview Questions to Ask**")
            st.markdown("*   *\"How can I apply Bayesian methods to audit risk assessment?\"*\n*   *\"Does your firm analyze unstructured data (like contracts/images) using GNNs or NLP?\"*")
            
            st.info("**Firm-Specific Tech Vibes**")
            st.markdown("""
            *   **EY**: Very strong brand in "Digital Audit". Has "EY Digital" specific recruiting tracks.
            *   **PwC**: Strong on "Tech-enablement". "Digital Upskilling" for all staff is a key slogan.
            *   **Deloitte**: "Audit Analytics" is a core part of their massive scale.
            *   **KPMG**: "Digital Innovation" focus, often collaborative with their consulting arm.
            """)

    with tab4:
        st.subheader("ğŸ‡ºğŸ‡¸ Boston Career Forum (BCF)")
        st.markdown("The world's largest job fair for Japanese-English bilinguals. **Crucial for Master's students.**")
        
        st.info("ğŸ’¡ **Why BCF for You?**\n*   **Speed**: Offers (Naitei) often given in 3 days (Fri-Sun).\n*   **Positions**: Big 4 hires for **Advisory/Consulting** heavily here, not just Audit.\n*   **Timing**: Held in November, aligning perfectly with post-essay exam period.")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ“… Timeline")
            st.markdown("""
            *   **Aug-Sep**: Registration & Resume Upload.
            *   **Sep-Oct**: Online Applications & Skype Interviews (Pre-event).
            *   **Nov (Event)**: Walk-ins (Risky) vs. Scheduled Interviews (Safe).
            """)
        with col2:
            st.markdown("### ğŸ¯ Strategy")
            st.markdown("""
            *   **Pre-Event is King**: Secure interviews *before* flying to Boston.
            *   **Target**: Big 4 (US & Japan offices), Consulting (MBB/Accenture), Tech.
            *   **Dinner Invitations**: If you do well, you get invited to dinner. This is effectively the final interview.
            """)
        st.link_button("BCF Official Site", "https://careerforum.net/en/event/bos/")

    with tab5:
        st.subheader("ğŸ“ Interview & Case Prep: The 'Master' Level")
        
        st.info("ğŸ’¡ **Goal**: Move beyond 'prepared answers'. Show **Intellectual Curiosity** and **Professional Maturity**.")

        # --- Interactive Mock Interview ---
        st.markdown("### ğŸ¤– Mock Interview Simulator")
        mock_mode = st.radio("Select Mode:", ["Behavioral (HR/Partner)", "Technical (Audit/Accounting)", "Case/Logic (Consulting)", "Buy-Side (Investment)"], horizontal=True)
        
        if st.button("ğŸ² Generate Question"):
            import random
            
            if "Behavioral" in mock_mode:
                q_bank = [
                    {"q": "Why do you want to be a CPA instead of an Engineer?", "hint": "Connect 'Reliability' in Engineering to 'Assurance' in Audit."},
                    {"q": "Why our firm specifically? (Why not others?)", "hint": "Mention specific culture, clients (Tech/Auto), or digital initiatives."},
                    {"q": "Tell me about a time you failed.", "hint": "Focus on the **Lesson Learned** and **Improvement**, not the failure itself."},
                    {"q": "How do you handle disagreement with a team member?", "hint": "Emphasize **Listening**, **Data-driven discussion**, and **Shared Goals**."},
                    {"q": "What is your career plan for the next 5-10 years?", "hint": "Be ambitious but realistic. 'Digital Audit Specialist' -> 'Project Manager'."},
                    {"q": "Describe your research in simple terms to a 10-year-old.", "hint": "Tests communication skills. Avoid jargon. Use analogies."}
                ]
            elif "Technical" in mock_mode:
                q_bank = [
                    {"q": "What is the difference between 'Audit' and 'Advisory'?", "hint": "Audit = Assurance (Past/Present). Advisory = Consulting (Future/Improvement)."},
                    {"q": "Explain 'Materiality' in Audit.", "hint": "The threshold above which a misstatement would influence decision making."},
                    {"q": "How would you audit a company with massive data volumes?", "hint": "ITAC (IT Application Controls) + Data Analytics (Full population testing)."},
                    {"q": "What are the risks of using AI in financial reporting?", "hint": "Black box logic, Bias, Hallucinations, Lack of audit trail."},
                    {"q": "Explain the concept of 'Going Concern'.", "hint": "The assumption that a company will continue operating in the foreseeable future."}
                ]
            elif "Case/Logic" in mock_mode: # Case
                q_bank = [
                    {"q": "Estimate the number of smartphones sold in Japan annually.", "hint": "Pop (125M) x Penetration (80%) / Replacement Cycle (3 years)."},
                    {"q": "A client's profit is down 20%. How do you analyze it?", "hint": "Revenue vs Cost. Price x Vol. Fixed vs Variable. External vs Internal."},
                    {"q": "Should a Japanese auto-maker enter the EV market in India?", "hint": "Market Size, Competition, Regulation, Infrastructure, Capabilities."},
                    {"q": "How would you use AI to improve audit efficiency?", "hint": "Automated document review, Anomaly detection in journals, Chatbot for inquiries."}
                ]
            else: # Buy-Side
                q_bank = [
                    {"q": "Pitch a stock you would buy today (Japan-listed).", "hint": "Thesis, Catalysts, Valuation (PE/EV/EBITDA/DCF), Risks."},
                    {"q": "Walk me through an LBO model at a high level.", "hint": "Sources & Uses, Leverage, Operating Case, Exit Multiple, IRR/MOIC."},
                    {"q": "How would you diligence a mid-cap manufacturing target?", "hint": "Unit economics, customers, order backlog, capex, working capital seasonality."},
                    {"q": "What is your investment edge as a CPA + Engineer?", "hint": "Accounting quality + Technical moat assessment + Data skills."}
                ]
            
            selected = random.choice(q_bank)
            st.session_state['mock_q'] = selected
            st.session_state['show_hint'] = False
        
        if 'mock_q' in st.session_state:
            st.markdown(f"#### â“ Q: {st.session_state['mock_q']['q']}")
            
            if st.button("Show Hint / Direction"):
                st.session_state['show_hint'] = not st.session_state.get('show_hint', False)
                
            if st.session_state.get('show_hint', False):
                st.success(f"ğŸ’¡ **Direction**: {st.session_state['mock_q']['hint']}")
        
        st.divider()

        # --- Case Interview Prep ---
        st.markdown("### ğŸ§® Case Interview Prep")
        with st.expander("Framework Cheatsheetï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ—©è¦‹ï¼‰", expanded=False):
            st.markdown("""
            - Profitability: Profit = PriceÃ—Volume âˆ’ Fixed âˆ’ Variable
            - Market Sizing: Top-down (Populationâ†’Penetrationâ†’Frequency) / Bottom-up (UnitsÃ—Price)
            - Growth: New customers / ARPU / Retention / New products / Geographies
            - Cost Cut: COGSï¼ˆææ–™/æ­©ç•™/ç‰©æµï¼‰Ã— ç¨¼åƒç‡ã€SG&Aï¼ˆäººä»¶è²»/åºƒå‘Š/ITï¼‰
            - Pricing: Value-based / Cost-plus / Competitive parity / Segmentation
            - Investment: Thesis / Catalysts / Moat / Valuation / Risks
            """)
        with st.expander("Quick Calculatorsï¼ˆå³å¸­è¨ˆç®—ï¼‰", expanded=False):
            col_q1, col_q2 = st.columns(2)
            with col_q1:
                st.caption("Break-even Units")
                be_f = st.number_input("Fixed Costs", min_value=0.0, value=1000.0, step=10.0, key="case_be_f")
                be_p = st.number_input("Price per Unit", min_value=0.0, value=20.0, step=1.0, key="case_be_p")
                be_v = st.number_input("Variable per Unit", min_value=0.0, value=12.0, step=1.0, key="case_be_v")
                be_units = (be_f / (be_p - be_v)) if (be_p - be_v) > 0 else None
                st.metric("Q_BE", f"{be_units:.1f}" if be_units else "N/A")
            with col_q2:
                st.caption("Simple DCF (Perpetual)")
                cf1 = st.number_input("FCF Year 1", min_value=0.0, value=100.0, step=5.0, key="case_dcf_cf1")
                g = st.number_input("Growth g (%)", min_value=0.0, max_value=10.0, value=2.0, step=0.5, key="case_dcf_g")
                k = st.number_input("Discount k (%)", min_value=1.0, max_value=20.0, value=8.0, step=0.5, key="case_dcf_k")
                pv = (cf1 * (1 + g/100)) / ((k/100) - (g/100)) if k > g else None
                st.metric("PV (Gordon)", f"{pv:.1f}" if pv else "N/A")
        with st.expander("Issue Tree Builderï¼ˆMECEï¼‰", expanded=False):
            case_type = st.selectbox("Case Type", ["Profitability", "Market Entry", "Growth"], key="issue_type")
            seed = {
                "Profitability": ["Revenue", "Costs"],
                "Market Entry": ["Market", "Competition", "Capabilities", "Regulation"],
                "Growth": ["New Customers", "ARPU", "Retention", "Geographies", "Products"]
            }[case_type]
            st.write(", ".join(seed))
            note = st.text_area("Add branches (one per line)", value="")
            if st.button("Export Outline", key="issue_export"):
                txt = f"{case_type} Case\n" + "\n".join([f"- {x}" for x in seed]) + ("\n" + "\n".join([f"- {x}" for x in note.splitlines() if x.strip()]) if note else "")
                st.code(txt, language="markdown")
        with st.expander("Market Sizing Generator", expanded=False):
            if st.button("Generate Scenario", key="ms_gen"):
                import random
                pop = random.choice([50, 80, 100, 125])
                pen = random.choice([40, 60, 75, 80])
                freq = random.choice([1, 2, 4, 12])
                price = random.choice([1000, 2000, 5000])
                st.session_state['ms_scn'] = {"pop": pop, "pen": pen, "freq": freq, "price": price}
            scn = st.session_state.get('ms_scn')
            if scn:
                st.markdown(f"Population={scn['pop']}M, Penetration={scn['pen']}%, Frequency={scn['freq']}/yr, Price=Â¥{scn['price']}")
                ans_units = scn['pop']*1e6 * (scn['pen']/100) * scn['freq']
                ans_revenue = ans_units * scn['price']
                guess = st.number_input("Your revenue estimate (JPY)", min_value=0.0, value=0.0, step=1000.0)
                if st.button("Check", key="ms_check"):
                    tol = 0.1
                    low = ans_revenue*(1-tol)
                    high = ans_revenue*(1+tol)
                    correct = (guess >= low and guess <= high)
                    if correct:
                        st.success("Close enough. Good job.")
                    else:
                        st.error("Outside tolerance.")
                    st.caption(f"Answerâ‰ˆ Â¥{int(ans_revenue):,}")
        with st.expander("Math Speed Drills", expanded=False):
            if st.button("New Set", key="math_new"):
                import random
                qs = []
                for _ in range(5):
                    a = random.randint(50, 500)
                    b = random.randint(5, 50)
                    qs.append({"q": f"{a} Ã— {b}", "a": a*b})
                st.session_state['math_set'] = qs
            ms = st.session_state.get('math_set', [])
            if ms:
                answers = []
                for i, item in enumerate(ms):
                    u = st.number_input(item["q"], min_value=0.0, step=1.0, key=f"math_{i}")
                    answers.append(u)
                if st.button("Grade", key="math_grade"):
                    correct = 0
                    for i, item in enumerate(ms):
                        if int(answers[i]) == item["a"]:
                            correct += 1
                    st.metric("Score", f"{correct}/5")
        with st.expander("Chart Reading Drill", expanded=False):
            import pandas as _pd
            import plotly.express as _px
            dfc = _pd.DataFrame({"Cat": ["A","B","C","D"], "Y1": [100, 140, 90, 110], "Y2": [120, 130, 150, 100]})
            figc = _px.bar(dfc, x="Cat", y=["Y1","Y2"], barmode="group", title="Category Values")
            st.plotly_chart(figc, use_container_width=True)
            st.caption("Q: Which category has the largest increase from Y1 to Y2?")
            inp = st.selectbox("Your answer", ["A","B","C","D"], key="chart_ans")
            inc = (dfc["Y2"]-dfc["Y1"]).tolist()
            idx = inc.index(max(inc))
            if st.button("Check", key="chart_check"):
                if inp == dfc.iloc[idx]["Cat"]:
                    st.success("Correct.")
                else:
                    st.error(f"Incorrect. Answer: {dfc.iloc[idx]['Cat']}")

        st.divider()

        # --- Detailed Guide ---
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ—£ï¸ Core Competency Questions (STAR Method)")
            with st.expander("1. Self-Introduction & Why CPA?", expanded=True):
                st.markdown("""
                **The 'Engineer to Auditor' Narrative**:
                *   "I research **Defect Localization** in aerospace structures using **AI**. My job is to find 'hidden cracks' before they cause failure."
                *   "I realized **Audit** is the same concept but for **Business Structures**. I want to use my tech skills to find 'financial cracks' and ensure stability."
                *   **Why**: "Engineering is precise. Accounting is the language of business. I want to combine **Precision + Business Logic**."
                """)
            
            with st.expander("2. Handling Conflict / Teamwork"):
                st.markdown("""
                *   **Situation**: "In a joint research project with 3 others..."
                *   **Task**: "We disagreed on the simulation method (Speed vs Accuracy)."
                *   **Action**: "I didn't argue opinion. I proposed a **small-scale benchmark test** to compare data."
                *   **Result**: "Data showed my method was 2x faster with 99% accuracy. Team agreed based on evidence."
                *   **Key**: You are **Data-Driven** and **Collaborative**.
                """)

        with col2:
            st.markdown("### ğŸ™‹â€â™‚ï¸ Reverse Questions (Gyakushitsumon)")
            st.info("Asking good questions is more important than giving good answers.")
            
            with st.expander("Level 1: The 'Safe' Questions"):
                st.markdown("""
                *   "What does a typical day look like for a first-year associate?"
                *   "How is the team structure for a typical audit engagement?"
                *   "What kind of training support is available for CPA exam (Jitsumu Hoshu)?"
                """)
                
            with st.expander("Level 2: The 'Interest' Questions"):
                st.markdown("""
                *   "I am interested in the Digital Audit sector. How early can I get involved in data analytics projects?"
                *   "What differentiates a 'High Performer' from an average one in your firm?"
                *   "Can you tell me about the most challenging project you've worked on recently?"
                """)
                
            with st.expander("Level 3: The 'Killer' Questions (Partner Level)"):
                st.markdown("""
                *   "With the rise of AI, how do you see the **business model of Audit** changing in 5 years? Will it shift from 'Time-Charge' to 'Value-Based'?"
                *   "How is the firm preparing for the auditing of **Non-Financial Information** (ESG/Sustainability)? I believe my engineering background could be useful there."
                *   "I want to be a bridge between the Tech team and the Audit team. Is there a career path for a 'Hybrid' professional?"
                """)
        st.divider()
        st.markdown("### ğŸ§‘â€ğŸ’» Programming Test")
        prob = st.selectbox("Select Problem", ["FizzBuzz", "Two Sum", "Valid Parentheses", "Fibonacci", "Anagram Grouping"], key="code_prob")
        starter = {
            "FizzBuzz": "def fizzbuzz(n):\n    res = []\n    for i in range(1, n+1):\n        out = ''\n        if i % 3 == 0:\n            out += 'Fizz'\n        if i % 5 == 0:\n            out += 'Buzz'\n        res.append(out or str(i))\n    return res\n",
            "Two Sum": "def two_sum(nums, target):\n    idx = {}\n    for i, x in enumerate(nums):\n        y = target - x\n        if y in idx:\n            return [idx[y], i]\n        idx[x] = i\n    return []\n",
            "Valid Parentheses": "def valid_parentheses(s):\n    stack = []\n    m = {')':'(', ']':'[', '}':'{'}\n    for ch in s:\n        if ch in '([{':\n            stack.append(ch)\n        elif ch in ')]}':\n            if not stack or stack[-1] != m[ch]:\n                return False\n            stack.pop()\n    return not stack\n",
            "Fibonacci": "def fib(n):\n    if n <= 1:\n        return n\n    a, b = 0, 1\n    for _ in range(n-1):\n        a, b = b, a+b\n    return b\n",
            "Anagram Grouping": "def group_anagrams(words):\n    buckets = {}\n    for w in words:\n        k = ''.join(sorted(w))\n        buckets.setdefault(k, []).append(w)\n    return list(buckets.values())\n"
        }[prob]
        code = st.text_area("Write your function", value=starter, height=260, key="code_area")
        if st.button("Run Tests", key="run_tests"):
            safe_builtins = {'range': range, 'len': len, 'abs': abs, 'min': min, 'max': max, 'sum': sum, 'sorted': sorted, 'enumerate': enumerate, 'zip': zip, 'map': map, 'filter': filter, 'all': all, 'any': any, 'list': list, 'dict': dict, 'set': set, 'tuple': tuple}
            g = {"__builtins__": safe_builtins}
            l = {}
            ok = False
            try:
                exec(code, g, l)
                ok = True
            except Exception as e:
                st.error(f"Compile error: {e}")
            if ok:
                res_lines = []
                def run_case(fn, args, exp):
                    try:
                        out = fn(*args)
                        return out == exp, out, exp
                    except Exception as err:
                        return False, str(err), exp
                tests = []
                if prob == "FizzBuzz":
                    tests = [([15], [str(i) if (i%3 and i%5) else ('Fizz'*(i%3==0)+'Buzz'*(i%5==0)) or str(i) for i in range(1,16)])]
                    fn = l.get("fizzbuzz")
                elif prob == "Two Sum":
                    tests = [([[2,7,11,15], 9], [0,1]), ([[3,2,4], 6], [1,2])]
                    fn = l.get("two_sum")
                elif prob == "Valid Parentheses":
                    tests = [(["()[]{}"], True), (["(]"], False), (["({[]})"], True)]
                    fn = l.get("valid_parentheses")
                elif prob == "Fibonacci":
                    tests = [([0],0),([1],1),([10],55)]
                    fn = l.get("fib")
                else:
                    tests = [([["eat","tea","tan","ate","nat","bat"]], [['eat','tea','ate'], ['tan','nat'], ['bat']])]
                    fn = l.get("group_anagrams")
                if not fn:
                    st.error("Function not found with required name.")
                else:
                    passed = 0
                    for args, exp in tests:
                        ok, out, ex = run_case(fn, args, exp)
                        if ok:
                            passed += 1
                        res_lines.append(f"Input={args} | Output={out} | Expected={ex} | {'OK' if ok else 'NG'}")
                    st.code("\n".join(res_lines), language="text")
                    st.metric("Passed", f"{passed}/{len(tests)}")
        with st.expander("Solution Outline (Steps)", expanded=False):
            if prob == "FizzBuzz":
                st.write("Loop 1..n; if %3 append 'Fizz'; if %5 append 'Buzz'; else str(i).")
            elif prob == "Two Sum":
                st.write("Use hashmap: store valueâ†’index; for x find targetâˆ’x.")
            elif prob == "Valid Parentheses":
                st.write("Use stack; push opens; on close check top and pop; stack empty at end.")
            elif prob == "Fibonacci":
                st.write("Iterate a,b; next=b,a+b; repeat nâˆ’1 times.")
            else:
                st.write("Key = sorted letters of word; group by key.")

    # --- Buy-Side Path Tab ---
    tab_bs = st.tabs(["Buy-Side Path ğŸ’¹"])[0]
    with tab_bs:
        st.subheader("ğŸ’¹ Buy-Sideï¼ˆAM / PE / VCï¼‰ã¸ã®é“ï¼šCPAÃ—Engineer")
        st.markdown("""
        **Roles**
        - AMï¼ˆã‚¢ã‚»ãƒƒãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆï¼‰: Equity/Fixed Income Analyst â†’ PM  
        - PE: Deal Sourcing, DDï¼ˆå•†æµ/è²¡å‹™/æ¥­ç•Œï¼‰, ãƒ¢ãƒ‡ãƒ«ï¼ˆLBOï¼‰, ãƒãƒªãƒ¥ãƒ¼ã‚¢ãƒƒãƒ—  
        - VC: Sourcing, Tech DD, Term Sheet, ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ”¯æ´
        
        **å¿…é ˆã‚¹ã‚­ãƒ«**
        - Accounting/Valuation: è²¡å‹™3è¡¨ã€DCF/Multiplesã€Quality of Earnings
        - Modeling: 3-statement, LBO, Sensitivityï¼ˆExcel/Sheets; Pythonå¯ï¼‰
        - Domain/Tech: äº‹æ¥­ç†è§£ï¼ˆè£½é€ /Techï¼‰ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆPython, SQLï¼‰
        - Edgeï¼ˆå·®åˆ¥åŒ–ï¼‰: CPAã®ä¼šè¨ˆå“è³ªÃ—Engineerã®æŠ€è¡“ç†è§£/è‡ªå‹•åŒ–
        
        **å…¸å‹ãƒ«ãƒ¼ãƒˆ**
        1) ç›£æŸ»ï¼ˆä¸Šå ´/è£½é€ /Techï¼‰â†’ FASï¼ˆDD/Valuationï¼‰â†’ PE  
        2) ç›£æŸ» â†’ äº‹æ¥­ä¼šç¤¾ï¼ˆCorp Dev/IR/FP&Aï¼‰â†’ PE/AM  
        3) Data/MLï¼ˆFinï¼‰â†’ Quant/AM  
        
        **å®Ÿè£…ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆToDoï¼‰**
        - ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆï¼š3è¡¨ãƒ»DCFãƒ»LBOï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æ•´å‚™ï¼‰
        - æŠ•è³‡ãƒ¡ãƒ¢ï¼ˆ1-2ãƒšãƒ¼ã‚¸ï¼‰: Thesis/Catalysts/Valuation/Risksï¼ˆæœˆ1æœ¬ï¼‰
        - èªå®š: CFAï¼ˆæ¨å¥¨ï¼‰ï¼‹CPAã€Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ/ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
        - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°: ãƒŸãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€OBè¨ªå•ã€LinkedInæœ€é©åŒ–
        """)
        with st.expander("ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ï¼‰", expanded=False):
            st.markdown("- DCF ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆæº–å‚™ä¸­ï¼‰\n- LBO ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆæº–å‚™ä¸­ï¼‰\n- One-Pager æŠ•è³‡ãƒ¡ãƒ¢ï¼ˆæº–å‚™ä¸­ï¼‰")

        st.markdown("### What is Buy-Side?")
        st.markdown("""
        - Investors that allocate capital to generate returns.  
        - ä»£è¡¨: ã‚¢ã‚»ãƒƒãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆï¼ˆå…¬å‹Ÿ/æ©Ÿé–¢ï¼‰ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚¨ã‚¯ã‚¤ãƒ†ã‚£ã€ãƒ™ãƒ³ãƒãƒ£ãƒ¼ã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€ãƒ˜ãƒƒã‚¸ãƒ•ã‚¡ãƒ³ãƒ‰ã€‚  
        - ä¸»ãªæˆæœç‰©: æŠ•è³‡ãƒªã‚¿ãƒ¼ãƒ³ã€æŠ•è³‡ãƒ¡ãƒ¢ã€DDãƒ¬ãƒãƒ¼ãƒˆã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ã€‚
        """)
        st.markdown("### Buy-Side vs Sell-Side")
        st.markdown("""
        | è¦³ç‚¹ | Buy-Side | Sell-Side |
        |---|---|---|
        | é¡§å®¢ | è‡ªç¤¾/æŠ•è³‡å®¶ | å¤–éƒ¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ |
        | æˆæœ | ãƒªã‚¿ãƒ¼ãƒ³/æç›Š | ãƒ•ã‚£ãƒ¼/ã‚¢ãƒ‰ãƒã‚¤ã‚¹ |
        | ä»•äº‹ | æŠ•è³‡é¸å®š/DD/é‹ç”¨ | ãƒªã‚µãƒ¼ãƒ/ä»²ä»‹/ã‚¢ãƒ‰ãƒã‚¤ã‚¹ |
        | æ™‚é–“è»¸ | ä¸­é•·æœŸï¼ˆæˆ¦ç•¥/å®Ÿè¡Œï¼‰ | çŸ­ä¸­æœŸï¼ˆæ¡ˆä»¶/ãƒ¬ãƒãƒ¼ãƒˆï¼‰ |
        """)

        if "buyside_plan" not in st.session_state:
            try:
                _data = load_data()
                st.session_state["buyside_plan"] = _data.get("buyside_plan", {})
            except Exception:
                st.session_state["buyside_plan"] = {}

        st.markdown("### Readiness Self-Assessment")
        c1, c2, c3 = st.columns(3)
        with c1:
            r_acc = st.slider("Accounting/Valuation", 0, 10, 6, key="ready_acc")
            r_mod = st.slider("Modeling (3è¡¨/DCF/LBO)", 0, 10, 5, key="ready_mod")
        with c2:
            r_dom = st.slider("Domain (è£½é€ /Techç†è§£)", 0, 10, 6, key="ready_dom")
            r_data = st.slider("Data (Python/SQL)", 0, 10, 6, key="ready_data")
        with c3:
            r_eng = st.slider("English/Global", 0, 10, 5, key="ready_eng")
            r_net = st.slider("Networking", 0, 10, 4, key="ready_net")
        score = int((r_acc*0.2 + r_mod*0.2 + r_dom*0.15 + r_data*0.15 + r_eng*0.15 + r_net*0.15) * 10)
        st.metric("Readiness Score", f"{score}/100")
        st.progress(score)
        if score < 60:
            st.info("Focus: Modeling ã¨ English ã‚’å¼•ãä¸Šã’ã‚‹ã€‚DCF/LBO ã¨è‹±èªãƒ”ãƒƒãƒã®åå¾©ã€‚")
        elif score < 80:
            st.success("Good åŸºç›¤ã€‚æ¡ˆä»¶å‹ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆï¼ˆæŠ•è³‡ãƒ¡ãƒ¢/æœˆï¼‰ã‚’ç¿’æ…£åŒ–ã€‚")
        else:
            st.success("Ready æ°´æº–ã€‚å¿œå‹Ÿï¼‹é¢æ¥ç·´ç¿’ã‚’æœ¬æ ¼åŒ–ã€‚")

        st.markdown("### 12-Week Plan")
        plan_items = [
            "Week1: 3è¡¨ãƒªãƒ³ã‚¯å†å¾©ç¿’ï¼ˆé‹è»¢è³‡æœ¬/è¨­å‚™/ç¨åŠ¹æœï¼‰",
            "Week2: DCFï¼ˆWACC/Terminalï¼‰ã‚’è‡ªä½œãƒ†ãƒ³ãƒ—ãƒ¬ã§2ç¤¾",
            "Week3: ä¸Šå ´è£½é€ æ¥­ã§QofEè¦–ç‚¹ã®èª¿æ•´ã‚’è€ƒãˆã‚‹",
            "Week4: LBOç°¡æ˜“ãƒ¢ãƒ‡ãƒ«ï¼ˆ5å¹´ãƒ»ç°¡æ˜“é‡‘åˆ©ãƒ»Exitå€æ•°ï¼‰",
            "Week5: Stock Pitch #1ï¼ˆ1-2ãƒšãƒ¼ã‚¸ï¼‰",
            "Week6: ã‚»ã‚¯ã‚¿ãƒ¼ç ”ç©¶ï¼ˆè‡ªå‹•è»Š/ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ï¼‰",
            "Week7: DDãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆå•†æµ/è²¡å‹™/æ³•å‹™/ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰",
            "Week8: Stock Pitch #2ï¼ˆç•°æ¥­ç¨®ï¼‰",
            "Week9: Pythonã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿",
            "Week10: ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ¯”è¼ƒï¼ˆMultiples Ã— DCFï¼‰",
            "Week11: è‹±èªãƒ”ãƒƒãƒç·´ç¿’ï¼ˆ5åˆ†ï¼‰ã‚’éŒ²éŸ³/æ”¹å–„",
            "Week12: é¢æ¥ç·ä»•ä¸Šã’ï¼ˆBuy-Sideæƒ³å®šè³ªç–‘ï¼‰"
        ]
        current_plan = st.session_state.get("buyside_plan", {})
        new_plan = {}
        for item in plan_items:
            checked = st.checkbox(item, value=bool(current_plan.get(item)), key=f"pl_{item}")
            new_plan[item] = checked
        csa1, csa2 = st.columns([1,1])
        with csa1:
            if st.button("Save Progress", key="save_buyside_plan"):
                st.session_state["buyside_plan"] = new_plan
                try:
                    blob = load_data()
                    blob["buyside_plan"] = new_plan
                    save_data(blob)
                    st.success("Saved progress.")
                except Exception as e:
                    st.error(f"Save failed: {e}")
        with csa2:
            if st.button("Reset Plan", key="reset_buyside_plan"):
                for item in plan_items:
                    st.session_state[f"pl_{item}"] = False
                st.session_state["buyside_plan"] = {}
                try:
                    blob = load_data()
                    blob["buyside_plan"] = {}
                    save_data(blob)
                except Exception:
                    pass
                st.info("Plan reset.")

        st.markdown("### Stock Pitch Builder")
        p1, p2 = st.columns([2,1])
        with p1:
            sp_name = st.text_input("Company", value="Example Corp")
            sp_thesis = st.text_area("Thesis (3 bullets, one per line)", value="1) Structural growth\n2) Operating leverage\n3) Cash returns policy")
            sp_catalysts = st.text_area("Catalysts", value="New product launch; Cost restructuring; Regulatory approval")
        with p2:
            sp_val = st.selectbox("Valuation Method", ["PE", "EV/EBITDA", "DCF"], index=1)
            sp_risks = st.text_area("Risks", value="FX; Raw materials; Execution")
        if st.button("Build One-Pager", key="build_pitch"):
            text = f"""Company: {sp_name}
Thesis:
{sp_thesis}
Valuation: {sp_val}
Catalysts: {sp_catalysts}
Risks: {sp_risks}
"""
            st.code(text, language="markdown")

        st.markdown("### Quick LBO Estimator")
        l1, l2, l3 = st.columns(3)
        with l1:
            ebitda = st.number_input("EBITDA (Year 1)", min_value=0.0, value=1000.0, step=50.0, key="lbo_ebitda")
            entry_mult = st.number_input("Entry EV/EBITDA", min_value=1.0, value=8.0, step=0.5, key="lbo_entry_mult")
        with l2:
            debt_mult = st.number_input("Debt / EBITDA", min_value=0.0, value=4.0, step=0.5, key="lbo_debt_mult")
            exit_mult = st.number_input("Exit EV/EBITDA", min_value=1.0, value=8.0, step=0.5, key="lbo_exit_mult")
        with l3:
            years = st.number_input("Hold Years", min_value=1, value=5, step=1, key="lbo_years")
            growth = st.number_input("EBITDA CAGR (%)", min_value=0.0, value=5.0, step=0.5, key="lbo_cagr")
        entry_ev = ebitda * entry_mult
        debt = ebitda * debt_mult
        equity = max(entry_ev - debt, 0.0)
        ebitda_exit = ebitda * ((1 + growth/100) ** years)
        exit_ev = ebitda_exit * exit_mult
        equity_exit = max(exit_ev - debt, 0.0)
        moic = (equity_exit / equity) if equity > 0 else None
        irr = ((moic ** (1/years)) - 1) * 100 if moic and moic > 0 else None
        st.metric("MOIC (approx)", f"{moic:.2f}x" if moic else "N/A")
        st.metric("IRR (approx)", f"{irr:.1f}%" if irr else "N/A")


elif page == "Company Directory ğŸ¢":
    st.header("ğŸ¢ Company Directory for CPA Candidates")
    st.markdown("A curated list of potential employers in Japan for CPA holders, ranging from Audit to Tech.")

    st.subheader("Preferences")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        target_city = st.selectbox("Target City", ["Tokyo", "Osaka", "Nagoya", "Any"], index=0)
    with c2:
        w_cpa = st.slider("Weight: CPA Track", 0, 50, 20)
    with c3:
        w_ds = st.slider("Weight: Data Science/Tech", 0, 50, 15)
    with c4:
        w_global = st.slider("Weight: Global Brand", 0, 30, 5)
    min_score = st.slider("Show companies with score â‰¥", 0, 100, 0, 5)

    def _score_company(attrs, locs):
        score = 50
        try:
            if target_city != "Any":
                if isinstance(locs, list) and target_city in locs:
                    score += 30
                else:
                    score -= 10
            cpa_v = attrs.get("CPA", False)
            if isinstance(cpa_v, bool):
                score += w_cpa if cpa_v else 0
            elif isinstance(cpa_v, str):
                m = {"High": 1.0, "Medium": 0.6, "Low": 0.2}.get(cpa_v, 0.0)
                score += int(w_cpa * m)
            ds_v = attrs.get("DS", False)
            if isinstance(ds_v, bool):
                score += w_ds if ds_v else 0
            elif isinstance(ds_v, str):
                m = {"High": 1.0, "Medium": 0.6, "Low": 0.2}.get(ds_v, 0.0)
                score += int(w_ds * m)
            global_v = attrs.get("Global", False)
            if global_v:
                score += w_global
        except Exception:
            pass
        if score < 0:
            score = 0
        if score > 100:
            score = 100
        return int(score)

    tab1, tab2, tab3 = st.tabs(["Audit (Big 4 & Mid)", "Consulting & FAS", "Tech & Enterprise"])

    with tab1:
        st.subheader("Big 4 Audit Firms (The Standard Path)")
        big4 = [
            {"name": "Deloitte Touche Tohmatsu", "desc": "Largest scale, aggressive growth. Strong in IPO support.", "link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html", "locs": ["Tokyo", "Osaka", "Nagoya"], "attrs": {"CPA": True, "DS": True, "Global": True}},
            {"name": "KPMG AZSA", "desc": "Balanced portfolio, strong manufacturing clients. 'Gentleman' culture.", "link": "https://home.kpmg/jp/ja/home/careers.html", "locs": ["Tokyo", "Osaka", "Nagoya"], "attrs": {"CPA": True, "DS": True, "Global": True}},
            {"name": "EY ShinNihon", "desc": "Longest history, most listed clients. Strong Digital Audit focus.", "link": "https://www.ey.com/ja_jp/careers/audit", "locs": ["Tokyo", "Osaka", "Nagoya"], "attrs": {"CPA": True, "DS": True, "Global": True}},
            {"name": "PwC Aarata / Kyoto", "desc": "Global integration, innovative. PwC Kyoto is famous for high profitability.", "link": "https://www.pwc.com/jp/ja/careers/audit.html", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": True, "DS": True, "Global": True}}
        ]
        for c in big4:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            with st.expander(f"ğŸ¦ {c['name']}  |  Score: {sc}/100"):
                st.write(c['desc'])
                st.progress(sc)
                st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                st.link_button("Recruit Page", c['link'])

        st.divider()
        st.subheader("Mid-Tier Audit Firms (å‡†å¤§æ‰‹)")
        st.info("ğŸ’¡ **Why Mid-Tier?** Faster promotion, broader experience (you do everything), better work-life balance.")
        mid_tier = [
            {"name": "Grant Thornton Taiyo (å¤ªé™½)", "desc": "Largest mid-tier. Very growing. Good alternative to Big 4.", "link": "https://www.grantthornton.jp/recruit/", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Crowe Toyo (æ±é™½)", "desc": "Strong in domestic IPOs. Traditional but stable.", "link": "https://www.toyo-audit.or.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}},
            {"name": "BDO Sanyu (ä¸‰å„ª)", "desc": "Friendly culture. Good international network via BDO.", "link": "https://www.bdo.or.jp/sanyu/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}},
            {"name": "RSM Seiwa (æ¸…å’Œ)", "desc": "Mid-sized, focus on healthcare and mid-cap clients.", "link": "https://www.seiwa-audit.or.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}}
        ]
        for c in mid_tier:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            with st.expander(f"ğŸ¯ {c['name']}  |  Score: {sc}/100"):
                st.write(c['desc'])
                st.progress(sc)
                st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                st.link_button("Recruit Page", c['link'])

    with tab2:
        st.subheader("FAS (Financial Advisory Services)")
        st.info("ğŸ’¡ **High Expertise**: M&A, Valuation, Forensics. Often requires CPA + English/Tech.")
        fas = [
            {"name": "Deloitte Tohmatsu Financial Advisory (DTFA)", "link": "https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/dtfa/dtfa-recruit.html", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "KPMG FAS", "link": "https://home.kpmg/jp/ja/home/careers/fas.html", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "PwC Advisory", "link": "https://www.pwc.com/jp/ja/careers/advisory.html", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "EY Strategy and Transactions", "link": "https://www.ey.com/ja_jp/careers/strategy-and-transactions", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}}
        ]
        for c in fas:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            with st.expander(f"ğŸ’¼ {c['name']}  |  Score: {sc}/100"):
                st.progress(sc)
                st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                st.link_button("Recruit Page", c['link'])

        st.divider()
        st.subheader("Consulting Firms")
        st.markdown("Finance transformation, ERP implementation, Strategy.")
        consulting = [
            {"name": "Accenture (Strategy & Consulting)", "desc": "Top tier for DX/IT. High salary, hard work.", "link": "https://www.accenture.com/jp-ja/careers", "locs": ["Tokyo"], "attrs": {"CPA": False, "DS": True, "Global": True}},
            {"name": "BayCurrent Consulting", "desc": "Rapidly growing Japanese firm. High salary.", "link": "https://www.baycurrent.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": False}},
            {"name": "Nomura Research Institute (NRI)", "desc": "Stable, high salary, strong domestic presence.", "link": "https://www.nri.com/jp/career", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "ABeam Consulting", "desc": "Strong in SAP/ERP. Good for CPAs liking systems.", "link": "https://www.abeam.com/jp/ja/careers", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}}
        ]
        for c in consulting:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            with st.expander(f"ğŸ§  {c['name']}  |  Score: {sc}/100"):
                st.write(c['desc'])
                st.progress(sc)
                st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                st.link_button("Recruit Page", c['link'])

    with tab3:
        st.subheader("Tech & Enterprise (CFO Track)")
        st.info("ğŸ’¡ **Business Side**: FP&A, Accounting Manager, IPO Prep.")
        fc1, fc2 = st.columns([1, 2])
        with fc1:
            te_firm_type = st.selectbox("Firm Type", ["All", "Foreign", "Japanese"], index=0, key="te_firm_type")
        with fc2:
            te_standards = st.multiselect("Accounting Standard Experience", ["IFRS", "US GAAP", "JGAAP"], default=[], key="te_standards")
        use_leftnav = st.checkbox("Left Navigation View (recommended)", value=True, key="te_leftnav")
        if use_leftnav:
            col_nav, col_view = st.columns([1, 3])
            with col_nav:
                subsec = st.radio(
                    "Section",
                    [
                        "Tech / Global",
                        "Holdings / Conglomerates",
                        "Securities",
                        "Makers",
                        "Utilities & Energy",
                        "Megabanks",
                        "Consulting (MBB)",
                        "Trading Companies",
                        "Buy-Side (AM / PE / VC)",
                        "User Catalog",
                        "Bulk Add"
                    ],
                    index=0,
                    key="te_nav"
                )
                cat_meta = {
                    "Tech / Global": {"salary": "6â€“12M JPY", "diff": "High"},
                    "Holdings / Conglomerates": {"salary": "7â€“12M JPY", "diff": "High"},
                    "Securities": {"salary": "6â€“12M JPY", "diff": "High"},
                    "Makers": {"salary": "5â€“9M JPY", "diff": "Medium"},
                    "Utilities & Energy": {"salary": "5â€“8M JPY", "diff": "Lowâ€“Medium"},
                    "Megabanks": {"salary": "6â€“10M JPY", "diff": "Medium"},
                    "Consulting (MBB)": {"salary": "8â€“14M JPY", "diff": "Ultra"},
                    "Trading Companies": {"salary": "8â€“14M JPY", "diff": "Ultra"},
                    "Buy-Side (AM / PE / VC)": {"salary": "8â€“20M JPY", "diff": "Ultra"},
                    "User Catalog": {"salary": "Varies", "diff": "Varies"},
                    "Bulk Add": {"salary": "", "diff": ""}
                }
                meta = cat_meta.get(subsec, {})
                if meta:
                    st.metric("Salary (cat)", meta.get("salary", "â€”"))
                    st.metric("Difficulty", meta.get("diff", "â€”"))
            with col_view:
                def _render_items(items, cat_name):
                    for c in items:
                        if te_firm_type != "All":
                            ctype = c.get("type")
                            if ctype and ctype != te_firm_type:
                                continue
                        if te_standards:
                            cstd = c.get("standards", [])
                            if cstd and not any(s in cstd for s in te_standards):
                                continue
                        sc = _score_company(c.get("attrs", {}), c.get("locs", []))
                        if sc < min_score:
                            continue
                        st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c.get('desc','')} [Link]({c.get('link','')})")
                        st.progress(sc)
                        st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                        cm = cat_meta.get(cat_name, {})
                        sal = c.get("salary") or cm.get("salary", "â€”")
                        dif = c.get("difficulty") or cm.get("diff", "â€”")
                        st.caption(f"Salary: {sal} | Difficulty: {dif}")
                if subsec == "Tech / Global":
                    items = [
                        {"name": "Google / Amazon / MS (Japan)", "desc": "FP&A roles. Very high English requirement. Competitive.", "link": "https://careers.google.com/", "locs": ["Tokyo"], "attrs": {"CPA": False, "DS": True, "Global": True}, "type": "Foreign", "standards": ["US GAAP", "IFRS"], "salary": "10â€“14M+ JPY", "difficulty": "Ultra"},
                        {"name": "Rakuten Group", "desc": "English official language. Massive FinTech ecosystem.", "link": "https://corp.rakuten.co.jp/careers/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"], "salary": "6â€“10M JPY"},
                        {"name": "Line Yahoo", "desc": "Major domestic tech player. Strong benefits.", "link": "https://www.lycorp.co.jp/ja/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Mercari", "desc": "Modern tech culture. Good for ambitious finance pros.", "link": "https://careers.mercari.com/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Tech / Global")
                elif subsec == "Holdings / Conglomerates":
                    items = [
                        {"name": "SoftBank Group", "desc": "Investment conglomerate. Complex consolidations and valuation analytics.", "link": "https://group.softbank/en/corp/recruit", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Recruit Holdings", "desc": "HR Tech conglomerate. Data-driven culture; FP&A and IR strong.", "link": "https://recruit-holdings.com/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Fast Retailing (UNIQLO)", "desc": "Globally integrated retail. Inventory/FX/IFRS exposure.", "link": "https://www.fastretailing.com/employment/ja/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Takeda Pharmaceutical", "desc": "Global pharma. R&D capitalization, global IFRS, treasury.", "link": "https://www.takeda.com/jp/ja-us/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Holdings / Conglomerates")
                elif subsec == "Securities":
                    items = [
                        {"name": "Nomura Securities (é‡æ‘è­‰åˆ¸)", "desc": "Top-tier securities. IB, Markets, Corporate planning/Finance roles.", "link": "https://www.nomura.com/jpn/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["US GAAP", "IFRS"]},
                        {"name": "Daiwa Securities (å¤§å’Œè¨¼åˆ¸)", "desc": "Major securities group. IB/markets, group finance & IR.", "link": "https://www.daiwa-grp.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Securities")
                elif subsec == "Makers":
                    items = [
                        {"name": "Toyota", "desc": "Global auto leader. Robust finance org; strong FP&A/treasury.", "link": "https://global.toyota/en/company/", "locs": ["Tokyo", "Aichi"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Keyence", "desc": "High-margin factory automation. Lean org, high productivity.", "link": "https://www.keyence.co.jp/jobs/", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": "Medium", "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Fujifilm", "desc": "Diversified: healthcare, imaging, materials. Global operations.", "link": "https://recruit.fujifilm.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Sony", "desc": "Entertainment + Electronics. Complex consolidation; great for CPAs.", "link": "https://www.sony.com/en/SonyInfo/Careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Panasonic", "desc": "Devices to solutions. Large-scale finance transformation roles.", "link": "https://holdings.panasonic/jp/corporate/jobs/", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Hitachi", "desc": "OTÃ—IT leader. Project accounting, global IFRS exposure.", "link": "https://www.hitachi.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Makers")
                elif subsec == "Utilities & Energy":
                    items = [
                        {"name": "Tokyo Gas", "desc": "Stable utility. Long-term planning, project finance, IFRS.", "link": "https://www.tokyo-gas-recruit.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "TEPCO", "desc": "Large-scale regulated utility. Risk management heavy.", "link": "https://www.tepco.co.jp/recruit/index-j.html", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Utilities & Energy")
                elif subsec == "Megabanks":
                    items = [
                        {"name": "MUFG", "desc": "Japanâ€™s largest financial group. Treasury, ALM, IFRS9/CECL skills.", "link": "https://www.mufg.jp/csr/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "SMBC", "desc": "Corporate banking powerhouse. Debt/FX exposure for CFO track.", "link": "https://www.smbc.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Mizuho", "desc": "Universal bank. Group finance/controls; transformation programs.", "link": "https://www.mizuho-fg.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]}
                    ]
                    _render_items(items, "Megabanks")
                elif subsec == "Consulting (MBB)":
                    items = [
                        {"name": "McKinsey & Company", "desc": "Top strategy firm. CFO transformation, value creation.", "link": "https://www.mckinsey.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Foreign"},
                        {"name": "Boston Consulting Group", "desc": "Deep corporate finance practice.", "link": "https://careers.bcg.com/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Foreign"},
                        {"name": "Bain & Company", "desc": "Private equity, performance improvement.", "link": "https://www.bain.com/careers/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Foreign"}
                    ]
                    _render_items(items, "Consulting (MBB)")
                elif subsec == "Trading Companies":
                    st.markdown("Mitsubishi Corp, Mitsui & Co, Itochu, Sumitomo Corp, Marubeni")
                    st.caption("Salary: 8â€“14M JPY | Difficulty: Ultra")
                    st.caption("Extremely competitive. High salary. Global rotations.")
                elif subsec == "Buy-Side (AM / PE / VC)":
                    items = [
                        {"name": "Nomura Asset Management", "desc": "Japanâ€™s leading AM. Equity/Fixed Income/Quant.", "link": "https://www.nomura-am.co.jp/company/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Medium", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "Daiwa Asset Management", "desc": "Major AM house. Public equities and funds.", "link": "https://www.daiwa-am.co.jp/company/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Low", "Global": True}, "type": "Japanese", "standards": ["IFRS"]},
                        {"name": "BlackRock Japan", "desc": "Global leader. iShares/Institutional mandates.", "link": "https://careers.blackrock.com/early-careers", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": True, "Global": True}, "type": "Foreign", "standards": ["US GAAP", "IFRS"]},
                        {"name": "Fidelity Investments Japan", "desc": "Active management, research focus.", "link": "https://www.fidelity.co.jp/corporate/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Low", "Global": True}, "type": "Foreign", "standards": ["US GAAP", "IFRS"]},
                        {"name": "Advantage Partners", "desc": "Japanâ€™s top PE pioneer. Mid-market focus.", "link": "https://www.advantagepartners.com/jp/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}, "type": "Japanese"},
                        {"name": "Carlyle Japan", "desc": "Global PE. Large-cap to mid-cap.", "link": "https://www.carlyle.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}, "type": "Foreign"},
                        {"name": "Bain Capital Japan", "desc": "Global PE. Strong operating improvement.", "link": "https://www.baincapital.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}, "type": "Foreign"},
                        {"name": "Japan Industrial Partners (JIP)", "desc": "Carve-outs/turnarounds.", "link": "https://www.jipinc.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}, "type": "Japanese"},
                        {"name": "JAFCO", "desc": "Japanâ€™s classic VC. Early to growth.", "link": "https://www.jafco.co.jp/english/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Japanese"},
                        {"name": "Globis Capital Partners", "desc": "Top-tier domestic VC. SaaS/tech focus.", "link": "https://www.globis-capital.co.jp/en/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Japanese"},
                        {"name": "Incubate Fund", "desc": "Early-stage specialist.", "link": "https://incubatefund.com/en/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}, "type": "Japanese"},
                        {"name": "DNX Ventures", "desc": "B2B tech-focused VC (JP/US).", "link": "https://www.dnx.vc/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": True, "Global": True}, "type": "Foreign"}
                    ]
                    _render_items(items, "Buy-Side (AM / PE / VC)")
                elif subsec == "User Catalog":
                    catalog = st.session_state.get("company_catalog", [])
                    if catalog:
                        for c in catalog:
                            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
                            if sc < min_score:
                                continue
                            st.markdown(f"**{c.get('name','')}** â€” Score: {sc}/100  \n{c.get('desc','')} [Link]({c.get('link','')})")
                            st.progress(sc)
                            st.caption(f"Locations: {', '.join(c.get('locs', []))}")
                            st.caption("Salary: Varies | Difficulty: Varies")
                    else:
                        st.info("No entries. Use 'Bulk Add' to import.")
                else:
                    st.markdown("#### Bulk Add Companies (CSV/JSON)")
                    with st.expander("Import / Manage", expanded=True):
                        st.caption("Schema: name, desc, link, locs(list or comma-separated), attrs.CPA(bool/str), attrs.DS(bool/str), attrs.Global(bool)")
                        uploaded = st.file_uploader("Upload CSV or JSON", type=["csv", "json"], accept_multiple_files=False, key="company_catalog_uploader_left")
                        if uploaded is not None:
                            try:
                                import json as _json
                                import pandas as _pd
                                if uploaded.name.lower().endswith(".json"):
                                    entries = _json.loads(uploaded.read().decode("utf-8"))
                                else:
                                    dfu = _pd.read_csv(uploaded)
                                    entries = dfu.to_dict(orient="records")
                                if not isinstance(entries, list):
                                    entries = [entries]
                                catalog = st.session_state.get("company_catalog", [])
                                for e in entries:
                                    name = e.get("name") or e.get("Name")
                                    if not name:
                                        continue
                                    desc = e.get("desc") or e.get("Desc") or ""
                                    link = e.get("link") or e.get("Link") or ""
                                    locs = e.get("locs") or e.get("Locs") or e.get("locations") or e.get("Locations") or []
                                    if isinstance(locs, str):
                                        locs = [s.strip() for s in locs.split(",") if s.strip()]
                                    attrs = e.get("attrs") or {}
                                    if not attrs:
                                        attrs = {
                                            "CPA": e.get("CPA") if e.get("CPA") is not None else False,
                                            "DS": e.get("DS") if e.get("DS") is not None else False,
                                            "Global": e.get("Global") if e.get("Global") is not None else False
                                        }
                                    item = {"name": name, "desc": desc, "link": link, "locs": locs, "attrs": attrs}
                                    exists = False
                                    for old in catalog:
                                        if old.get("name") == name:
                                            old.update(item)
                                            exists = True
                                            break
                                    if not exists:
                                        catalog.append(item)
                                st.session_state["company_catalog"] = catalog
                                try:
                                    data_blob = load_data()
                                    data_blob["company_catalog"] = catalog
                                    save_data(data_blob)
                                except Exception:
                                    pass
                                st.success(f"Imported {len(entries)} entries.")
                            except Exception as e:
                                st.error(f"Failed to import: {e}")
                        col_i1, col_i2 = st.columns([1,1])
                        with col_i1:
                            if st.button("Clear Catalog", key="clear_catalog_left"):
                                st.session_state["company_catalog"] = []
                                try:
                                    data_blob = load_data()
                                    data_blob["company_catalog"] = []
                                    save_data(data_blob)
                                except Exception:
                                    pass
                                st.info("Catalog cleared.")
                        with col_i2:
                            if st.button("Load Catalog from Storage", key="load_catalog_left"):
                                try:
                                    data_blob = load_data()
                                    st.session_state["company_catalog"] = data_blob.get("company_catalog", [])
                                    st.success("Loaded from storage.")
                                except Exception as e:
                                    st.error(f"Failed to load: {e}")
            st.stop()
        
        tech = [
            {"name": "Google / Amazon / MS (Japan)", "desc": "FP&A roles. Very high English requirement. Competitive.", "link": "https://careers.google.com/", "locs": ["Tokyo"], "attrs": {"CPA": False, "DS": True, "Global": True}},
            {"name": "Rakuten Group", "desc": "English official language. Massive FinTech ecosystem.", "link": "https://corp.rakuten.co.jp/careers/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}},
            {"name": "Line Yahoo", "desc": "Major domestic tech player. Strong benefits.", "link": "https://www.lycorp.co.jp/ja/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}},
            {"name": "Mercari", "desc": "Modern tech culture. Good for ambitious finance pros.", "link": "https://careers.mercari.com/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}}
        ]
        st.markdown("#### Tech / Global")
        for c in tech:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Trading Companies (Sogo Shosha)")
        shosha = ["Mitsubishi Corp", "Mitsui & Co", "Itochu", "Sumitomo Corp", "Marubeni"]
        st.write(", ".join(shosha))
        st.caption("Extremely competitive. High salary. Global rotations.")

        st.divider()
        st.markdown("#### Top-Tier Holdings / Conglomerates")
        holdings = [
            {"name": "SoftBank Group", "desc": "Investment conglomerate. Complex consolidations and valuation analytics.", "link": "https://group.softbank/en/corp/recruit", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": True, "Global": True}},
            {"name": "Recruit Holdings", "desc": "HR Tech conglomerate. Data-driven culture; FP&A and IR strong.", "link": "https://recruit-holdings.com/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}},
            {"name": "Fast Retailing (UNIQLO)", "desc": "Globally integrated retail. Inventory/FX/IFRS exposure.", "link": "https://www.fastretailing.com/employment/ja/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Takeda Pharmaceutical", "desc": "Global pharma. R&D capitalization, global IFRS, treasury.", "link": "https://www.takeda.com/jp/ja-us/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}}
        ]
        for c in holdings:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Securities (è¨¼åˆ¸)")
        securities = [
            {"name": "Nomura Securities (é‡æ‘è­‰åˆ¸)", "desc": "Top-tier securities. IB, Markets, Corporate planning/Finance roles.", "link": "https://www.nomura.com/jpn/careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Daiwa Securities (å¤§å’Œè¨¼åˆ¸)", "desc": "Major securities group. IB/markets, group finance & IR.", "link": "https://www.daiwa-grp.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}}
        ]
        for c in securities:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Bulk Add Companies (CSV/JSON)")
        with st.expander("Import / Manage", expanded=False):
            st.caption("Schema: name, desc, link, locs(list or comma-separated), attrs.CPA(bool/str), attrs.DS(bool/str), attrs.Global(bool)")
            uploaded = st.file_uploader("Upload CSV or JSON", type=["csv", "json"], accept_multiple_files=False, key="company_catalog_uploader")
            if uploaded is not None:
                try:
                    import json as _json
                    import pandas as _pd
                    if uploaded.name.lower().endswith(".json"):
                        entries = _json.loads(uploaded.read().decode("utf-8"))
                    else:
                        dfu = _pd.read_csv(uploaded)
                        entries = dfu.to_dict(orient="records")
                    if not isinstance(entries, list):
                        entries = [entries]
                    catalog = st.session_state.get("company_catalog", [])
                    for e in entries:
                        name = e.get("name") or e.get("Name")
                        if not name:
                            continue
                        desc = e.get("desc") or e.get("Desc") or ""
                        link = e.get("link") or e.get("Link") or ""
                        locs = e.get("locs") or e.get("Locs") or e.get("locations") or e.get("Locations") or []
                        if isinstance(locs, str):
                            locs = [s.strip() for s in locs.split(",") if s.strip()]
                        attrs = e.get("attrs") or {}
                        if not attrs:
                            attrs = {
                                "CPA": e.get("CPA") if e.get("CPA") is not None else False,
                                "DS": e.get("DS") if e.get("DS") is not None else False,
                                "Global": e.get("Global") if e.get("Global") is not None else False
                            }
                        item = {"name": name, "desc": desc, "link": link, "locs": locs, "attrs": attrs}
                        exists = False
                        for old in catalog:
                            if old.get("name") == name:
                                old.update(item)
                                exists = True
                                break
                        if not exists:
                            catalog.append(item)
                    st.session_state["company_catalog"] = catalog
                    try:
                        data_blob = load_data()
                        data_blob["company_catalog"] = catalog
                        save_data(data_blob)
                    except Exception:
                        pass
                    st.success(f"Imported {len(entries)} entries.")
                except Exception as e:
                    st.error(f"Failed to import: {e}")
            col_i1, col_i2 = st.columns([1,1])
            with col_i1:
                if st.button("Clear Catalog"):
                    st.session_state["company_catalog"] = []
                    try:
                        data_blob = load_data()
                        data_blob["company_catalog"] = []
                        save_data(data_blob)
                    except Exception:
                        pass
                    st.info("Catalog cleared.")
            with col_i2:
                if st.button("Load Catalog from Storage"):
                    try:
                        data_blob = load_data()
                        st.session_state["company_catalog"] = data_blob.get("company_catalog", [])
                        st.success("Loaded from storage.")
                    except Exception as e:
                        st.error(f"Failed to load: {e}")
        user_catalog = st.session_state.get("company_catalog", [])
        if user_catalog:
            st.markdown("#### User Catalog")
            for c in user_catalog:
                sc = _score_company(c.get("attrs", {}), c.get("locs", []))
                if sc < min_score:
                    continue
                st.markdown(f"**{c.get('name','')}** â€” Score: {sc}/100  \n{c.get('desc','')} [Link]({c.get('link','')})")
                st.progress(sc)
                st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Makers (Tier 1)")
        makers = [
            {"name": "Toyota", "desc": "Global auto leader. Robust finance org; strong FP&A/treasury.", "link": "https://global.toyota/en/company/", "locs": ["Tokyo", "Aichi"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Keyence", "desc": "High-margin factory automation. Lean org, high productivity.", "link": "https://www.keyence.co.jp/jobs/", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": "Medium", "DS": "Medium", "Global": True}},
            {"name": "Fujifilm", "desc": "Diversified: healthcare, imaging, materials. Global operations.", "link": "https://recruit.fujifilm.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Sony", "desc": "Entertainment + Electronics. Complex consolidation; great for CPAs.", "link": "https://www.sony.com/en/SonyInfo/Careers/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}},
            {"name": "Panasonic", "desc": "Devices to solutions. Large-scale finance transformation roles.", "link": "https://holdings.panasonic/jp/corporate/jobs/", "locs": ["Tokyo", "Osaka"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Hitachi", "desc": "OTÃ—IT leader. Project accounting, global IFRS exposure.", "link": "https://www.hitachi.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": True, "Global": True}}
        ]
        for c in makers:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Utilities & Energy")
        utilities = [
            {"name": "Tokyo Gas", "desc": "Stable utility. Long-term planning, project finance, IFRS.", "link": "https://www.tokyo-gas-recruit.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}},
            {"name": "TEPCO", "desc": "Large-scale regulated utility. Risk management heavy.", "link": "https://www.tepco.co.jp/recruit/index-j.html", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}}
        ]
        for c in utilities:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Megabanks")
        megabanks = [
            {"name": "MUFG", "desc": "Japanâ€™s largest financial group. Treasury, ALM, IFRS9/CECL skills.", "link": "https://www.mufg.jp/csr/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "SMBC", "desc": "Corporate banking powerhouse. Debt/FX exposure for CFO track.", "link": "https://www.smbc.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}},
            {"name": "Mizuho", "desc": "Universal bank. Group finance/controls; transformation programs.", "link": "https://www.mizuho-fg.co.jp/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Medium", "Global": True}}
        ]
        for c in megabanks:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Strategy Consulting (MBB)")
        mbb = [
            {"name": "McKinsey & Company", "desc": "Top strategy firm. CFO transformation, value creation.", "link": "https://www.mckinsey.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "Boston Consulting Group", "desc": "Deep corporate finance practice.", "link": "https://careers.bcg.com/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "Bain & Company", "desc": "Private equity, performance improvement.", "link": "https://www.bain.com/careers/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}}
        ]
        for c in mbb:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")

        st.divider()
        st.markdown("#### Buy-Side (AM / PE / VC)")
        buyside = [
            # Asset Management
            {"name": "Nomura Asset Management", "desc": "Japanâ€™s leading AM. Equity/Fixed Income/Quant.", "link": "https://www.nomura-am.co.jp/company/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Medium", "Global": True}},
            {"name": "Daiwa Asset Management", "desc": "Major AM house. Public equities and funds.", "link": "https://www.daiwa-am.co.jp/company/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Low", "Global": True}},
            {"name": "BlackRock Japan", "desc": "Global leader. iShares/Institutional mandates.", "link": "https://careers.blackrock.com/early-careers", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": True, "Global": True}},
            {"name": "Fidelity Investments Japan", "desc": "Active management, research focus.", "link": "https://www.fidelity.co.jp/corporate/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Medium", "DS": "Low", "Global": True}},
            # Private Equity
            {"name": "Advantage Partners", "desc": "Japanâ€™s top PE pioneer. Mid-market focus.", "link": "https://www.advantagepartners.com/jp/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}},
            {"name": "Carlyle Japan", "desc": "Global PE. Large-cap to mid-cap.", "link": "https://www.carlyle.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}},
            {"name": "Bain Capital Japan", "desc": "Global PE. Strong operating improvement.", "link": "https://www.baincapital.com/careers", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": True}},
            {"name": "Japan Industrial Partners (JIP)", "desc": "Carve-outs/turnarounds.", "link": "https://www.jipinc.com/", "locs": ["Tokyo"], "attrs": {"CPA": True, "DS": "Low", "Global": False}},
            # Venture Capital
            {"name": "JAFCO", "desc": "Japanâ€™s classic VC. Early to growth.", "link": "https://www.jafco.co.jp/english/recruit/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "Globis Capital Partners", "desc": "Top-tier domestic VC. SaaS/tech focus.", "link": "https://www.globis-capital.co.jp/en/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "Incubate Fund", "desc": "Early-stage specialist.", "link": "https://incubatefund.com/en/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": "Medium", "Global": True}},
            {"name": "DNX Ventures", "desc": "B2B tech-focused VC (JP/US).", "link": "https://www.dnx.vc/", "locs": ["Tokyo"], "attrs": {"CPA": "Low", "DS": True, "Global": True}}
        ]
        for c in buyside:
            sc = _score_company(c.get("attrs", {}), c.get("locs", []))
            if sc < min_score:
                continue
            st.markdown(f"**{c['name']}** â€” Score: {sc}/100  \n{c['desc']} [Link]({c['link']})")
            st.progress(sc)
            st.caption(f"Locations: {', '.join(c.get('locs', []))}")


elif page == "Future ğŸš€":
    st.header("ğŸš€ 100-Year Life & Career Plan: The 'Founder' Trajectory")
    st.markdown("Your roadmap from **Master's Student** to **Tech CEO**. A comprehensive simulation of career, wealth, and life milestones.")

    # Top Status Board
    st.subheader("ğŸ“ Current Status")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Current Age", "24", "Phase: Foundation")
    c2.metric("Next Big Milestone", "CPA Exam Pass", "2027 (Age 25)")
    c3.metric("Career Goal", "Audit Tech Founder", "Launch @ Age 35")
    c4.metric("Financial Freedom", "Target: Age 45", "Asset Goal: 500M JPY")
    
    st.divider()

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["â³ 100-Year Timeline", "ğŸ§  Skill Evolution", "ğŸ’° Wealth (Monte Carlo)", "ğŸ¦„ Entrepreneurship Blueprint", "ğŸ’ Life & Family"])

    with tab1:
        st.subheader("The Century Plan (Age 24 - 100)")
        
        timeline_events = [
            {"Age": 24, "Year": 2026, "Phase": "Foundation", "Event": "Master's (Germany/Japan) + CPA Study Start", "Status": "Current", "Importance": 3},
            {"Age": 25, "Year": 2027, "Phase": "Foundation", "Event": "Pass CPA Exam (May/Aug) ğŸ†", "Status": "Goal", "Importance": 5},
            {"Age": 26, "Year": 2028, "Phase": "Foundation", "Event": "Graduation & Join Big 4 (Digital Audit/FAS)", "Status": "Planned", "Importance": 4},
            {"Age": 29, "Year": 2031, "Phase": "Growth", "Event": "Promoted to Senior Associate. Lead ML Projects.", "Status": "Planned", "Importance": 3},
            {"Age": 30, "Year": 2032, "Phase": "Life", "Event": "Marriage ğŸ’ (Target)", "Status": "Life", "Importance": 5},
            {"Age": 32, "Year": 2034, "Phase": "Growth", "Event": "Manager Promotion. Deep expertise in AI Governance.", "Status": "Planned", "Importance": 3},
            {"Age": 35, "Year": 2037, "Phase": "Launch", "Event": "ğŸš€ FOUND YOUR COMPANY (AI Audit Firm). Disruption.", "Status": "Dream", "Importance": 5},
            {"Age": 40, "Year": 2042, "Phase": "Scale", "Event": "Global Expansion. AI-First Assurance.", "Status": "Dream", "Importance": 4},
            {"Age": 45, "Year": 2047, "Phase": "Exit", "Event": "IPO or Strategic Partnership. Financial Freedom.", "Status": "Dream", "Importance": 5},
            {"Age": 50, "Year": 2052, "Phase": "Invest", "Event": "Angel Investor for Deep Tech. University Lecturer.", "Status": "Vision", "Importance": 3},
            {"Age": 60, "Year": 2062, "Phase": "Legacy", "Event": "Establish Scholarship Foundation.", "Status": "Vision", "Importance": 3},
            {"Age": 80, "Year": 2082, "Phase": "Wisdom", "Event": "Write Memoirs. Mentor next gen.", "Status": "Vision", "Importance": 2},
            {"Age": 100, "Year": 2102, "Phase": "Complete", "Event": "Die Empty. No regrets.", "Status": "Final", "Importance": 5}
        ]
        
        df_timeline = pd.DataFrame(timeline_events)
        
        # Visual Timeline - Improved
        fig_timeline = px.scatter(
            df_timeline, 
            x="Year", 
            y="Age", 
            color="Phase", 
            size="Importance",
            hover_name="Event",
            text="Event", 
            title="Life Trajectory Map", 
            size_max=40,
            template="plotly_white"
        )
        fig_timeline.update_traces(textposition='top center', marker=dict(line=dict(width=2, color='DarkSlateGrey')))
        fig_timeline.update_layout(
            height=600,
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True, title="Age"),
            showlegend=True
        )
        # Add connecting line
        fig_timeline.add_trace(go.Scatter(
            x=df_timeline["Year"], 
            y=df_timeline["Age"], 
            mode='lines', 
            line=dict(color='lightgrey', width=1, dash='dot'),
            showlegend=False,
            hoverinfo='skip'
        ))
        
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        with st.expander("Show Data Table"):
            st.dataframe(df_timeline, use_container_width=True)

    with tab2:
        st.subheader("ğŸ§  Skill Evolution: The 'T-Shaped' Professional")
        st.markdown("Visualizing your growth from a CPA specialist to a Tech CEO.")
        
        categories = ['Accounting/Audit', 'Coding/AI', 'English/Global', 'Leadership', 'Risk Taking']
        
        fig_radar = go.Figure()
        
        fig_radar.add_trace(go.Scatterpolar(
            r=[4, 2, 3, 2, 2],
            theta=categories,
            fill='toself',
            name='Current (Age 24)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 4, 3],
            theta=categories,
            fill='toself',
            name='Manager (Age 32)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 5, 5],
            theta=categories,
            fill='toself',
            name='Founder/CEO (Age 40)'
        ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                visible=True,
                range=[0, 5]
                )),
            showlegend=True,
            title="Skill Radar Chart"
        )
        
        col_r1, col_r2 = st.columns([2, 1])
        with col_r1:
            st.plotly_chart(fig_radar, use_container_width=True)
        with col_r2:
            st.info("ğŸ’¡ **Key Insight**")
            st.markdown("""
            *   **Accounting**: Must be perfect early on (CPA).
            *   **Coding/AI**: Your differentiator. Grow this during your Associate years.
            *   **Risk Taking**: The biggest shift required to become a Founder.
            """)

    with tab3:
        st.subheader("ğŸ’° Financial Simulation: Monte Carlo Analysis")
        st.markdown("A Quant-style simulation of your future wealth. **Life is probabilistic, not deterministic.**")
        
        # --- Interactive Sliders ---
        col_ctrl1, col_ctrl2 = st.columns(2)
        with col_ctrl1:
            st.markdown("**Income & Savings**")
            initial_salary = st.slider("Starting Salary (Million JPY)", 4.0, 10.0, 6.0, 0.5)
            savings_rate = st.slider("Savings Rate (%)", 10, 70, 30, 5) / 100.0
            investment_return_mean = st.slider("Expected Return (%)", 1.0, 15.0, 5.0, 0.5) / 100.0
            investment_volatility = st.slider("Volatility (Risk) (%)", 5.0, 30.0, 15.0, 1.0) / 100.0
            
        with col_ctrl2:
            st.markdown("**Startup Variables**")
            launch_age = st.slider("Launch Age", 28, 45, 35)
            exit_age = st.slider("Exit Age", launch_age + 3, 60, 45)
            exit_valuation = st.slider("Exit Valuation (Million JPY)", 100, 10000, 500, 100)
            exit_prob = st.slider("Exit Success Probability (%)", 10, 90, 30, 5) / 100.0
            
        st.divider()

        if st.button("Run Monte Carlo Simulation (100 Scenarios)"):
            with st.spinner("Running 100 simulations..."):
                # Simulation Data
                years = list(range(2026, 2060))
                ages = list(range(24, 58))
                n_sims = 100
                
                # Store all paths
                all_paths = []
                
                for i in range(n_sims):
                    path = []
                    current_asset = 1.0
                    
                    # Startup outcome for this simulation
                    is_successful_exit = np.random.random() < exit_prob
                    
                    for age in ages:
                        # Salary Logic
                        if age < launch_age:
                            # Corporate Phase
                            if age < 26: sal = 0
                            elif age < 30: sal = initial_salary
                            elif age < 35: sal = initial_salary * 1.5
                            elif age < 40: sal = initial_salary * 2.0
                            else: sal = initial_salary * 2.5
                            
                            current_asset += (sal * savings_rate)
                            
                        elif age == launch_age:
                            # Launch Cost
                            current_asset -= 5.0
                            if current_asset < 0: current_asset = 0
                            
                        elif age < exit_age:
                            # Founder Phase (Lean)
                            sal = 4.0
                            current_asset += (sal * 0.1)
                            
                        elif age == exit_age:
                            # Exit Event
                            if is_successful_exit:
                                current_asset += exit_valuation
                            else:
                                current_asset += 0 # Failed exit
                                
                        else:
                            # Post-Exit / Investor
                            pass

                        # Investment Return (Stochastic)
                        # Geometric Brownian Motion component: exp((mu - 0.5*sigma^2) + sigma*Z)
                        # Simplified: return ~ N(mean, vol)
                        r = np.random.normal(investment_return_mean, investment_volatility)
                        current_asset *= (1 + r)
                        
                        path.append(current_asset)
                    
                    all_paths.append(path)
                
                # Calculate Percentiles
                all_paths_np = np.array(all_paths) # shape (n_sims, n_years)
                p10 = np.percentile(all_paths_np, 10, axis=0)
                p50 = np.percentile(all_paths_np, 50, axis=0)
                p90 = np.percentile(all_paths_np, 90, axis=0)
                
                # Plot
                df_mc = pd.DataFrame({
                    "Age": ages,
                    "P10 (Pessimistic)": p10,
                    "P50 (Median)": p50,
                    "P90 (Optimistic)": p90
                })
                
                fig_mc = go.Figure()
                fig_mc.add_trace(go.Scatter(x=ages, y=p90, mode='lines', name='90th Percentile (Lucky)', line=dict(width=0), showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p10, mode='lines', name='10th Percentile (Unlucky)', line=dict(width=0), fill='tonexty', fillcolor='rgba(0,100,80,0.2)', showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p50, mode='lines', name='Median Outcome', line=dict(color='rgb(0,100,80)')))
                
                fig_mc.update_layout(title="Monte Carlo Wealth Projection (90% Confidence Interval)", yaxis_title="Net Assets (Million JPY)", hovermode="x")
                st.plotly_chart(fig_mc, use_container_width=True)
                
                st.success(f"Simulation Complete. Median Asset at Age {ages[-1]}: **{p50[-1]:.1f}M JPY**")
                if p90[-1] > 1000:
                    st.balloons()
        else:
            st.info("Click the button above to run the Monte Carlo simulation.")

    with tab4:
        st.subheader("ğŸ¦„ Entrepreneurship Blueprint: 'Next-Gen AI Audit Firm'")
        
        # Business Stats
        m1, m2, m3 = st.columns(3)
        m1.metric("TAM (Total Addressable Market)", "Â¥500 Billion", "Audit Market in Japan")
        m2.metric("Target Market", "Â¥50 Billion", "Mid-Cap Listed Companies")
        m3.metric("Your Edge", "Tech + License", "Unbeatable Combo")
        
        st.markdown("---")
        
        st.info("ğŸ’¡ **Why AI Audit Firm > SaaS?**")
        st.markdown("""
        *   **SaaS Weakness**: High churn, low barrier to entry, "race to the bottom" pricing. Anyone can build a tool.
        *   **Audit Strength**: **Regulatory Moat**. Only licensed firms can sign off on financial statements. High switching costs.
        *   **The Opportunity**: Build a **Tech-Enabled Audit Firm** (Service + Tech) that operates at 10x efficiency of Big 4, undercutting their fees while maintaining higher margins.
        """)

        st.markdown("""
        **Vision**: Replace the "Army of Associates" with **Autonomous AI Agents**. Focus on high-level judgement and client relationships.
        
        **Phase 1: The "Insider" (Age 26-34)**
        *   **Goal**: Become a domain expert (CPA License is the Key). Understand *exactly* where the inefficiencies are in Big 4.
        *   **Action**: Lead "Digital Transformation" projects. Learn the *regulatory constraints* inside out.
        
        **Phase 2: The "Prototype" (Age 34-35)**
        *   **Goal**: Build the "AI Auditor" (Internal Tool).
        *   **Tech**: RAG (Retrieval Augmented Generation) for accounting standards, GNNs for transaction anomaly detection.
        *   **Team**: You (CTO/CEO) + Experienced Audit Partner (for credibility/signing).
        
        **Phase 3: The "Disruption" (Age 35+)**
        *   **Target**: Mid-cap public companies (tired of high Big 4 fees).
        *   **Product**: **"AI-First Statutory Audit"**. 
        *   **Value Prop**: "Faster audit, lower fees, deeper insights." Not just a software tool, but the *full service*.
        """)

    with tab5:
        st.subheader("ğŸ’ Life, Family & Happiness")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Family Goals")
            st.write("*   **Age 30**: Marriage (Partner who understands the startup grind).")
            st.write("*   **Age 32**: First Child.")
            st.write("*   **Age 35**: Second Child (Coincides with Startup Launch - Tough!).")
            st.write("*   **Policy**: Weekends are for family. No work on Sundays.")
            
        with col2:
            st.markdown("### âœˆï¸ Experiences")
            st.write("*   **20s**: Backpacking Europe/Asia (Cheap travel).")
            st.write("*   **30s**: Family trips to Hawaii/Okinawa.")
            st.write("*   **40s**: World Cruise (Post-Exit).")
            st.write("*   **Hobbies**: Hiking, Coding, Wine Tasting.")


import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date
import json
import os

# Set page config
st.set_page_config(page_title="CPA Perfect Platform 2027", layout="wide", page_icon="ğŸ“š")

# Data Persistence
DATA_FILE = "cpa_data.json"

def load_data():
    defaults = {"scores": [], "logs": [], "xp": 0, "level": 1, "badges": []}
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                # Merge defaults for backward compatibility
                for k, v in defaults.items():
                    if k not in data:
                        data[k] = v
                return data
            except:
                return defaults
    return defaults

def save_data(data):
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Initialize Session State
if 'data' not in st.session_state:
    st.session_state.data = load_data()

if 'quiz_state' not in st.session_state:
    st.session_state.quiz_state = {
        'active': False,
        'subject': None,
        'level': None,
        'q_index': 0,
        'score': 0,
        'show_feedback': False,
        'selected_option': None
    }

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4e8cff;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
    }
    .correct-answer {
        background-color: #d1fae5;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #10b981;
        color: #065f46;
    }
    .incorrect-answer {
        background-color: #fee2e2;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ef4444;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

# Mock Data
mock_exams = [
    {'date': '2026-11-15', 'type': 'Short', 'name': 'Dec Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2026-12-13', 'type': 'Short', 'name': 'Official Dec Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-04-25', 'type': 'Short', 'name': 'May Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-05-23', 'type': 'Short', 'name': 'Official May Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-07-10', 'type': 'Essay', 'name': 'Essay Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-08-20', 'type': 'Essay', 'name': 'Official Aug Essay Exam', 'provider': 'CPAAOB', 'status': 'Target'}
]

# Vocabulary Data
vocab_data = {
    'Financial': [
        {'term': 'Going Concern', 'jp': 'ç¶™ç¶šä¼æ¥­ã®å‰æ', 'desc': 'ä¼æ¥­ãŒå°†æ¥ã«ã‚ãŸã£ã¦äº‹æ¥­ã‚’ç¶™ç¶šã™ã‚‹ã¨ã„ã†å‰æã€‚'},
        {'term': 'Accrual Basis', 'jp': 'ç™ºç”Ÿä¸»ç¾©', 'desc': 'ç¾é‡‘ã®åæ”¯ã«ã‹ã‹ã‚ã‚‰ãšã€çµŒæ¸ˆçš„äº‹è±¡ã®ç™ºç”Ÿæ™‚ç‚¹ã§åç›Šãƒ»è²»ç”¨ã‚’èªè­˜ã™ã‚‹åŸå‰‡ã€‚'},
        {'term': 'Materiality', 'jp': 'é‡è¦æ€§', 'desc': 'è²¡å‹™è«¸è¡¨åˆ©ç”¨è€…ã®æ„æ€æ±ºå®šã«å½±éŸ¿ã‚’ä¸ãˆã‚‹æƒ…å ±ã®æ€§è³ªã‚„é‡‘é¡ã®å¤§ãã•ã€‚'},
        {'term': 'Impairment', 'jp': 'æ¸›æ', 'desc': 'è³‡ç”£ã®åç›Šæ€§ãŒä½ä¸‹ã—ãŸçµæœã€æŠ•è³‡é¡ã®å›åãŒè¦‹è¾¼ã‚ãªããªã£ãŸå ´åˆã«å¸³ç°¿ä¾¡é¡ã‚’æ¸›é¡ã™ã‚‹ã“ã¨ã€‚'},
        {'term': 'Asset Retirement Obligation', 'jp': 'è³‡ç”£é™¤å»å‚µå‹™', 'desc': 'æœ‰å½¢å›ºå®šè³‡ç”£ã®å–å¾—ã‚„ä½¿ç”¨ã«ã‚ˆã£ã¦ç”Ÿã˜ã‚‹ã€é™¤å»ã«é–¢ã™ã‚‹å°†æ¥ã®æ³•çš„ç¾©å‹™ã€‚'},
        {'term': 'Fair Value', 'jp': 'å…¬æ­£ä¾¡å€¤', 'desc': 'å¸‚å ´å‚åŠ è€…é–“ã§ç§©åºã‚ã‚‹å–å¼•ãŒè¡Œã‚ã‚ŒãŸå ´åˆã«æˆç«‹ã™ã‚‹ä¾¡æ ¼ã€‚'},
        {'term': 'Deferred Tax Asset', 'jp': 'ç¹°å»¶ç¨é‡‘è³‡ç”£', 'desc': 'å°†æ¥ã®ç¨é‡‘ã‚’æ¸›ã‚‰ã™åŠ¹æœãŒã‚ã‚‹ä¸€æ™‚å·®ç•°ã€‚å›åå¯èƒ½æ€§ã®æ¤œè¨ãŒå¿…è¦ã€‚'},
        {'term': 'Equity Method', 'jp': 'æŒåˆ†æ³•', 'desc': 'æŠ•è³‡ä¼šç¤¾ã®æŒåˆ†ã«å¿œã˜ã¦ã€è¢«æŠ•è³‡ä¼šç¤¾ã®æç›Šç­‰ã‚’åæ˜ ã•ã›ã‚‹ä¼šè¨ˆå‡¦ç†ã€‚é–¢é€£ä¼šç¤¾ç­‰ã«é©ç”¨ã€‚'},
        {'term': 'Goodwill', 'jp': 'ã®ã‚Œã‚“', 'desc': 'ä¼æ¥­è²·åç­‰ã®éš›ã«æ”¯æ‰•ã£ãŸå¯¾ä¾¡ãŒã€å—ã‘å…¥ã‚ŒãŸç´”è³‡ç”£ã®æ™‚ä¾¡ã‚’ä¸Šå›ã‚‹è¶…éåç›ŠåŠ›ã€‚'},
        {'term': 'Comprehensive Income', 'jp': 'åŒ…æ‹¬åˆ©ç›Š', 'desc': 'ç´”è³‡ç”£ã®å¤‰å‹•é¡ã®ã†ã¡ã€è³‡æœ¬å–å¼•ã«ã‚ˆã‚‰ãªã„éƒ¨åˆ†ã€‚å½“æœŸç´”åˆ©ç›Šï¼‹ãã®ä»–ã®åŒ…æ‹¬åˆ©ç›Šã€‚'},
        {'term': 'Provision', 'jp': 'å¼•å½“é‡‘', 'desc': 'å°†æ¥ã®ç‰¹å®šã®è²»ç”¨ã‚„æå¤±ã«å‚™ãˆã¦ã€å½“æœŸã®è²»ç”¨ã¨ã—ã¦è¨ˆä¸Šã•ã‚Œã‚‹é‡‘é¡ã€‚'},
        {'term': 'Contingent Liability', 'jp': 'å¶ç™ºå‚µå‹™', 'desc': 'å°†æ¥ã®äº‹è±¡ã®ç™ºç”Ÿãƒ»ä¸ç™ºç”Ÿã«ã‚ˆã£ã¦å‚µå‹™ãŒç¢ºå®šã™ã‚‹æ½œåœ¨çš„ãªç¾©å‹™ã€‚'}
    ],
    'Management': [
        {'term': 'Opportunity Cost', 'jp': 'æ©Ÿä¼šåŸä¾¡', 'desc': 'ã‚ã‚‹ä»£æ›¿æ¡ˆã‚’é¸æŠã—ãŸã“ã¨ã«ã‚ˆã£ã¦çŠ ç‰²ã¨ãªã£ãŸï¼ˆè«¦ã‚ãŸï¼‰æœ€å¤§ã®åˆ©ç›Šã€‚'},
        {'term': 'Sunk Cost', 'jp': 'åŸ‹æ²¡åŸä¾¡', 'desc': 'éå»ã®æ„æ€æ±ºå®šã«ã‚ˆã£ã¦æ—¢ã«ç™ºç”Ÿã—ã€å›åä¸èƒ½ãªã‚³ã‚¹ãƒˆã€‚æ„æ€æ±ºå®šã§ã¯ç„¡è¦–ã™ã¹ãã€‚'},
        {'term': 'Break-even Point', 'jp': 'æç›Šåˆ†å²ç‚¹', 'desc': 'å£²ä¸Šé«˜ã¨ç·è²»ç”¨ãŒç­‰ã—ããªã‚Šã€åˆ©ç›ŠãŒã‚¼ãƒ­ã¨ãªã‚‹ç‚¹ã€‚'},
        {'term': 'Safety Margin', 'jp': 'å®‰å…¨ä½™è£•ç‡', 'desc': 'ç¾åœ¨ã®å£²ä¸Šé«˜ãŒæç›Šåˆ†å²ç‚¹ã‚’ã©ã‚Œã ã‘ä¸Šå›ã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã™æŒ‡æ¨™ã€‚é«˜ã„ã»ã©å®‰å…¨ã€‚'},
        {'term': 'Cost Driver', 'jp': 'ã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼', 'desc': 'æ´»å‹•åŸä¾¡è¨ˆç®—ï¼ˆABCï¼‰ã«ãŠã„ã¦ã€ã‚³ã‚¹ãƒˆç™ºç”Ÿã®åŸå› ã¨ãªã‚‹æ´»å‹•é‡ã‚„è¦å› ã€‚'},
        {'term': 'Standard Costing', 'jp': 'æ¨™æº–åŸä¾¡è¨ˆç®—', 'desc': 'ç§‘å­¦çš„ãƒ»çµ±è¨ˆçš„èª¿æŸ»ã«åŸºã¥ã„ã¦è¨­å®šã•ã‚ŒãŸç›®æ¨™åŸä¾¡ã‚’ç”¨ã„ã¦è¡Œã†åŸä¾¡è¨ˆç®—ã€‚'},
        {'term': 'Variance Analysis', 'jp': 'å·®ç•°åˆ†æ', 'desc': 'æ¨™æº–åŸä¾¡ã¨å®Ÿéš›åŸä¾¡ã®å·®é¡ï¼ˆå·®ç•°ï¼‰ã‚’åˆ†æã—ã€åŸå› ã‚’ç‰¹å®šã—ã¦ç®¡ç†ã«å½¹ç«‹ã¦ã‚‹æ‰‹æ³•ã€‚'},
        {'term': 'Direct Costing', 'jp': 'ç›´æ¥åŸä¾¡è¨ˆç®—', 'desc': 'åŸä¾¡ã‚’å¤‰å‹•è²»ã¨å›ºå®šè²»ã«åˆ†è§£ã—ã€å¤‰å‹•è²»ã®ã¿ã‚’è£½å“åŸä¾¡ã¨ã™ã‚‹è¨ˆç®—æ‰‹æ³•ï¼ˆCVPåˆ†æã«æœ‰ç”¨ï¼‰ã€‚'},
        {'term': 'ROI (Return on Investment)', 'jp': 'æŠ•ä¸‹è³‡æœ¬åˆ©ç›Šç‡', 'desc': 'æŠ•è³‡ã—ãŸè³‡æœ¬ã«å¯¾ã—ã¦ã©ã‚Œã ã‘ã®åˆ©ç›Šã‚’ä¸Šã’ãŸã‹ã‚’ç¤ºã™åç›Šæ€§æŒ‡æ¨™ã€‚'},
        {'term': 'Balanced Scorecard', 'jp': 'ãƒãƒ©ãƒ³ã‚¹ãƒˆãƒ»ã‚¹ã‚³ã‚¢ã‚«ãƒ¼ãƒ‰', 'desc': 'è²¡å‹™ã€é¡§å®¢ã€æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã€å­¦ç¿’ã¨æˆé•·ã®4ã¤ã®è¦–ç‚¹ã‹ã‚‰æ¥­ç¸¾ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã€‚'},
        {'term': 'Just-In-Time (JIT)', 'jp': 'ã‚¸ãƒ£ã‚¹ãƒˆãƒ»ã‚¤ãƒ³ãƒ»ã‚¿ã‚¤ãƒ ', 'desc': 'å¿…è¦ãªã‚‚ã®ã‚’ã€å¿…è¦ãªæ™‚ã«ã€å¿…è¦ãªé‡ã ã‘ç”Ÿç”£ãƒ»ä¾›çµ¦ã™ã‚‹ç”Ÿç”£æ–¹å¼ã€‚'},
        {'term': 'Kaizen Costing', 'jp': 'æ”¹å–„åŸä¾¡è¨ˆç®—', 'desc': 'è£½é€ æ®µéšã«ãŠã„ã¦ã€ç¶™ç¶šçš„ãªæ”¹å–„æ´»å‹•ã‚’é€šã˜ã¦åŸä¾¡ä½æ¸›ã‚’å›³ã‚‹æ‰‹æ³•ã€‚'}
    ],
    'Audit': [
        {'term': 'Professional Skepticism', 'jp': 'è·æ¥­çš„æ‡ç–‘å¿ƒ', 'desc': 'å¸¸ã«ç–‘å¿µã‚’æŒã¡ã€ç›£æŸ»è¨¼æ‹ ã‚’æ‰¹åˆ¤çš„ã«è©•ä¾¡ã™ã‚‹å§¿å‹¢ã€‚'},
        {'term': 'Audit Risk', 'jp': 'ç›£æŸ»ãƒªã‚¹ã‚¯', 'desc': 'è²¡å‹™è«¸è¡¨ã«é‡è¦ãªè™šå½è¡¨ç¤ºãŒã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç›£æŸ»äººãŒä¸é©åˆ‡ãªæ„è¦‹ã‚’è¡¨æ˜ã™ã‚‹ãƒªã‚¹ã‚¯ã€‚'},
        {'term': 'Material Misstatement', 'jp': 'é‡è¦ãªè™šå½è¡¨ç¤º', 'desc': 'è²¡å‹™è«¸è¡¨åˆ©ç”¨è€…ã®åˆ¤æ–­ã‚’èª¤ã‚‰ã›ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹èª¤ã‚Šã‚„ä¸æ­£ã€‚'},
        {'term': 'Internal Control', 'jp': 'å†…éƒ¨çµ±åˆ¶', 'desc': 'æ¥­å‹™ã®æœ‰åŠ¹æ€§ãƒ»åŠ¹ç‡æ€§ã€è²¡å‹™å ±å‘Šã®ä¿¡é ¼æ€§ãªã©ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«çµ„ç¹”å†…ã«æ§‹ç¯‰ã•ã‚Œã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚'},
        {'term': 'Substantive Procedures', 'jp': 'å®Ÿè¨¼æ‰‹ç¶š', 'desc': 'é‡è¦ãªè™šå½è¡¨ç¤ºã‚’ç™ºè¦‹ã™ã‚‹ãŸã‚ã«ã€å–å¼•ã‚„æ®‹é«˜ã®è©³ç´°ã‚’ç›´æ¥æ¤œè¨¼ã™ã‚‹æ‰‹ç¶šã€‚'},
        {'term': 'Significant Deficiency', 'jp': 'é‡è¦ãªä¸å‚™', 'desc': 'å†…éƒ¨çµ±åˆ¶ã®ä¸å‚™ã®ã†ã¡ã€è²¡å‹™è«¸è¡¨ã®ä¿¡é ¼æ€§ã«é‡è¦ãªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒé«˜ã„ã‚‚ã®ã€‚'},
        {'term': 'Key Audit Matters (KAM)', 'jp': 'ç›£æŸ»ä¸Šã®ä¸»è¦ãªæ¤œè¨äº‹é …', 'desc': 'å½“å¹´åº¦ã®ç›£æŸ»ã«ãŠã„ã¦ã€è·æ¥­çš„å°‚é–€å®¶ã¨ã—ã¦ç‰¹ã«é‡è¦ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ãŸäº‹é …ã€‚'},
        {'term': 'Audit Evidence', 'jp': 'ç›£æŸ»è¨¼æ‹ ', 'desc': 'ç›£æŸ»æ„è¦‹ã®åŸºç¤ã¨ãªã‚‹çµè«–ã‚’å°ããŸã‚ã«ç›£æŸ»äººãŒå…¥æ‰‹ã—ãŸæƒ…å ±ã€‚'},
        {'term': 'Sampling Risk', 'jp': 'è©¦æŸ»ãƒªã‚¹ã‚¯', 'desc': 'ç›£æŸ»äººãŒæ¯é›†å›£ã®ä¸€éƒ¨ï¼ˆè©¦æŸ»ï¼‰ã«åŸºã¥ã„ã¦çµè«–ã‚’å‡ºã™éš›ã«ã€æ¯é›†å›£å…¨ä½“ã‚’ç²¾æŸ»ã—ãŸå ´åˆã¨ç•°ãªã‚‹çµè«–ã«ãªã‚‹ãƒªã‚¹ã‚¯ã€‚'},
        {'term': 'Management Representation Letter', 'jp': 'çµŒå–¶è€…ç¢ºèªæ›¸', 'desc': 'çµŒå–¶è€…ãŒç›£æŸ»äººã«å¯¾ã—ã¦ã€è²¡å‹™è«¸è¡¨ä½œæˆè²¬ä»»ã®å±¥è¡Œã‚„æƒ…å ±ã®å®Œå…¨æ€§ãªã©ã‚’æ–‡æ›¸ã§ç¢ºèªã™ã‚‹ã‚‚ã®ã€‚'},
        {'term': 'Subsequent Events', 'jp': 'å¾Œç™ºäº‹è±¡', 'desc': 'æ±ºç®—æ—¥å¾Œã«ç™ºç”Ÿã—ãŸäº‹è±¡ã§ã€æ¬¡æœŸä»¥é™ã®è²¡æ”¿çŠ¶æ…‹ã‚„çµŒå–¶æˆç¸¾ã«å½±éŸ¿ã‚’åŠã¼ã™ã‚‚ã®ã€‚'}
    ],
    'Company': [
        {'term': 'Fiduciary Duty', 'jp': 'å—è¨—è€…è²¬ä»»', 'desc': 'å–ç· å½¹ãªã©ãŒä¼šç¤¾ã‚„æ ªä¸»ã®ãŸã‚ã«å¿ å®Ÿã«è·å‹™ã‚’é‚è¡Œã™ã‚‹ç¾©å‹™ï¼ˆå–„ç®¡æ³¨æ„ç¾©å‹™ãƒ»å¿ å®Ÿç¾©å‹™ï¼‰ã€‚'},
        {'term': 'Shareholder Derivative Suit', 'jp': 'æ ªä¸»ä»£è¡¨è¨´è¨Ÿ', 'desc': 'ä¼šç¤¾ãŒå–ç· å½¹ã®è²¬ä»»ã‚’è¿½åŠã—ãªã„å ´åˆã«ã€æ ªä¸»ãŒä¼šç¤¾ã«ä»£ã‚ã£ã¦æèµ·ã™ã‚‹è¨´è¨Ÿã€‚'},
        {'term': 'Business Judgment Rule', 'jp': 'çµŒå–¶åˆ¤æ–­ã®åŸå‰‡', 'desc': 'å–ç· å½¹ã®çµŒå–¶åˆ¤æ–­ãŒåˆç†çš„ã§èª å®Ÿã«è¡Œã‚ã‚ŒãŸå ´åˆã€çµæœçš„ã«æå®³ãŒç”Ÿã˜ã¦ã‚‚è²¬ä»»ã‚’å•ã‚ã‚Œãªã„åŸå‰‡ã€‚'},
        {'term': 'Authorized Shares', 'jp': 'ç™ºè¡Œå¯èƒ½æ ªå¼ç·æ•°', 'desc': 'å®šæ¬¾ã§å®šã‚ã‚‰ã‚ŒãŸã€ä¼šç¤¾ãŒç™ºè¡Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹æ ªå¼ã®ä¸Šé™æ•°ã€‚'},
        {'term': 'Treasury Stock', 'jp': 'è‡ªå·±æ ªå¼', 'desc': 'ä¼šç¤¾ãŒä¿æœ‰ã™ã‚‹è‡ªç¤¾ã®æ ªå¼ã€‚è­°æ±ºæ¨©ã‚„é…å½“è«‹æ±‚æ¨©ã¯ãªã„ã€‚'},
        {'term': 'Articles of Incorporation', 'jp': 'å®šæ¬¾', 'desc': 'ä¼šç¤¾ã®ç›®çš„ã€å•†å·ã€æœ¬åº—æ‰€åœ¨åœ°ãªã©ã®åŸºæœ¬è¦å‰‡ã‚’å®šã‚ãŸæ ¹æœ¬è¦å‰‡ã€‚'},
        {'term': 'Board of Directors', 'jp': 'å–ç· å½¹ä¼š', 'desc': 'æ¥­å‹™åŸ·è¡Œã®æ±ºå®šã‚„å–ç· å½¹ã®è·å‹™åŸ·è¡Œã®ç›£ç£ã‚’è¡Œã†æ©Ÿé–¢ã€‚'},
        {'term': 'Statutory Auditor', 'jp': 'ç›£æŸ»å½¹', 'desc': 'å–ç· å½¹ã®è·å‹™åŸ·è¡Œã‚„ä¼šè¨ˆã‚’ç›£æŸ»ã™ã‚‹æ©Ÿé–¢ã€‚'},
        {'term': 'General Meeting of Shareholders', 'jp': 'æ ªä¸»ç·ä¼š', 'desc': 'æ ªå¼ä¼šç¤¾ã®æœ€é«˜æ„æ€æ±ºå®šæ©Ÿé–¢ã€‚æ ªä¸»ã§æ§‹æˆã•ã‚Œã‚‹ã€‚'},
        {'term': 'Corporate Governance', 'jp': 'ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ãƒˆãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹', 'desc': 'ä¼æ¥­çµŒå–¶ã‚’è¦å¾‹ã™ã‚‹ãŸã‚ã®ä»•çµ„ã¿ã€‚ä¼æ¥­çµ±æ²»ã€‚'},
        {'term': 'Stock Option', 'jp': 'ã‚¹ãƒˆãƒƒã‚¯ãƒ»ã‚ªãƒ—ã‚·ãƒ§ãƒ³', 'desc': 'è‡ªç¤¾æ ªã‚’ã‚ã‚‰ã‹ã˜ã‚æ±ºã‚ã‚‰ã‚ŒãŸä¾¡æ ¼ã§è³¼å…¥ã§ãã‚‹æ¨©åˆ©ã€‚å½¹å“¡ã‚„å¾“æ¥­å“¡ã¸ã®ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã€‚'},
        {'term': 'Mergers and Acquisitions (M&A)', 'jp': 'M&Aï¼ˆåˆä½µãƒ»è²·åï¼‰', 'desc': 'ä¼æ¥­ã®åˆä½µã‚„è²·åã®ç·ç§°ã€‚çµ„ç¹”å†ç·¨è¡Œç‚ºã‚’å«ã‚€ã€‚'}
    ]
}

drill_questions = {
    'Financial': [
        {
            'level': 1,
            'q': "ç¾é‡‘é é‡‘: è²¸å€Ÿå¯¾ç…§è¡¨ã®ã€Œç¾é‡‘ã€ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç´™å¹£ (Bank notes)", "ç¡¬è²¨ (Coins)", "éƒµä¾¿åˆ‡æ‰‹ (Postage stamps)", "å½“åº§é é‡‘ (Demand deposits)"],
            'correct': 2,
            'explanation': "éƒµä¾¿åˆ‡æ‰‹ã¯ã€Œè²¯è”µå“ã€ã¾ãŸã¯ã€Œé€šä¿¡è²»ã€ã¨ã—ã¦å‡¦ç†ã•ã‚Œã€ç¾é‡‘ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚ç¾é‡‘ã«ã¯é€šè²¨ã€å°åˆ‡æ‰‹ã€å½“åº§é é‡‘ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›ä¾¡å„Ÿå´: è³‡ç”£ã®åˆ©ç”¨é‡ã«åŸºã¥ã„ã¦æ¸›ä¾¡å„Ÿå´è²»ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å®šé¡æ³• (Straight-line)", "å®šç‡æ³• (Declining-balance)", "ç”Ÿç”£é«˜æ¯”ä¾‹æ³• (Production-output)", "ç´šæ•°æ³• (Sum-of-the-years'-digits)"],
            'correct': 2,
            'explanation': "ç”Ÿç”£é«˜æ¯”ä¾‹æ³•ã¯ã€ç·è¦‹ç©ç”Ÿç”£é‡ã«å¯¾ã™ã‚‹å½“æœŸã®å®Ÿéš›ç”Ÿç”£é‡ã®å‰²åˆã«åŸºã¥ã„ã¦è²»ç”¨ã‚’é…åˆ†ã™ã‚‹æ–¹æ³•ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ£šå¸è³‡ç”£: ç‰©ä¾¡ä¸Šæ˜‡å±€é¢ã«ãŠã„ã¦ã€å½“æœŸç´”åˆ©ç›ŠãŒæœ€ã‚‚å¤§ãããªã‚‹è©•ä¾¡æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å…ˆå…¥å…ˆå‡ºæ³• (FIFO)", "å¾Œå…¥å…ˆå‡ºæ³• (LIFO)", "ç§»å‹•å¹³å‡æ³• (Weighted Average)", "å€‹åˆ¥æ³• (Specific Identification)"],
            'correct': 0,
            'explanation': "å…ˆå…¥å…ˆå‡ºæ³•(FIFO)ã§ã¯ã€éå»ã®ï¼ˆå®‰ã„ï¼‰åœ¨åº«ãŒå…ˆã«å£²ä¸ŠåŸä¾¡ã¨ãªã‚Šã€æœŸæœ«åœ¨åº«ã«ç›´è¿‘ã®ï¼ˆé«˜ã„ï¼‰å˜ä¾¡ãŒæ®‹ã‚‹ãŸã‚ã€å£²ä¸ŠåŸä¾¡ãŒå°ã•ããªã‚Šåˆ©ç›ŠãŒå¤§ãããªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è³‡ç”£é™¤å»å‚µå‹™: è³‡ç”£é™¤å»å‚µå‹™ã¯å½“åˆä½•ã‚’ã‚‚ã£ã¦æ¸¬å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["é™¤å»è²»ç”¨ã®å°†æ¥ä¾¡å€¤", "é™¤å»è²»ç”¨ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤", "è³‡ç”£ã®å–å¾—åŸä¾¡", "è³‡ç”£ã®å…¬æ­£ä¾¡å€¤"],
            'correct': 1,
            'explanation': "è³‡ç”£é™¤å»å‚µå‹™ã¯ã€å°†æ¥ç™ºç”Ÿã™ã‚‹ã¨è¦‹è¾¼ã¾ã‚Œã‚‹é™¤å»è²»ç”¨ã®ã€Œå‰²å¼•ç¾åœ¨ä¾¡å€¤ã€ã§ç®—å®šã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸€èˆ¬åŸå‰‡: ä¼æ¥­ä¼šè¨ˆåŸå‰‡ã®ã€ŒçœŸå®Ÿæ€§ã®åŸå‰‡ã€ã«ãŠã‘ã‚‹ã€ŒçœŸå®Ÿã€ã®æ„å‘³ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµ¶å¯¾çš„çœŸå®Ÿ", "ç›¸å¯¾çš„çœŸå®Ÿ", "å½¢å¼çš„çœŸå®Ÿ", "æ³•çš„çœŸå®Ÿ"],
            'correct': 1,
            'explanation': "ä¼æ¥­ä¼šè¨ˆã¯è¤‡æ•°ã®ä¼šè¨ˆå‡¦ç†ã®åŸå‰‡ãƒ»æ‰‹ç¶šã®é¸æŠé©ç”¨ã‚’èªã‚ã¦ã„ã‚‹ãŸã‚ã€æ±‚ã‚ã‚‰ã‚Œã‚‹ã®ã¯ã€Œç›¸å¯¾çš„çœŸå®Ÿã€ã§ã‚ã‚‹ã¨è§£ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›æä¼šè¨ˆ: å›ºå®šè³‡ç”£ã®ã€Œå›åå¯èƒ½ä¾¡é¡ã€ã¨ã¯ã€ã©ã®ã‚ˆã†ã«ç®—å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹é«˜ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹ä½ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã®ã¿", "ä½¿ç”¨ä¾¡å€¤ã®ã¿"],
            'correct': 0,
            'explanation': "å›åå¯èƒ½ä¾¡é¡ã¯ã€è³‡ç”£ã®ã€Œæ­£å‘³å£²å´ä¾¡é¡ã€ã¨ã€Œä½¿ç”¨ä¾¡å€¤ã€ã®ã„ãšã‚Œã‹é«˜ã„æ–¹ã®é‡‘é¡ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ãƒªãƒ¼ã‚¹ä¼šè¨ˆ: ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹å–å¼•ã«ãŠã„ã¦ã€å€Ÿæ‰‹ãŒè¨ˆä¸Šã™ã‚‹è³‡ç”£ã®é¡ã¯åŸå‰‡ã¨ã—ã¦ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["ãƒªãƒ¼ã‚¹æ–™ç·é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤ã¨è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ç­‰ã®ã„ãšã‚Œã‹ä½ã„é¡", "è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤"],
            'correct': 1,
            'explanation': "é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹ã§ã¯ã€ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®ç¾åœ¨ä¾¡å€¤ã¨ã€è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ï¼ˆç¾é‡‘è³¼å…¥ä¾¡é¡ï¼‰ã®ã„ãšã‚Œã‹ä½ã„é¡ã§è³‡ç”£è¨ˆä¸Šã—ã¾ã™ã€‚"
        },
        {
            'level': 2,
            'q': "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸: é–“æ¥æ³•ã«ãŠã„ã¦ã€ç¨å¼•å‰å½“æœŸç´”åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹éš›ã€æ¸›ä¾¡å„Ÿå´è²»ã¯ã©ã†èª¿æ•´ã—ã¾ã™ã‹ï¼Ÿ",
            'options': ["åŠ ç®—ã™ã‚‹", "æ¸›ç®—ã™ã‚‹", "èª¿æ•´ã—ãªã„", "å–¶æ¥­å¤–åç›Šã¨ã—ã¦æ‰±ã†"],
            'correct': 0,
            'explanation': "æ¸›ä¾¡å„Ÿå´è²»ã¯ç¾é‡‘æ”¯å‡ºã‚’ä¼´ã‚ãªã„è²»ç”¨ï¼ˆéè³‡é‡‘æç›Šï¼‰ã§ã‚ã‚‹ãŸã‚ã€åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‚’æ±‚ã‚ã‚‹éš›ã¯ã€ŒåŠ ç®—ã€ã—ã¦æˆ»ã—ã¾ã™ã€‚"
        },
        {
            'level': 3,
            'q': "ç¨åŠ¹æœä¼šè¨ˆ: ç¹°å»¶ç¨é‡‘è³‡ç”£ã®å›åå¯èƒ½æ€§ã‚’åˆ¤æ–­ã™ã‚‹éš›ã€ä¼šç¤¾åˆ†é¡ãŒã€Œåˆ†é¡2ã€ã®ä¼æ¥­ã«ãŠã„ã¦ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªä¸€æ™‚å·®ç•°ã¯ã„ã¤ã¾ã§è¨ˆä¸Šå¯èƒ½ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´ä»¥å†…", "5å¹´ä»¥å†…", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå…¨æœŸé–“", "è¨ˆä¸Šã§ããªã„"],
            'correct': 2,
            'explanation': "ã€Œåˆ†é¡2ï¼ˆæ¥­ç¸¾ãŒå®‰å®šã—ã¦ã„ã‚‹ä¼æ¥­ï¼‰ã€ã®å ´åˆã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå°†æ¥æ¸›ç®—ä¸€æ™‚å·®ç•°ã«ã¤ã„ã¦ã¯ã€æœŸé–“åˆ¶é™ãªãï¼ˆå…¨æœŸé–“ï¼‰å›åå¯èƒ½æ€§ãŒã‚ã‚‹ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚"
        }
    ],
    'Management': [
        {
            'level': 1,
            'q': "CVPåˆ†æ: æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡", "å›ºå®šè²» Ã· å¤‰å‹•è²»ç‡", "å¤‰å‹•è²» Ã· å£²ä¸Šé«˜", "åˆ©ç›Š Ã· å£²ä¸Šé«˜"],
            'correct': 0,
            'explanation': "æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ ï¼ å›ºå®šè²» Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡ã®åˆ†é¡: ã€Œç´ ä¾¡ (Prime Cost)ã€ã‚’æ§‹æˆã™ã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç›´æ¥ææ–™è²» ï¼‹ ç›´æ¥åŠ´å‹™è²»", "ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»", "ç›´æ¥ææ–™è²» ï¼‹ è£½é€ é–“æ¥è²»", "è²©å£²è²»åŠã³ä¸€èˆ¬ç®¡ç†è²»"],
            'correct': 0,
            'explanation': "ç´ ä¾¡ï¼ˆPrime Costï¼‰ã¯ã€ç›´æ¥ææ–™è²»ã¨ç›´æ¥åŠ´å‹™è²»ã®åˆè¨ˆã§ã™ã€‚ï¼ˆåŠ å·¥è²» ï¼ ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»ï¼‰"
        },
        {
            'level': 1,
            'q': "æ¨™æº–åŸä¾¡è¨ˆç®—: å®Ÿéš›æ¶ˆè²»é‡ãŒæ¨™æº–æ¶ˆè²»é‡ã‚’ä¸Šå›ã£ãŸå ´åˆã«ç™ºç”Ÿã™ã‚‹å·®ç•°ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æœ‰åˆ©æ•°é‡å·®ç•°", "ä¸åˆ©æ•°é‡å·®ç•°", "æœ‰åˆ©ä¾¡æ ¼å·®ç•°", "ä¸åˆ©ä¾¡æ ¼å·®ç•°"],
            'correct': 1,
            'explanation': "æ¨™æº–ã‚ˆã‚Šã‚‚å¤šãã®æ•°é‡ã‚’æ¶ˆè²»ã—ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ã‚³ã‚¹ãƒˆå¢—ã¨ãªã‚‹ãŸã‚ã€Œä¸åˆ©å·®ç•°ï¼ˆUnfavorableï¼‰ã€ã¨ãªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›´æ¥åŸä¾¡è¨ˆç®—: å›ºå®šè£½é€ é–“æ¥è²»ã¯ã©ã®ã‚ˆã†ã«å‡¦ç†ã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["è£½å“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "æœŸé–“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "è³‡ç”£ã¨ã—ã¦è¨ˆä¸Š", "è² å‚µã¨ã—ã¦è¨ˆä¸Š"],
            'correct': 1,
            'explanation': "ç›´æ¥åŸä¾¡è¨ˆç®—ã§ã¯ã€å›ºå®šè£½é€ é–“æ¥è²»ã¯ç™ºç”Ÿæ™‚ã«ã€ŒæœŸé–“åŸä¾¡ã€ã¨ã—ã¦å…¨é¡è²»ç”¨å‡¦ç†ã•ã‚Œã¾ã™ï¼ˆCVPåˆ†æã«æœ‰ç”¨ï¼‰ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡è¨ˆç®—åŸºæº–: åŸä¾¡è¨ˆç®—åŸºæº–ã«ãŠã„ã¦ã€åŸä¾¡è¨ˆç®—ã®ç›®çš„ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è²¡å‹™è«¸è¡¨ã®ä½œæˆ", "åŸä¾¡ç®¡ç†", "äºˆç®—çµ±åˆ¶", "å¾“æ¥­å“¡çµ¦ä¸ã®è¨ˆç®—"],
            'correct': 3,
            'explanation': "åŸä¾¡è¨ˆç®—åŸºæº–ã«ã¯ã€è²¡å‹™è«¸è¡¨ä½œæˆã€ä¾¡æ ¼è¨ˆç®—ã€åŸä¾¡ç®¡ç†ã€äºˆç®—ç®¡ç†ã€åŸºæœ¬è¨ˆç”»ç­–å®šã®5ã¤ã®ç›®çš„ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€çµ¦ä¸è¨ˆç®—ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "ABC (æ´»å‹•åŸºæº–åŸä¾¡è¨ˆç®—): è£½é€ é–“æ¥è²»ã‚’è£½å“ã«é…è³¦ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹åŸºæº–ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            'options': ["æ“æ¥­åº¦", "ã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ (æ´»å‹•åŸä¾¡è¦å› )", "ç›´æ¥ä½œæ¥­æ™‚é–“", "æ©Ÿæ¢°ç¨¼åƒæ™‚é–“"],
            'correct': 1,
            'explanation': "ABCã§ã¯ã€è£½é€ é–“æ¥è²»ã‚’æ´»å‹•ã”ã¨ã«æŠŠæ¡ã—ã€ãã‚Œãã‚Œã®æ´»å‹•ã®ç™ºç”Ÿè¦å› ã§ã‚ã‚‹ã€Œã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã€ã«åŸºã¥ã„ã¦è£½å“ã«é…è³¦ã—ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æŠ•è³‡ã®çµŒæ¸ˆæ€§è¨ˆç®—: ROI (æŠ•ä¸‹è³‡æœ¬åˆ©ç›Šç‡) ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["åˆ©ç›Š Ã· å£²ä¸Šé«˜", "å£²ä¸Šé«˜ Ã· æŠ•ä¸‹è³‡æœ¬", "åˆ©ç›Š Ã· æŠ•ä¸‹è³‡æœ¬", "æŠ•ä¸‹è³‡æœ¬ Ã· åˆ©ç›Š"],
            'correct': 2,
            'explanation': "ROI (Return On Investment) ã¯ã€åˆ©ç›Šã‚’æŠ•ä¸‹è³‡æœ¬ã§å‰²ã£ã¦ç®—å‡ºã—ã¾ã™ï¼ˆROI = å£²ä¸Šé«˜åˆ©ç›Šç‡ Ã— è³‡æœ¬å›è»¢ç‡ï¼‰ã€‚"
        },
        {
            'level': 2,
            'q': "CVPåˆ†æ: å›ºå®šè²»1,000ã€å¤‰å‹•è²»ç‡0.6ã€ç›®æ¨™åˆ©ç›Š200ã®å ´åˆã€ç›®æ¨™å£²ä¸Šé«˜ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["2,000", "3,000", "2,500", "1,200"],
            'correct': 1,
            'explanation': "ç›®æ¨™å£²ä¸Šé«˜ ï¼ (å›ºå®šè²» ï¼‹ ç›®æ¨™åˆ©ç›Š) Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ (1000 + 200) Ã· 0.4 ï¼ 3000 ã§ã™ã€‚"
        }
    ],
    'Audit': [
        {
            'level': 1,
            'q': "ç›£æŸ»ãƒªã‚¹ã‚¯: ç›£æŸ»ãƒªã‚¹ã‚¯ãƒ»ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆè¦ç´ ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºæœ‰ãƒªã‚¹ã‚¯ Ã— çµ±åˆ¶ãƒªã‚¹ã‚¯ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯", "ãƒ“ã‚¸ãƒã‚¹ãƒªã‚¹ã‚¯ Ã— ç›£æŸ»ãƒªã‚¹ã‚¯", "é‡è¦æ€§ Ã— ãƒªã‚¹ã‚¯", "æŠ½å‡ºãƒªã‚¹ã‚¯ Ã— éæŠ½å‡ºãƒªã‚¹ã‚¯"],
            'correct': 0,
            'explanation': "ç›£æŸ»ãƒªã‚¹ã‚¯ ï¼ é‡è¦ãªè™šå½è¡¨ç¤ºãƒªã‚¹ã‚¯ï¼ˆå›ºæœ‰ãƒªã‚¹ã‚¯Ã—çµ±åˆ¶ãƒªã‚¹ã‚¯ï¼‰ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç‹¬ç«‹æ€§: ã€Œå¤–è¦³çš„ç‹¬ç«‹æ€§ã€ã‚’æãªã†è¦å› ã¨ãªã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ä¿æœ‰", "èª å®Ÿã§ã‚ã‚‹ã“ã¨", "å°‚é–€èƒ½åŠ›ã‚’æœ‰ã™ã‚‹ã“ã¨", "å€«ç†è¦å®šã®éµå®ˆ"],
            'correct': 0,
            'explanation': "è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ã‚„é‡è¦ãªçµŒæ¸ˆçš„åˆ©å®³é–¢ä¿‚ã‚’æœ‰ã™ã‚‹ã“ã¨ã¯ã€å¤–è¦³çš„ç‹¬ç«‹æ€§ï¼ˆç¬¬ä¸‰è€…ã‹ã‚‰è¦‹ã¦ç‹¬ç«‹ã—ã¦ã„ã‚‹ã¨è¦‹ãˆã‚‹ã“ã¨ï¼‰ã‚’æãªã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»æ„è¦‹: è²¡å‹™è«¸è¡¨å…¨ä½“ã«é‡è¦ãªè™šå½è¡¨ç¤ºãŒã‚ã‚Šã€ã‹ã¤ãã®å½±éŸ¿ãŒåºƒç¯„ã§ã‚ã‚‹å ´åˆã«è¡¨æ˜ã•ã‚Œã‚‹æ„è¦‹ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç„¡é™å®šé©æ­£æ„è¦‹", "é™å®šä»˜é©æ­£æ„è¦‹", "ä¸é©æ­£æ„è¦‹", "æ„è¦‹ä¸è¡¨æ˜"],
            'correct': 2,
            'explanation': "é‡è¦ã‹ã¤åºƒç¯„ï¼ˆPervasiveï¼‰ãªè™šå½è¡¨ç¤ºãŒã‚ã‚‹å ´åˆã¯ã€ã€Œä¸é©æ­£æ„è¦‹ï¼ˆAdverse Opinionï¼‰ã€ãŒè¡¨æ˜ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "å†…éƒ¨çµ±åˆ¶: å†…éƒ¨çµ±åˆ¶ã®æ•´å‚™ãƒ»é‹ç”¨è²¬ä»»ã¯èª°ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            'options': ["ç›£æŸ»äºº", "çµŒå–¶è€…", "æ ªä¸»", "æ”¿åºœ"],
            'correct': 1,
            'explanation': "å†…éƒ¨çµ±åˆ¶ã‚’æ•´å‚™ã—é‹ç”¨ã™ã‚‹è²¬ä»»ã¯ã€ŒçµŒå–¶è€…ã€ã«ã‚ã‚Šã¾ã™ã€‚ç›£æŸ»äººã¯ãã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡ãƒ»å ±å‘Šã™ã‚‹ç«‹å ´ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»è¨¼æ‹ : ä¸€èˆ¬çš„ã«æœ€ã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã‚‹ç›£æŸ»è¨¼æ‹ ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµŒå–¶è€…ã¸ã®è³ªå•", "è¦³å¯Ÿ", "å¤–éƒ¨ç¢ºèª", "ç¤¾å†…æ–‡æ›¸"],
            'correct': 2,
            'explanation': "å¤–éƒ¨ã®ç¬¬ä¸‰è€…ã‹ã‚‰ç›´æ¥å…¥æ‰‹ã™ã‚‹ã€Œç¢ºèªï¼ˆExternal Confirmationï¼‰ã€ã¯ã€ä¸€èˆ¬ã«ç¤¾å†…è¨¼æ‹ ã‚ˆã‚Šã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸æ­£å¯¾å¿œ: ã€Œä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã€ã®3è¦ç´ ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼", "æ©Ÿä¼š", "å§¿å‹¢ãƒ»æ­£å½“åŒ–", "ç½°å‰‡"],
            'correct': 3,
            'explanation': "ä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã¯ã€ã€Œå‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã€ã€Œæ©Ÿä¼šã€ã€Œå§¿å‹¢ãƒ»æ­£å½“åŒ–ã€ã®3è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å ±å‘Šæ›¸: ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã„ã¤ã§ã‚ã‚‹ã¹ãã§ã™ã‹ï¼Ÿ",
            'options': ["æ±ºç®—æ—¥", "ç›£æŸ»äººãŒç›£æŸ»æ„è¦‹ã‚’å½¢æˆã™ã‚‹ã®ã«ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥", "æ ªä¸»ç·ä¼šé–‹å‚¬æ—¥", "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æå‡ºæ—¥"],
            'correct': 1,
            'explanation': "ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã€ç›£æŸ»äººãŒæ„è¦‹è¡¨æ˜ã®åŸºç¤ã¨ãªã‚‹ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥ï¼ˆç›£æŸ»çµ‚äº†æ—¥ï¼‰ã¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        }
    ],
    'Company': [
        {
            'level': 1,
            'q': "è¨­ç«‹: æ ªå¼ä¼šç¤¾ã®è¨­ç«‹ã«ãŠã‘ã‚‹æœ€ä½è³‡æœ¬é‡‘ã®é¡ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["1,000ä¸‡å††", "300ä¸‡å††", "1å††", "0å††"],
            'correct': 2,
            'explanation': "ç¾åœ¨ã®ä¼šç¤¾æ³•ã§ã¯ã€æœ€ä½è³‡æœ¬é‡‘åˆ¶åº¦ã¯æ’¤å»ƒã•ã‚Œã¦ãŠã‚Šã€è³‡æœ¬é‡‘1å††ã‹ã‚‰è¨­ç«‹ãŒå¯èƒ½ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è‡ªå·±æ ªå¼: æ ªå¼ä¼šç¤¾ã¯è‡ªå·±æ ªå¼ã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã‹ï¼Ÿ",
            'options': ["å®Œå…¨ã«ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹", "è²¡æºè¦åˆ¶ç­‰ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã‚‹", "è‡ªç”±ã«èªã‚ã‚‰ã‚Œã‚‹", "è§£æ•£æ™‚ã®ã¿èªã‚ã‚‰ã‚Œã‚‹"],
            'correct': 1,
            'explanation': "è‡ªå·±æ ªå¼ã®å–å¾—ã¯ã€åˆ†é…å¯èƒ½é¡ã®ç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚„æ ªä¸»ç·ä¼šæ±ºè­°ãªã©ã®è¦åˆ¶ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ©Ÿé–¢è¨­è¨ˆ: å–ç· å½¹ä¼šè¨­ç½®ä¼šç¤¾ã«ãŠã‘ã‚‹å–ç· å½¹ã®æœ€ä½äººæ•°ã¯ä½•äººã§ã™ã‹ï¼Ÿ",
            'options': ["1äºº", "2äºº", "3äºº", "5äºº"],
            'correct': 2,
            'explanation': "å–ç· å½¹ä¼šã‚’è¨­ç½®ã™ã‚‹å ´åˆã€å–ç· å½¹ã¯3äººä»¥ä¸Šå¿…è¦ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ç·ä¼š: ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ",
            'options': ["è­°æ±ºæ¨©ã®éåŠæ•°", "è­°æ±ºæ¨©ã®3åˆ†ã®1", "è­°æ±ºæ¨©ã®3åˆ†ã®2", "å…¨æ ªä¸»"],
            'correct': 0,
            'explanation': "ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã€Œè­°æ±ºæ¨©ã®éåŠæ•°ã€ã§ã™ï¼ˆå®šæ¬¾ã§3åˆ†ã®1ã¾ã§ç·©å’Œå¯ï¼‰ã€‚æ±ºè­°è¦ä»¶ã¯å‡ºå¸­æ ªä¸»ã®è­°æ±ºæ¨©ã®3åˆ†ã®2ä»¥ä¸Šã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å½¹: ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦ä½•å¹´ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´", "2å¹´", "4å¹´", "10å¹´"],
            'correct': 2,
            'explanation': "ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦4å¹´ã§ã™ã€‚å®šæ¬¾ã«ã‚ˆã£ã¦ã‚‚çŸ­ç¸®ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ã®æ¨©åˆ©: å˜ç‹¬æ ªä¸»æ¨©ï¼ˆ1æ ªã§ã‚‚ä¿æœ‰ã—ã¦ã„ã‚Œã°è¡Œä½¿ã§ãã‚‹æ¨©åˆ©ï¼‰ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æ ªä¸»ç·ä¼šæ‹›é›†è«‹æ±‚æ¨©", "å¸³ç°¿é–²è¦§è«‹æ±‚æ¨©", "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©", "å–ç· å½¹è§£ä»»è«‹æ±‚æ¨©"],
            'correct': 2,
            'explanation': "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©ã‚„è­°æ±ºæ¨©ã¯ã€1æ ªã‹ã‚‰èªã‚ã‚‰ã‚Œã‚‹å˜ç‹¬æ ªä¸»æ¨©ã§ã™ã€‚å¸³ç°¿é–²è¦§æ¨©ãªã©ã¯ä¸€å®šã®æ ªå¼æ•°ãƒ»æœŸé–“ãŒå¿…è¦ãªå°‘æ•°æ ªä¸»æ¨©ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "äº‹æ¥­è­²æ¸¡: æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã¨ãªã‚‹äº‹æ¥­è­²æ¸¡ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["äº‹æ¥­ã®å…¨éƒ¨ã¾ãŸã¯é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡", "é‡è¦ãªè³‡ç”£ã®å‡¦åˆ†", "å¤šé¡ã®å€Ÿè²¡", "æ”¯é…äººã®é¸ä»»"],
            'correct': 0,
            'explanation': "äº‹æ¥­ã®å…¨éƒ¨ã®è­²æ¸¡ã€ã¾ãŸã¯äº‹æ¥­ã®é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡ï¼ˆè­²æ¸¡è³‡ç”£ãŒç·è³‡ç”£ã®1/5è¶…ãªã©ï¼‰ã«ã¯ã€æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã§ã™ã€‚"
        }
    ]
}

# Load generated questions
json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
if os.path.exists(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            generated_questions = json.load(f)
            for subject, questions in generated_questions.items():
                if subject in drill_questions:
                    drill_questions[subject].extend(questions)
                else:
                    drill_questions[subject] = questions
    except Exception as e:
        st.error(f"Failed to load generated questions: {e}")

# Load Study Materials (Syllabus)
def load_study_materials():
    # Looking for 'studying' folder in 'platform' directory (moved inside)
    materials_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'studying')
    syllabus = {}
    extra_pdfs = []
    
    if not os.path.exists(materials_dir):
        return {}, []
        
    for filename in os.listdir(materials_dir):
        if filename.endswith('.xlsx') and not filename.startswith('~$'): # Ignore temp files
            try:
                # Extract subject from filename (e.g., "1-è²¡å‹™ä¼šè¨ˆè«–ã‚³ãƒ¼ã‚¹.xlsx" -> "è²¡å‹™ä¼šè¨ˆè«–")
                parts = filename.split('-')
                if len(parts) > 1:
                    subject_name = parts[1].replace('ã‚³ãƒ¼ã‚¹.xlsx', '')
                else:
                    subject_name = filename.replace('.xlsx', '')
                
                # Read Excel
                file_path = os.path.join(materials_dir, filename)
                df = pd.read_excel(file_path, header=1)
                
                # Fill merged cells (NaN) with previous value
                if 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚«ãƒ†ã‚´ãƒª'].ffill()
                if 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'].ffill()
                
                # Filter relevant columns
                if 'è¬›åº§å' in df.columns:
                    items = []
                    for _, row in df.iterrows():
                        if pd.notna(row['è¬›åº§å']):
                            items.append({
                                'category': row.get('ã‚«ãƒ†ã‚´ãƒª', ''),
                                'subcategory': row.get('ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª', ''),
                                'title': row['è¬›åº§å'],
                                'duration': row.get('å†ç”Ÿæ™‚é–“/æ¨™æº–æ™‚é–“', '')
                            })
                    
                    # Find corresponding PDF
                    pdf_path = os.path.join(materials_dir, filename.replace('.xlsx', '.pdf'))
                    has_pdf = os.path.exists(pdf_path)
                    
                    syllabus[subject_name] = {
                        'items': items,
                        'pdf_path': pdf_path if has_pdf else None,
                        'excel_path': file_path
                    }
            except Exception as e:
                print(f"Error loading {filename}: {e}")
    
    # Load extra PDFs from 'PDF' subdirectory
    pdf_dir = os.path.join(materials_dir, 'PDF')
    if os.path.exists(pdf_dir):
        for f in os.listdir(pdf_dir):
            if f.lower().endswith('.pdf'):
                extra_pdfs.append({
                    'name': f,
                    'path': os.path.join(pdf_dir, f)
                })
                
    # Also load standalone PDFs in the root of 'studying' that are not paired with an Excel file
    # Get list of PDF paths already associated with courses
    paired_pdfs = set()
    for subject_data in syllabus.values():
        if subject_data['pdf_path']:
            paired_pdfs.add(os.path.normpath(subject_data['pdf_path']))
            
    for filename in os.listdir(materials_dir):
        if filename.lower().endswith('.pdf'):
            full_path = os.path.join(materials_dir, filename)
            if os.path.normpath(full_path) not in paired_pdfs:
                extra_pdfs.append({
                    'name': filename,
                    'path': full_path
                })
                
    return syllabus, extra_pdfs

study_materials, extra_pdfs = load_study_materials()

roadmap_md = """
# CPA 1.5 Year Strategy Roadmap

## Phase 0: Foundation (2026)
* **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics.
* **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
* **Jul - Sep**: **CRITICAL** Start Tax Law & Electives.
* **Oct - Dec**: **Dec Short Exam Challenge**. Aim to pass!

## Phase 1: Short Exam Mastery (Jan - May 2027)
* **Jan - Mar**: Solidify basics. 75%+ in drills.
* **Apr - May**: Peak conditioning. Rote memorization.

## Phase 2: Essay Sprint (Jun - Aug 2027)
* **Jun**: Revive Tax/Elective knowledge.
* **Jul**: Output training (Writing).
* **Aug**: Final adjustments.
"""

# Navigation
st.sidebar.title("CPA Platform 2027")

# User Profile in Sidebar
with st.sidebar.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        st.markdown("### ğŸ“")
    with col2:
        curr_level = st.session_state.data.get('level', 1)
        st.write(f"**Level {curr_level}**")
    
    curr_xp = st.session_state.data.get('xp', 0)
    next_level_xp = curr_level * 100
    progress = min(curr_xp / next_level_xp, 1.0)
    st.progress(progress)
    st.caption(f"XP: {curr_xp} / {next_level_xp}")

st.sidebar.markdown("---")

# Quick Links
st.sidebar.markdown("""
    <style>
    .big-rocket-button {
        display: inline-block;
        width: 100%;
        padding: 12px;
        background: linear-gradient(135deg, #FF4B4B 0%, #FF0000 100%);
        color: white !important;
        text-align: center;
        font-size: 18px;
        font-weight: 900;
        border-radius: 12px;
        text-decoration: none !important;
        box-shadow: 0 4px 15px rgba(255, 0, 0, 0.4);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        border: 2px solid rgba(255, 255, 255, 0.2);
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .big-rocket-button:hover {
        background: linear-gradient(135deg, #FF0000 0%, #D00000 100%);
        transform: translateY(-2px) scale(1.02);
        box-shadow: 0 6px 20px rgba(255, 0, 0, 0.6);
        border-color: rgba(255, 255, 255, 0.5);
    }
    .big-rocket-button:active {
        transform: translateY(1px);
        box-shadow: 0 2px 10px rgba(255, 0, 0, 0.3);
    }
    </style>
    <a href="https://member.studying.jp/top/" target="_blank" class="big-rocket-button">
        ğŸš€ STUDYING
    </a>
    """, unsafe_allow_html=True)

st.sidebar.markdown("---")
page = st.sidebar.radio("Navigation", ["Dashboard", "My Syllabus ğŸ“š", "Old Exams ğŸ“„", "Study Timer", "Mock Exams", "Scores", "Drills", "Survival Mode âš¡", "Roadmap", "Big 4 Job Hunting", "Future ğŸš€"])

if page == "Dashboard":
    st.header("Dashboard")
    st.subheader("Goal: 2027 May Short & Aug Essay")
    
    # Countdowns
    col1, col2, col3 = st.columns(3)
    today = date.today()
    
    with col1:
        target = date(2026, 12, 13)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>Dec 2026 Short</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
        
    with col2:
        target = date(2027, 5, 23)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>May 2027 Short</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
        
    with col3:
        target = date(2027, 8, 20)
        diff = (target - today).days
        st.markdown(f"""<div class="metric-card"><h4>Aug 2027 Essay</h4><h1>{max(0, diff)} Days</h1></div>""", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Daily Tip
    st.subheader("ğŸ’¡ Daily CPA Tip")
    tips = [
        "Consistency is key. 30 minutes every day is better than 5 hours once a week.",
        "Focus on 'why', not just 'how'. Understanding the logic helps in applied questions.",
        "Don't ignore the theory. It's 40-50% of the exam.",
        "Review your mistakes. The 'incorrect' options are learning opportunities.",
        "Sleep is part of studying. Memory consolidation happens during sleep.",
        "Use the 'Survival Mode' to build speed and accuracy under pressure!",
        "Audit isn't just memorization; imagine you are the auditor in that situation."
    ]
    import random
    st.info(random.choice(tips))
    
    st.markdown("---")
    
    # Study Time & Radar Chart
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.subheader("Skill Balance")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        # Mock scores for radar chart if empty
        radar_scores = [60, 55, 40, 45, 30, 30]
        
        # Calculate from actual scores if available
        if st.session_state.data["scores"]:
            df_scores = pd.DataFrame(st.session_state.data["scores"])
            avg_scores = []
            for sub in subjects:
                sub_df = df_scores[df_scores['subject'] == sub]
                if not sub_df.empty:
                    avg_scores.append(sub_df['val'].mean())
                else:
                    avg_scores.append(30) # Default baseline
            radar_scores = avg_scores
            
        fig = go.Figure(data=go.Scatterpolar(
            r=radar_scores,
            theta=subjects,
            fill='toself',
            name='Current Skill'
        ))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
    with c2:
        st.subheader("Phase Progress: Foundation")
        st.progress(15)
        st.markdown("""
        * Focus: Financial & Management Accounting Calculation
        * Goal: Complete basic lectures by Aug 2026
        * Next Milestone: Dec 2026 Short Exam
        """)

elif page == "My Syllabus ğŸ“š":
    st.header("My Study Syllabus ğŸ“š")
    st.info("Based on your uploaded materials in 'studying' folder.")
    
    if not study_materials and not extra_pdfs:
        st.warning("No study materials found in 'studying' folder.")
    else:
        # Progress Tracking
        if 'syllabus_progress' not in st.session_state.data:
            st.session_state.data['syllabus_progress'] = []
            
        completed_items = set(st.session_state.data['syllabus_progress'])
        
        # Callback for checkbox
        def toggle_syllabus(key):
            if key in st.session_state.data['syllabus_progress']:
                st.session_state.data['syllabus_progress'].remove(key)
            else:
                st.session_state.data['syllabus_progress'].append(key)
                # Add XP for completing a lecture!
                st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + 50
                st.toast("Lecture Completed! +50 XP", icon="ğŸ“")
            save_data(st.session_state.data)

        # Tabs for subjects
        if study_materials:
            subjects = list(study_materials.keys())
            tabs = st.tabs(subjects)
            
            for i, subject in enumerate(subjects):
                with tabs[i]:
                    data = study_materials[subject]
                    items = data['items']
                    pdf_path = data['pdf_path']
                    excel_path = data['excel_path']
                    
                    # Header Actions
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        st.subheader(f"{subject} ({len(items)} Lectures)")
                    with c2:
                        if pdf_path:
                            if st.button(f"ğŸ“„ Open PDF", key=f"pdf_{subject}"):
                                try:
                                    os.startfile(pdf_path)
                                    st.toast(f"Opening {subject} PDF...", icon="ğŸš€")
                                except Exception as e:
                                    st.error(f"Cannot open PDF: {e}")
                        
                        if st.button(f"ğŸ“Š Open Excel", key=f"excel_{subject}"):
                            try:
                                os.startfile(excel_path)
                                st.toast(f"Opening {subject} Excel...", icon="ğŸ“Š")
                            except Exception as e:
                                st.error(f"Cannot open Excel: {e}")

                    
                    # Progress Bar for Subject
                    subject_completed = [item['title'] for item in items if f"{subject}|{item['title']}" in completed_items]
                    prog = len(subject_completed) / len(items) if items else 0
                    st.progress(prog)
                    st.caption(f"Progress: {len(subject_completed)} / {len(items)} ({prog:.1%})")
                    
                    # Group by Category/Subcategory
                    df = pd.DataFrame(items)
                    if not df.empty and 'category' in df.columns:
                        for cat, group in df.groupby('category'):
                            with st.expander(f"ğŸ“‚ {cat}", expanded=True):
                                for _, row in group.iterrows():
                                    title = row['title']
                                    unique_key = f"{subject}|{title}"
                                    is_done = unique_key in completed_items
                                    
                                    c_chk, c_txt, c_time = st.columns([0.5, 4, 1.5])
                                    with c_chk:
                                        st.checkbox("", value=is_done, key=f"chk_{unique_key}", on_change=toggle_syllabus, kwargs={'key': unique_key})
                                    
                                    with c_txt:
                                        if is_done:
                                            st.markdown(f"~~{title}~~")
                                        else:
                                            st.markdown(f"**{title}**")
                                            if row['subcategory']:
                                                st.caption(f"â”” {row['subcategory']}")
                                                
                                    with c_time:
                                        st.caption(f"â±ï¸ {row['duration']}")

        # Supplemental Resources (Extra PDFs)
        if extra_pdfs:
            st.markdown("---")
            st.subheader("ğŸ“š Supplemental Resources")
            for pdf in extra_pdfs:
                c1, c2 = st.columns([4, 1])
                with c1:
                    st.markdown(f"ğŸ“„ **{pdf['name']}**")
                with c2:
                    if st.button("Open", key=f"extra_pdf_{pdf['name']}"):
                        try:
                            os.startfile(pdf['path'])
                            st.toast(f"Opening {pdf['name']}...", icon="ğŸš€")
                        except Exception as e:
                            st.error(f"Cannot open PDF: {e}")

elif page == "Old Exams ğŸ“„":
    st.header("Old Exam Papers ğŸ“„")
    
    # Path to EXAM folder
    # platform/app.py -> CPA/platform -> CPA/EXAM
    exam_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'EXAM')
    
    if not os.path.exists(exam_dir):
        st.error(f"EXAM directory not found at: {exam_dir}")
    else:
        files = [f for f in os.listdir(exam_dir) if f.lower().endswith('.pdf')]
        
        if not files:
            st.warning("No PDF exam papers found.")
        else:
            st.write(f"Found {len(files)} exam papers.")
            
            for f in sorted(files):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.markdown(f"ğŸ“„ **{f}**")
                with col2:
                    if st.button("Open", key=f"open_exam_{f}"):
                        try:
                            file_path = os.path.join(exam_dir, f)
                            os.startfile(file_path)
                            st.toast(f"Opening {f}...", icon="ğŸš€")
                        except Exception as e:
                            st.error(f"Error opening file: {e}")
            
            st.markdown("---")
            st.info("ğŸ’¡ Tip: Use these papers to practice time management.")

elif page == "Study Timer":
    st.header("Study Timer")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Log Study Session")
        with st.form("timer_form"):
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective"])
            duration = st.number_input("Duration (minutes)", min_value=1, value=60)
            date_val = st.date_input("Date", value=date.today())
            submitted = st.form_submit_button("Log Session")
            
            if submitted:
                new_log = {
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'duration': duration
                }
                st.session_state.data["logs"].append(new_log)
                save_data(st.session_state.data)
                st.success("Session logged!")
                
    with col2:
        st.subheader("Recent Logs")
        if st.session_state.data["logs"]:
            df_logs = pd.DataFrame(st.session_state.data["logs"])
            st.dataframe(df_logs.sort_values('date', ascending=False))
            
            total_mins = df_logs['duration'].sum()
            hours = total_mins // 60
            mins = total_mins % 60
            st.metric("Total Study Time", f"{hours}h {mins}m")
        else:
            st.info("No logs yet.")

elif page == "Mock Exams":
    st.header("Mock Exam Schedule")
    df_exams = pd.DataFrame(mock_exams)
    st.table(df_exams)

elif page == "Scores":
    st.header("Score Tracker")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        with st.form("score_form"):
            name = st.text_input("Exam/Drill Name")
            date_val = st.date_input("Date", value=date.today())
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective", "Total"])
            val = st.number_input("Score (%)", min_value=0, max_value=100, value=70)
            submitted = st.form_submit_button("Save Score")
            
            if submitted:
                new_score = {
                    'name': name,
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'val': val
                }
                st.session_state.data["scores"].append(new_score)
                save_data(st.session_state.data)
                st.success("Score saved!")
                
    with col2:
        if st.session_state.data["scores"]:
            df = pd.DataFrame(st.session_state.data["scores"])
            st.subheader("History")
            st.dataframe(df.sort_values('date', ascending=False))
            
            # Line Chart
            st.subheader("Trend")
            fig = go.Figure()
            for sub in df['subject'].unique():
                sub_df = df[df['subject'] == sub].sort_values('date')
                fig.add_trace(go.Scatter(x=sub_df['date'], y=sub_df['val'], mode='lines+markers', name=sub))
            fig.update_layout(yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No scores recorded yet.")

elif page == "Drills":
    st.header("Drills âœï¸")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("Select Topic")
        subject = st.radio("Subject", ["Financial", "Management", "Audit", "Company"])
        
        st.subheader("Select Level")
        level = st.radio("Level", ["Level 1 (Basic)", "Level 2 (Standard)", "Level 3 (Advanced)", "Vocabulary (Important Words)"])
        level_map = {
            "Level 1 (Basic)": 1, 
            "Level 2 (Standard)": 2, 
            "Level 3 (Advanced)": 3,
            "Vocabulary (Important Words)": "vocab"
        }
        selected_level = level_map[level]
        
        if selected_level == "vocab":
            st.info("ğŸ’¡ Hint: These are key English terms often found in global accounting standards (IFRS/US GAAP).")
    
        # Load generated questions if available and not already loaded
        if 'generated_questions' not in st.session_state:
            try:
                with open('questions.json', 'r', encoding='utf-8') as f:
                    st.session_state.generated_questions = json.load(f)
            except FileNotFoundError:
                st.session_state.generated_questions = {}

        if st.button("Start / Restart Quiz"):
            import random
            st.session_state.quiz_state['active'] = True
            st.session_state.quiz_state['subject'] = subject
            st.session_state.quiz_state['level'] = selected_level
            st.session_state.quiz_state['q_index'] = 0
            st.session_state.quiz_state['score'] = 0
            st.session_state.quiz_state['show_feedback'] = False
            st.session_state.quiz_state['selected_option'] = None
            
            # Select questions based on level
            if selected_level == "vocab":
                vocab_list = vocab_data.get(subject, [])
                if vocab_list:
                    vocab_questions = []
                    for v in vocab_list:
                        vocab_questions.append({
                            'q': f"ã€é‡è¦èªå¥ã€‘ ã€Œ{v['term']}ã€ ã®æ„å‘³ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã¯ï¼Ÿ",
                            'options': [v['desc'], "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é€†ã®æ„å‘³ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: ç„¡é–¢ä¿‚ãªå®šç¾©ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é¡ä¼¼ç”¨èªã®å®šç¾©ï¼‰"],
                            'correct': 0,
                            'explanation': f"**{v['term']} ({v['jp']})**\n\n{v['desc']}",
                            'type': 'vocab'
                        })
                    # Shuffle options for each question
                    for q in vocab_questions:
                        correct_opt = q['options'][0]
                        random.shuffle(q['options'])
                        q['correct'] = q['options'].index(correct_opt)
                    
                    st.session_state.quiz_state['questions'] = vocab_questions
                else:
                    st.warning(f"No vocabulary data for {subject} yet.")
                    st.session_state.quiz_state['active'] = False
            
            elif selected_level == 2 or selected_level == 3:
                # Use generated questions for Level 2/3
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level_gen_qs = [q for q in gen_qs if q.get('level') == selected_level]
                
                if level_gen_qs:
                     # Pick 10 random questions
                    if len(level_gen_qs) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(level_gen_qs, 10)
                    else:
                        st.session_state.quiz_state['questions'] = level_gen_qs
                else:
                    st.warning(f"No generated questions for {subject} Level {selected_level} yet.")
                    st.session_state.quiz_state['active'] = False

            else:
                # Level 1 (Static questions)
                raw_questions = drill_questions.get(subject, [])
                # Filter for Level 1 or undefined (legacy)
                filtered_questions = [q for q in raw_questions if q.get('level', 1) == 1]
                
                if filtered_questions:
                    st.session_state.quiz_state['questions'] = filtered_questions
                else:
                    st.warning(f"No questions found for {subject} Level 1.")
                    st.session_state.quiz_state['active'] = False
                
    with col2:
        qs = st.session_state.quiz_state
        if qs['active']:
            current_q = qs['questions'][qs['q_index']]
            total_q = len(qs['questions'])
            
            st.subheader(f"Question {qs['q_index'] + 1} / {total_q}")
            st.markdown(f"**{current_q['q']}**")
            
            # Options
            options = current_q['options']
            
            # If feedback is shown, disable interaction or show result
            if qs['show_feedback']:
                for idx, opt in enumerate(options):
                    if idx == current_q['correct']:
                        st.markdown(f"<div class='correct-answer'>{opt} (Correct)</div>", unsafe_allow_html=True)
                    elif idx == qs['selected_option']:
                        st.markdown(f"<div class='incorrect-answer'>{opt} (Your Answer)</div>", unsafe_allow_html=True)
                    else:
                        st.text(opt)
                
                st.markdown("### Explanation")
                st.info(current_q['explanation'])
                
                if qs['q_index'] < total_q - 1:
                    if st.button("Next Question"):
                        qs['q_index'] += 1
                        qs['show_feedback'] = False
                        qs['selected_option'] = None
                        st.rerun()
                else:
                    score = qs['score']
                    st.success(f"Quiz Completed! Score: {score} / {total_q}")
                    
                    if st.button("Finish & Claim XP"):
                        # XP Logic
                        earned_xp = score * 10
                        current_xp = st.session_state.data.get('xp', 0)
                        current_level = st.session_state.data.get('level', 1)
                        
                        new_xp = current_xp + earned_xp
                        required_xp = current_level * 100
                        
                        leveled_up = False
                        while new_xp >= required_xp:
                            new_xp -= required_xp
                            current_level += 1
                            required_xp = current_level * 100
                            leveled_up = True
                        
                        st.session_state.data['xp'] = new_xp
                        st.session_state.data['level'] = current_level
                        
                        # Save score history
                        st.session_state.data["scores"].append({
                            'name': f"Drill: {qs.get('subject', 'General')} Lv{qs.get('level', '?')}",
                            'date': date.today().strftime("%Y-%m-%d"),
                            'subject': qs.get('subject', 'General'),
                            'val': (score / total_q) * 100 if total_q > 0 else 0
                        })
                        save_data(st.session_state.data)
                        
                        if leveled_up:
                            st.balloons()
                            st.success(f"LEVEL UP! You are now Level {current_level}!")
                        else:
                            st.success(f"Earned {earned_xp} XP!")
                            
                        qs['active'] = False
                        st.rerun()
                        
            else:
                choice = st.radio("Choose Answer:", options, index=None, key=f"q_{qs['q_index']}")
                if st.button("Submit Answer"):
                    if choice:
                        selected_idx = options.index(choice)
                        qs['selected_option'] = selected_idx
                        qs['show_feedback'] = True
                        if selected_idx == current_q['correct']:
                            qs['score'] += 1
                        st.rerun()
                    else:
                        st.warning("Please select an option.")
        else:
            st.info("Select a subject and level from the sidebar to start.")

elif page == "Survival Mode âš¡":
    st.header("âš¡ Survival Mode")
    st.markdown("### Challenge your limits! 3 Strikes and you're out.")
    
    # Initialize State
    if 'survival' not in st.session_state:
        st.session_state.survival = {
            'active': False,
            'lives': 3,
            'streak': 0,
            'score': 0,
            'q': None,
            'feedback': False,
            'user_ans': None,
            'target_streak': "Unlimited"
        }
    
    ss = st.session_state.survival
    
    # Load Questions Logic
    if 'all_questions' not in st.session_state:
        all_qs = []
        # Static
        for sub, qs in drill_questions.items():
            for q in qs:
                # Create a copy to avoid modifying original
                q_copy = q.copy()
                q_copy['subject'] = sub
                all_qs.append(q_copy)
        # Generated
        json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
        if os.path.exists(json_path):
             try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gen_qs = json.load(f)
                    for sub, qs in gen_qs.items():
                        for q in qs:
                            q_copy = q.copy()
                            q_copy['subject'] = sub
                            all_qs.append(q_copy)
             except:
                 pass
        st.session_state.all_questions = all_qs
    
    if not ss['active']:
        st.subheader("Select Challenge Mode")
        streak_target = st.radio("Target Streak", ["Unlimited", 1, 5, 10], horizontal=True, format_func=lambda x: "âˆ Unlimited" if x == "Unlimited" else f"Target: {x} ğŸ”¥")

        if st.button("ğŸš€ Start Challenge", use_container_width=True):
            ss['active'] = True
            ss['lives'] = 3
            ss['streak'] = 0
            ss['score'] = 0
            ss['q'] = None
            ss['feedback'] = False
            ss['target_streak'] = streak_target
            st.rerun()
            
    else:
        # Metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("Lives", "â¤ï¸" * ss['lives'])
        target_display = "âˆ" if ss.get('target_streak', "Unlimited") == "Unlimited" else ss['target_streak']
        c2.metric("Streak", f"ğŸ”¥ {ss['streak']} / {target_display}")
        c3.metric("Score", ss['score'])
        
        target = ss.get('target_streak', "Unlimited")
        is_win = target != "Unlimited" and ss['streak'] >= target

        if ss['lives'] <= 0 or is_win:
            if is_win:
                st.balloons()
                st.success(f"ğŸ‰ MISSION ACCOMPLISHED! You reached a {ss['streak']} streak!")
            else:
                st.error("ğŸ’€ GAME OVER")
            
            st.markdown(f"### Final Score: {ss['score']}")
            
            # Save High Score
            if ss['score'] > 0:
                st.session_state.data["scores"].append({
                    'name': f"Survival Mode âš¡ (Target {target})",
                    'date': date.today().strftime("%Y-%m-%d"),
                    'subject': 'Survival',
                    'val': ss['score'] # Just storing score
                })
                save_data(st.session_state.data)
            
            if st.button("Try Again", use_container_width=True):
                ss['active'] = False
                st.rerun()
        else:
            # Get Question
            if ss['q'] is None:
                import random
                if st.session_state.all_questions:
                    q_data = random.choice(st.session_state.all_questions)
                    # Shuffle options
                    opts = q_data['options'].copy()
                    correct_text = q_data['options'][q_data['correct']]
                    random.shuffle(opts)
                    
                    ss['q'] = {
                        'q': q_data['q'],
                        'options': opts,
                        'correct_idx': opts.index(correct_text),
                        'explanation': q_data['explanation'],
                        'subject': q_data.get('subject', 'General')
                    }
                else:
                    st.error("No questions found!")
                    st.stop()
            
            q = ss['q']
            
            st.markdown(f"**[{q['subject']}]** {q['q']}")
            
            if not ss['feedback']:
                # Use a form to prevent reload on radio selection
                with st.form(key=f"surv_form_{ss['score']}_{ss['lives']}"):
                    ans = st.radio("Select Answer:", q['options'])
                    submit = st.form_submit_button("Submit Answer")
                    
                    if submit:
                        ss['user_ans'] = q['options'].index(ans)
                        ss['feedback'] = True
                        
                        if ss['user_ans'] == q['correct_idx']:
                            # Bonus XP for streak
                            bonus = ss['streak'] * 2
                            points = 10 + bonus
                            ss['score'] += points
                            ss['streak'] += 1
                            st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + points
                            st.toast(f"Correct! +{points} XP", icon="âœ…")
                            
                            # Check Win
                            target = ss.get('target_streak', "Unlimited")
                            if target != "Unlimited" and ss['streak'] >= target:
                                st.rerun()
                        else:
                            ss['lives'] -= 1
                            ss['streak'] = 0
                            st.toast("Wrong Answer!", icon="âŒ")
                        
                        st.rerun()
            else:
                # Show Feedback
                if ss['user_ans'] == q['correct_idx']:
                    st.success("âœ… Correct!")
                else:
                    st.error(f"âŒ Wrong! Correct: {q['options'][q['correct_idx']]}")
                
                st.info(f"**Explanation:**\n\n{q['explanation']}")
                
                if st.button("Next Question â¡", use_container_width=True):
                    ss['q'] = None
                    ss['feedback'] = False
                    st.rerun()

elif page == "Roadmap":
    st.header("ğŸ—ºï¸ CPA Exam Strategy Roadmap (2026-2027)")
    
    # 1. Countdown Section
    today = date.today()
    tanto_date = date(2027, 5, 23) # Estimated
    ronbun_date = date(2027, 8, 20) # Estimated
    
    days_tanto = (tanto_date - today).days
    days_ronbun = (ronbun_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Days to May Short Exam", f"{days_tanto} Days", "Target: Pass")
    col2.metric("Days to Aug Essay Exam", f"{days_ronbun} Days", "Final Goal")
    col3.metric("Current Phase", "Foundation (2026)", "Build Habits")
    
    st.divider()

    # 2. Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Visual Schedule (Gantt)", "ğŸ—“ï¸ Monthly Strategy", "â° Daily Routine"])
    
    with tab1:
        st.subheader("Strategic Timeline")
        # Gantt Chart Data
        df_gantt = pd.DataFrame([
            dict(Task="Foundation (Fin/Mgmt)", Start='2026-02-01', Finish='2026-06-30', Phase='Phase 0: Foundation'),
            dict(Task="Audit & Company Law", Start='2026-04-01', Finish='2026-09-30', Phase='Phase 0: Foundation'),
            dict(Task="Tax Law & Electives", Start='2026-07-01', Finish='2026-12-31', Phase='Phase 0: Foundation'),
            dict(Task="Dec Short (Practice)", Start='2026-10-01', Finish='2026-12-13', Phase='Phase 0: Foundation'),
            dict(Task="Short Exam Mastery", Start='2027-01-01', Finish='2027-05-23', Phase='Phase 1: Short Exam'),
            dict(Task="Essay Sprint", Start='2027-05-24', Finish='2027-08-20', Phase='Phase 2: Essay Sprint'),
        ])
        
        # Create Gantt
        fig = px.timeline(df_gantt, x_start="Start", x_end="Finish", y="Task", color="Phase", 
                          title="CPA Exam 1.5 Year Plan",
                          color_discrete_sequence=px.colors.qualitative.Prism)
        fig.update_yaxes(autorange="reversed") # Task order top-to-bottom
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("ğŸ’¡ **Golden Route**: Pass May Short -> Pass August Essay in one go.")

    with tab2:
        st.subheader("Detailed Monthly Strategy")
        
        with st.expander("Phase 0: Foundation (2026)", expanded=True):
            st.markdown("""
            *   **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics (Calculations).
            *   **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
            *   **Jul - Sep**: **CRITICAL** Start Tax Law & Electives (Management/Statistics).
            *   **Oct - Dec**: **Dec Short Exam Challenge**. Aim for 60%+ even if you fail.
            """)
            
        with st.expander("Phase 1: Short Exam Mastery (Jan - May 2027)"):
            st.markdown("""
            *   **Jan - Mar**: Solidify basics. Aim for 75%+ in drills. Focus on weak areas.
            *   **Apr**: Mock Exams (TAC/Ohara). Analyze errors thoroughly.
            *   **May**: Peak conditioning. Rote memorization of text (Audit/Company Law). **PASS EXAM**.
            """)
            
        with st.expander("Phase 2: Essay Sprint (Jun - Aug 2027)"):
            st.markdown("""
            *   **Jun**: Revive Tax/Elective knowledge (often forgotten during Short prep).
            *   **Jul**: Output training (Writing). Learn "Key Phrases" for theory questions.
            *   **Aug**: Final adjustments. Health management is key. **PASS EXAM**.
            """)

    with tab3:
        st.subheader("â° Ideal Daily Routine (Student/Full-time Study)")
        
        schedule_data = [
            {"Time": "07:00 - 08:00", "Activity": "Wake up / Light Breakfast / Review Vocab"},
            {"Time": "08:00 - 11:00", "Activity": "ğŸ§  **Deep Work 1**: Financial Accounting (Calc) - 3h"},
            {"Time": "11:00 - 12:00", "Activity": "Lunch / Nap (20m)"},
            {"Time": "12:00 - 15:00", "Activity": "ğŸ§  **Deep Work 2**: Management Accounting / Theory - 3h"},
            {"Time": "15:00 - 16:00", "Activity": "Gym / Walk / Break"},
            {"Time": "16:00 - 19:00", "Activity": "ğŸ§  **Deep Work 3**: Corporate Law / Audit - 3h"},
            {"Time": "19:00 - 20:00", "Activity": "Dinner / Relax"},
            {"Time": "20:00 - 22:00", "Activity": "ğŸ“– **Review**: Weak areas / Next day planning - 2h"},
            {"Time": "22:00 - 23:00", "Activity": "Wind down / Sleep"},
        ]
        st.table(pd.DataFrame(schedule_data))
        st.success("Target: **10+ Hours/Day** of high-quality study.")

elif page == "Big 4 Job Hunting":
    st.header("ğŸ¢ Big 4 CPA Job Hunting Strategy")
    st.markdown("Strategy guide and comparison for the major audit firms in Japan.")

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["Strategy & Timeline", "Big 4 Comparison", "Tech & Data Science Advantage ğŸ¤–", "Boston Career Forum ğŸ‡ºğŸ‡¸", "Interview & Case Prep ğŸ“"])

    with tab1:
        st.subheader("ğŸ“… Job Hunting Timeline (Typical)")
        st.info("The job hunting season for CPA candidates peaks immediately after the August Essay Exam.")
        
        timeline_data = [
            {"Period": "August (Late)", "Activity": "Essay Exam Ends", "Details": "Rest for a few days, then prepare for briefings."},
            {"Period": "September", "Activity": "Firm Briefings (Setsumeikai)", "Details": "Attend online/offline sessions. Key for networking."},
            {"Period": "October", "Activity": "Entry Sheet (ES) Submission", "Details": "Prepare resumes. Focus on 'Why this firm?'"},
            {"Period": "November (Mid)", "Activity": "Results Announcement", "Details": "Official passing results released."},
            {"Period": "November (Late)", "Activity": "Interviews & Offers", "Details": "Intensive interview period (1-2 weeks). Offers issued quickly."}
        ]
        st.table(pd.DataFrame(timeline_data))

        st.subheader("ğŸ’¡ Key Strategies")
        st.markdown("""
        *   **Start Early**: Don't wait for the results. Attend briefings in September.
        *   **Differentiate**: All Big 4 do audit. Focus on culture, specific clients (e.g., Tech, Auto), or non-audit opportunities (IPO, Advisory).
        *   **Networking**: Use alumni connections (OB/OG Visits) if possible.
        """)

    with tab2:
        st.subheader("ğŸ“Š Big 4 Audit Firms vs. Tech Giants Comparison")
        
        # Personalized Ranking Section
        st.markdown("### ğŸ† Personalized Ranking for You (ML/DS Master's Student)")
        st.info("""
        Based on your **CPA Goal** + **ML/Data Science Strength**, here is your recommended priority:
        
        1.  ğŸ¥‡ **PwC Aarata / EY ShinNihon**: Best balance of **Digital Audit** innovation and **CPA License** support. Both have dedicated "Digital" tracks for auditors.
        2.  ğŸ¥ˆ **Deloitte Tohmatsu**: Massive scale and data access. Great for "Audit Analytics" but slightly more traditional hierarchy.
        3.  ğŸ¥‰ **Accenture / IBM**: **Top Tier for Tech**, but âš ï¸ **WARNING**: You likely **cannot** complete the CPA practical experience (Jitsumu Hoshu) requirement here. Great for *after* getting your CPA, or if you pivot to Consulting.
        """)

        # Radar Chart
        st.subheader("Visual Comparison (Illustrative)")
        categories = ['Tech/AI Focus', 'Global Network', 'Domestic Scale', 'IPO/Venture', 'Work-Life Balance']

        fig = go.Figure()

        # Tohmatsu (Deloitte)
        fig.add_trace(go.Scatterpolar(
            r=[4, 5, 5, 5, 3],
            theta=categories,
            fill='toself',
            name='Tohmatsu (Deloitte)'
        ))
        # AZSA (KPMG)
        fig.add_trace(go.Scatterpolar(
            r=[3, 4, 5, 3, 4],
            theta=categories,
            fill='toself',
            name='AZSA (KPMG)'
        ))
        # EY ShinNihon
        fig.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 3, 3],
            theta=categories,
            fill='toself',
            name='EY ShinNihon'
        ))
        # PwC Aarata
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 3, 2, 4],
            theta=categories,
            fill='toself',
            name='PwC Aarata'
        ))
        # Accenture (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 2, 2],
            theta=categories,
            fill='toself',
            name='Accenture (Ref)'
        ))
        # IBM (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 4, 1, 4],
            theta=categories,
            fill='toself',
            name='IBM (Ref)'
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5]
                )),
            showlegend=True,
            height=500,
            margin=dict(l=40, r=40, t=20, b=20)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("ğŸ¢ Firm Details")
        firms_data = [
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»»ç›£æŸ»æ³•äººãƒˆãƒ¼ãƒãƒ„ (Tohmatsu)",
                "Network": "Deloitte",
                "Key Strengths": "Largest scale, aggressive growth, strong in IPOs and Venture support.",
                "Culture": "Meritocratic, Sports-oriented, High energy.",
                "Link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"
            },
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»» ã‚ãšã•ç›£æŸ»æ³•äºº (AZSA)",
                "Network": "KPMG",
                "Key Strengths": "Balanced portfolio, strong domestic manufacturing clients.",
                "Culture": "Conservative, Collaborative, 'Gentlemanly'.",
                "Link": "https://home.kpmg/jp/ja/home/careers.html"
            },
            {
                "Firm Name (JP)": "EYæ–°æ—¥æœ¬æœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (EY ShinNihon)",
                "Network": "EY",
                "Key Strengths": "Long history, large number of listed clients, strong Digital Audit focus.",
                "Culture": "Traditional yet transforming, Diversity focus.",
                "Link": "https://www.ey.com/ja_jp/careers/audit"
            },
            {
                "Firm Name (JP)": "PwCã‚ã‚‰ãŸæœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (PwC Aarata)",
                "Network": "PwC",
                "Key Strengths": "Global integration, strong advisory connection, newer organizational style.",
                "Culture": "Global, Flat hierarchy, Innovative.",
                "Link": "https://www.pwc.com/jp/ja/careers/audit.html"
            },
            {
                "Firm Name (JP)": "ã‚¢ã‚¯ã‚»ãƒ³ãƒãƒ¥ã‚¢ (Accenture)",
                "Network": "Accenture",
                "Key Strengths": "Absolute leader in DX/IT Consulting. High salary.",
                "Culture": "Up or Out (Evolving), High performance, Tech-first.",
                "Link": "https://www.accenture.com/jp-ja/careers"
            },
            {
                "Firm Name (JP)": "æ—¥æœ¬IBM (IBM Japan)",
                "Network": "IBM",
                "Key Strengths": "Deep research (Watson), Hybrid Cloud, Legacy stability.",
                "Culture": "Engineering-driven, Mature, Good work-life balance.",
                "Link": "https://www.ibm.com/jp-ja/employment"
            }
        ]
        
        # Display as a styled table or cards
        for firm in firms_data:
            with st.expander(f"{firm['Firm Name (JP)']} ({firm['Network']})", expanded=True):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**Strengths:** {firm['Key Strengths']}")
                    st.markdown(f"**Culture:** {firm['Culture']}")
                with col2:
                    st.link_button("Recruit Page", firm['Link'])
    
    with tab3:
        st.subheader("ğŸ¤– Leveraging Data Science & ML in CPA Job Hunting")
        st.markdown("""
        **Profile:** Double Degree Master's Student (Keio ğŸ‡¯ğŸ‡µ & Leibniz Hannover ğŸ‡©ğŸ‡ª) | **Major:** Mechanical Engineering
        
        **Your Technical Arsenal:**
        *   **Advanced ML:** Graph Neural Networks (GNNs), PyTorch, Bayesian Inference (MCMC/TMCMC).
        *   **Engineering:** Finite Element Analysis (FEA), Structural Health Monitoring.
        *   **Languages:** Python, MATLAB, TypeScript.
        
        Your background is a **massive differentiator** in the modern audit industry. All Big 4 firms are heavily investing in "Audit Transformation" and "Digital Audit".
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ¯ Target Roles")
            st.success("**1. Digital Audit Specialist**")
            st.markdown("Work at the intersection of Audit and Tech. Use Python/SQL to analyze full population data instead of sampling.")
            
            st.success("**2. AI Governance / Algorithm Assurance**")
            st.markdown("Audit AI models! With your GNN/Bayesian background, you can audit complex *algorithms* themselves, not just the financial numbers.")
            
            st.success("**3. Financial Advisory (FAS) - Forensics**")
            st.markdown("Your experience in 'Defect Localization' translates perfectly to **Fraud Detection** (finding anomalies in massive datasets).")

        with col2:
            st.markdown("### ğŸ’¡ Strategic Actions")
            st.info("**Resume / Entry Sheet (ES)**")
            st.markdown("*   **Highlight Research**: Explicitly mention your GNN work for Aerospace/CFRP. It shows you can handle *complex, unstructured data*.")
            st.markdown("*   **Keywords**: `PyTorch`, `Bayesian Inference`, `Uncertainty Quantification`, `End-to-End Pipelines`.")
            
            st.info("**Interview Questions to Ask**")
            st.markdown("*   *\"How can I apply Bayesian methods to audit risk assessment?\"*\n*   *\"Does your firm analyze unstructured data (like contracts/images) using GNNs or NLP?\"*")
            
            st.info("**Firm-Specific Tech Vibes**")
            st.markdown("""
            *   **EY**: Very strong brand in "Digital Audit". Has "EY Digital" specific recruiting tracks.
            *   **PwC**: Strong on "Tech-enablement". "Digital Upskilling" for all staff is a key slogan.
            *   **Deloitte**: "Audit Analytics" is a core part of their massive scale.
            *   **KPMG**: "Digital Innovation" focus, often collaborative with their consulting arm.
            """)

    with tab4:
        st.subheader("ğŸ‡ºğŸ‡¸ Boston Career Forum (BCF)")
        st.markdown("The world's largest job fair for Japanese-English bilinguals. **Crucial for Master's students.**")
        
        st.info("ğŸ’¡ **Why BCF for You?**\n*   **Speed**: Offers (Naitei) often given in 3 days (Fri-Sun).\n*   **Positions**: Big 4 hires for **Advisory/Consulting** heavily here, not just Audit.\n*   **Timing**: Held in November, aligning perfectly with post-essay exam period.")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ“… Timeline")
            st.markdown("""
            *   **Aug-Sep**: Registration & Resume Upload.
            *   **Sep-Oct**: Online Applications & Skype Interviews (Pre-event).
            *   **Nov (Event)**: Walk-ins (Risky) vs. Scheduled Interviews (Safe).
            """)
        with col2:
            st.markdown("### ğŸ¯ Strategy")
            st.markdown("""
            *   **Pre-Event is King**: Secure interviews *before* flying to Boston.
            *   **Target**: Big 4 (US & Japan offices), Consulting (MBB/Accenture), Tech.
            *   **Dinner Invitations**: If you do well, you get invited to dinner. This is effectively the final interview.
            """)
        st.link_button("BCF Official Site", "https://careerforum.net/en/event/bos/")

    with tab5:
        st.subheader("ğŸ“ Interview & Case Prep")
        
        with st.expander("ğŸ§  Case Interview (Advisory/Consulting Focus)", expanded=True):
            st.markdown("""
            **Relevance**: Essential for Advisory (FAS) and Consulting roles at BCF.
            
            **Common Types**:
            1.  **Market Sizing (Fermi)**: "How many diapers are sold in Japan annually?"
            2.  **Business Case**: "Should Starbucks open a store in this university?"
            
            **Frameworks**:
            *   **3C**: Customer, Competitor, Company.
            *   **4P**: Product, Price, Place, Promotion.
            *   **Profit Tree**: Profit = Revenue - Cost = (Price x Vol) - (Fixed + Variable).
            """)
        
        with st.expander("ğŸ—£ï¸ Behavioral Interview Questions", expanded=True):
            st.markdown("""
            *   **Self-Intro**: "I am a Double Degree Master's student at **Keio University** and **Leibniz University Hannover**, specializing in **Mechanical Engineering**. My research focuses on **Defect Localization using Graph Neural Networks (GNNs)**..."
            *   **Why CPA?**: "I want to apply my expertise in **Uncertainty Quantification (Bayesian Inference)** to financial risk assessment and audit quality."
            *   **Why Big 4?**: "Because you handle the world's most complex data. I want to build the 'Digital Audit' tools of the future."
            *   **Weakness**: "I tend to dive too deep into technical details (like MCMC parameters). I am training myself to explain concepts to non-experts."
            """)
            
        with st.expander("ğŸ“„ Entry Sheet (ES) Tips", expanded=True):
            st.markdown("""
            **The 'Gaku-chika' (Student Efforts)**:
            *   **Structure (STAR)**:
                *   **Situation**: "Researching ML models for..."
                *   **Task**: "Accuracy was low (60%)..."
                *   **Action**: "I implemented a new data augmentation technique..."
                *   **Result**: "Improved to 90%, published a paper."
            *   **Key**: Show *process* and *problem-solving*, not just results.
            """)

elif page == "Future ğŸš€":
    st.header("ğŸš€ 100-Year Life & Career Plan: The 'Founder' Trajectory")
    st.markdown("Your roadmap from **Master's Student** to **Tech CEO**. A comprehensive simulation of career, wealth, and life milestones.")

    tab1, tab2, tab3, tab4 = st.tabs(["â³ 100-Year Timeline", "ğŸ’° Wealth & Salary Sim", "ğŸ¦„ Entrepreneurship Blueprint", "ğŸ’ Life & Family"])

    with tab1:
        st.subheader("The Century Plan (Age 24 - 100)")
        
        timeline_events = [
            {"Age": 24, "Year": 2026, "Phase": "Foundation", "Event": "Master's (Germany/Japan) + CPA Study Start", "Status": "Current"},
            {"Age": 25, "Year": 2027, "Phase": "Foundation", "Event": "Pass CPA Exam (May/Aug) ğŸ†", "Status": "Goal"},
            {"Age": 26, "Year": 2028, "Phase": "Foundation", "Event": "Graduation & Join Big 4 (Digital Audit/FAS)", "Status": "Planned"},
            {"Age": 29, "Year": 2031, "Phase": "Growth", "Event": "Promoted to Senior Associate. Lead ML Projects.", "Status": "Planned"},
            {"Age": 30, "Year": 2032, "Phase": "Life", "Event": "Marriage ğŸ’ (Target)", "Status": "Life"},
            {"Age": 32, "Year": 2034, "Phase": "Growth", "Event": "Manager Promotion. Deep expertise in AI Governance.", "Status": "Planned"},
            {"Age": 35, "Year": 2037, "Phase": "Launch", "Event": "ğŸš€ FOUND YOUR COMPANY (AI Audit SaaS). Seed Round.", "Status": "Dream"},
            {"Age": 40, "Year": 2042, "Phase": "Scale", "Event": "Series B Funding. Expansion to US/EU Markets.", "Status": "Dream"},
            {"Age": 45, "Year": 2047, "Phase": "Exit", "Event": "IPO or Strategic Acquisition. Financial Freedom.", "Status": "Dream"},
            {"Age": 50, "Year": 2052, "Phase": "Invest", "Event": "Angel Investor for Deep Tech. University Lecturer.", "Status": "Vision"},
            {"Age": 60, "Year": 2062, "Phase": "Legacy", "Event": "Establish Scholarship Foundation.", "Status": "Vision"},
            {"Age": 80, "Year": 2082, "Phase": "Wisdom", "Event": "Write Memoirs. Mentor next gen.", "Status": "Vision"},
            {"Age": 100, "Year": 2102, "Phase": "Complete", "Event": "Die Empty. No regrets.", "Status": "Final"}
        ]
        
        df_timeline = pd.DataFrame(timeline_events)
        st.dataframe(df_timeline, use_container_width=True)
        
        # Visual Timeline
        fig_timeline = px.scatter(df_timeline, x="Year", y="Age", color="Phase", text="Event", title="Life Trajectory", size_max=60)
        fig_timeline.update_traces(textposition='top center')
        fig_timeline.update_layout(height=500)
        st.plotly_chart(fig_timeline, use_container_width=True)

    with tab2:
        st.subheader("ğŸ’° Financial Simulation: Salary & Asset Growth")
        st.info("Simulating the 'J-Curve' effect of Entrepreneurship vs. Linear Corporate Growth.")
        
        # Simulation Data
        years = list(range(2026, 2060))
        ages = list(range(24, 58))
        
        # Salary Logic
        salary_corp = []
        assets_corp = []
        current_asset = 100  # Initial 1M JPY
        
        for age in ages:
            if age < 26: sal = 0  # Student
            elif age < 30: sal = 600  # Junior
            elif age < 35: sal = 1000 # Manager
            elif age < 40: sal = 1500 # Senior Manager
            else: sal = 2000 # Partner level
            salary_corp.append(sal)
            current_asset += (sal * 0.3) # Save 30%
            current_asset *= 1.04 # 4% Investment return
            assets_corp.append(current_asset)

        # Founder Logic
        salary_founder = []
        assets_founder = []
        founder_asset = 100
        
        for age in ages:
            if age < 35: # Same as corp until 35
                sal = salary_corp[ages.index(age)]
                founder_asset = assets_corp[ages.index(age)]
            elif age == 35: # STARTUP LAUNCH
                sal = 400 # Drop salary to survive
                founder_asset -= 500 # Initial Investment
            elif age < 40: # Early Stage
                sal = 600
                founder_asset += (sal * 0.1) # Low saving
            elif age == 45: # EXIT EVENT
                sal = 5000
                founder_asset += 50000 # 500M JPY Exit
            else: # Investor
                sal = 0
                founder_asset *= 1.05 # 5% return on massive capital
            
            salary_founder.append(sal)
            assets_founder.append(founder_asset)

        # Plot
        df_sim = pd.DataFrame({
            "Year": years,
            "Age": ages,
            "Corp Asset (Safe Path)": assets_corp,
            "Founder Asset (Risk Path)": assets_founder
        })
        
        fig_sim = px.line(df_sim, x="Age", y=["Corp Asset (Safe Path)", "Founder Asset (Risk Path)"], 
                          title="Asset Accumulation Simulation (Unit: 10k JPY)", markers=True)
        st.plotly_chart(fig_sim, use_container_width=True)
        
        st.warning("âš ï¸ **The Founder Gap**: Notice the dip at age 35. That is the 'Valley of Death'. You need ~10M JPY liquidity before launching.")

    with tab3:
        st.subheader("ğŸ¦„ Entrepreneurship Blueprint: 'AuditTech'")
        st.markdown("""
        **Vision**: Automate the "boring" parts of audit using **LLMs & GNNs**, allowing CPAs to focus on high-level risk assessment.
        
        **Phase 1: The "Insider" (Age 26-34)**
        *   **Goal**: Become a domain expert. Understand *exactly* where the inefficiencies are in Big 4.
        *   **Action**: Volunteer for "Digital Transformation" projects inside the firm. Network with Partners.
        
        **Phase 2: The "Prototype" (Age 34-35)**
        *   **Goal**: Build MVP (Minimum Viable Product).
        *   **Tech**: Python, LangChain, Neo4j (Graph DB).
        *   **Team**: Find a Co-founder (Business/Sales focus) since you are Tech/Product.
        
        **Phase 3: The "Launch" (Age 35)**
        *   **Target**: Mid-tier audit firms (who can't afford internal dev teams).
        *   **Product**: "Auto-Vouching AI" or "Fraud Detection Copilot".
        """)

    with tab4:
        st.subheader("ğŸ’ Life, Family & Happiness")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Family Goals")
            st.write("*   **Age 30**: Marriage (Partner who understands the startup grind).")
            st.write("*   **Age 32**: First Child.")
            st.write("*   **Age 35**: Second Child (Coincides with Startup Launch - Tough!).")
            st.write("*   **Policy**: Weekends are for family. No work on Sundays.")
            
        with col2:
            st.markdown("### âœˆï¸ Experiences")
            st.write("*   **20s**: Backpacking Europe/Asia (Cheap travel).")
            st.write("*   **30s**: Family trips to Hawaii/Okinawa.")
            st.write("*   **40s**: World Cruise (Post-Exit).")
            st.write("*   **Hobbies**: Hiking, Coding, Wine Tasting.")


import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, date
import json
import os

# Set page config
st.set_page_config(page_title="CPA Perfect Platform 2027", layout="wide", page_icon="ğŸ“š")

# Data Persistence
DATA_FILE = "cpa_data.json"

def load_data():
    defaults = {"scores": [], "logs": [], "xp": 0, "level": 1, "badges": []}
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                # Merge defaults for backward compatibility
                for k, v in defaults.items():
                    if k not in data:
                        data[k] = v
                return data
            except:
                return defaults
    return defaults

def save_data(data):
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Initialize Session State
if 'data' not in st.session_state:
    st.session_state.data = load_data()

if 'quiz_state' not in st.session_state:
    st.session_state.quiz_state = {
        'active': False,
        'subject': None,
        'level': None,
        'q_index': 0,
        'score': 0,
        'show_feedback': False,
        'selected_option': None
    }

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4e8cff;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
    }
    .correct-answer {
        background-color: #d1fae5;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #10b981;
        color: #065f46;
    }
    .incorrect-answer {
        background-color: #fee2e2;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ef4444;
        color: #991b1b;
    }
</style>
""", unsafe_allow_html=True)

# Mock Data
mock_exams = [
    {'date': '2026-11-15', 'type': 'Short', 'name': 'Dec Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2026-12-13', 'type': 'Short', 'name': 'Official Dec Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-04-25', 'type': 'Short', 'name': 'May Short Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-05-23', 'type': 'Short', 'name': 'Official May Short Exam', 'provider': 'CPAAOB', 'status': 'Target'},
    {'date': '2027-07-10', 'type': 'Essay', 'name': 'Essay Mock (TAC/Ohara)', 'provider': 'TAC/Ohara', 'status': 'Practice'},
    {'date': '2027-08-20', 'type': 'Essay', 'name': 'Official Aug Essay Exam', 'provider': 'CPAAOB', 'status': 'Target'}
]

# Vocabulary Data
def load_vocab_data():
    vocab_path = "assets/vocab.json"
    if os.path.exists(vocab_path):
        with open(vocab_path, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except:
                return {}
    return {}

vocab_data = load_vocab_data()

def load_formulas_data():
    p = os.path.join(os.path.dirname(os.path.abspath(__file__)), "assets", "formulas.json")
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

formulas_data = load_formulas_data()

drill_questions = {
    'Financial': [
        {
            'level': 1,
            'q': "ç¾é‡‘é é‡‘: è²¸å€Ÿå¯¾ç…§è¡¨ã®ã€Œç¾é‡‘ã€ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç´™å¹£ (Bank notes)", "ç¡¬è²¨ (Coins)", "éƒµä¾¿åˆ‡æ‰‹ (Postage stamps)", "å½“åº§é é‡‘ (Demand deposits)"],
            'correct': 2,
            'explanation': "éƒµä¾¿åˆ‡æ‰‹ã¯ã€Œè²¯è”µå“ã€ã¾ãŸã¯ã€Œé€šä¿¡è²»ã€ã¨ã—ã¦å‡¦ç†ã•ã‚Œã€ç¾é‡‘ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚ç¾é‡‘ã«ã¯é€šè²¨ã€å°åˆ‡æ‰‹ã€å½“åº§é é‡‘ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›ä¾¡å„Ÿå´: è³‡ç”£ã®åˆ©ç”¨é‡ã«åŸºã¥ã„ã¦æ¸›ä¾¡å„Ÿå´è²»ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å®šé¡æ³• (Straight-line)", "å®šç‡æ³• (Declining-balance)", "ç”Ÿç”£é«˜æ¯”ä¾‹æ³• (Production-output)", "ç´šæ•°æ³• (Sum-of-the-years'-digits)"],
            'correct': 2,
            'explanation': "ç”Ÿç”£é«˜æ¯”ä¾‹æ³•ã¯ã€ç·è¦‹ç©ç”Ÿç”£é‡ã«å¯¾ã™ã‚‹å½“æœŸã®å®Ÿéš›ç”Ÿç”£é‡ã®å‰²åˆã«åŸºã¥ã„ã¦è²»ç”¨ã‚’é…åˆ†ã™ã‚‹æ–¹æ³•ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ£šå¸è³‡ç”£: ç‰©ä¾¡ä¸Šæ˜‡å±€é¢ã«ãŠã„ã¦ã€å½“æœŸç´”åˆ©ç›ŠãŒæœ€ã‚‚å¤§ãããªã‚‹è©•ä¾¡æ–¹æ³•ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å…ˆå…¥å…ˆå‡ºæ³• (FIFO)", "å¾Œå…¥å…ˆå‡ºæ³• (LIFO)", "ç§»å‹•å¹³å‡æ³• (Weighted Average)", "å€‹åˆ¥æ³• (Specific Identification)"],
            'correct': 0,
            'explanation': "å…ˆå…¥å…ˆå‡ºæ³•(FIFO)ã§ã¯ã€éå»ã®ï¼ˆå®‰ã„ï¼‰åœ¨åº«ãŒå…ˆã«å£²ä¸ŠåŸä¾¡ã¨ãªã‚Šã€æœŸæœ«åœ¨åº«ã«ç›´è¿‘ã®ï¼ˆé«˜ã„ï¼‰å˜ä¾¡ãŒæ®‹ã‚‹ãŸã‚ã€å£²ä¸ŠåŸä¾¡ãŒå°ã•ããªã‚Šåˆ©ç›ŠãŒå¤§ãããªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è³‡ç”£é™¤å»å‚µå‹™: è³‡ç”£é™¤å»å‚µå‹™ã¯å½“åˆä½•ã‚’ã‚‚ã£ã¦æ¸¬å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["é™¤å»è²»ç”¨ã®å°†æ¥ä¾¡å€¤", "é™¤å»è²»ç”¨ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤", "è³‡ç”£ã®å–å¾—åŸä¾¡", "è³‡ç”£ã®å…¬æ­£ä¾¡å€¤"],
            'correct': 1,
            'explanation': "è³‡ç”£é™¤å»å‚µå‹™ã¯ã€å°†æ¥ç™ºç”Ÿã™ã‚‹ã¨è¦‹è¾¼ã¾ã‚Œã‚‹é™¤å»è²»ç”¨ã®ã€Œå‰²å¼•ç¾åœ¨ä¾¡å€¤ã€ã§ç®—å®šã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸€èˆ¬åŸå‰‡: ä¼æ¥­ä¼šè¨ˆåŸå‰‡ã®ã€ŒçœŸå®Ÿæ€§ã®åŸå‰‡ã€ã«ãŠã‘ã‚‹ã€ŒçœŸå®Ÿã€ã®æ„å‘³ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµ¶å¯¾çš„çœŸå®Ÿ", "ç›¸å¯¾çš„çœŸå®Ÿ", "å½¢å¼çš„çœŸå®Ÿ", "æ³•çš„çœŸå®Ÿ"],
            'correct': 1,
            'explanation': "ä¼æ¥­ä¼šè¨ˆã¯è¤‡æ•°ã®ä¼šè¨ˆå‡¦ç†ã®åŸå‰‡ãƒ»æ‰‹ç¶šã®é¸æŠé©ç”¨ã‚’èªã‚ã¦ã„ã‚‹ãŸã‚ã€æ±‚ã‚ã‚‰ã‚Œã‚‹ã®ã¯ã€Œç›¸å¯¾çš„çœŸå®Ÿã€ã§ã‚ã‚‹ã¨è§£ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ¸›æä¼šè¨ˆ: å›ºå®šè³‡ç”£ã®ã€Œå›åå¯èƒ½ä¾¡é¡ã€ã¨ã¯ã€ã©ã®ã‚ˆã†ã«ç®—å®šã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹é«˜ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã¨ä½¿ç”¨ä¾¡å€¤ã®ã„ãšã‚Œã‹ä½ã„é‡‘é¡", "æ­£å‘³å£²å´ä¾¡é¡ã®ã¿", "ä½¿ç”¨ä¾¡å€¤ã®ã¿"],
            'correct': 0,
            'explanation': "å›åå¯èƒ½ä¾¡é¡ã¯ã€è³‡ç”£ã®ã€Œæ­£å‘³å£²å´ä¾¡é¡ã€ã¨ã€Œä½¿ç”¨ä¾¡å€¤ã€ã®ã„ãšã‚Œã‹é«˜ã„æ–¹ã®é‡‘é¡ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ãƒªãƒ¼ã‚¹ä¼šè¨ˆ: ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹å–å¼•ã«ãŠã„ã¦ã€å€Ÿæ‰‹ãŒè¨ˆä¸Šã™ã‚‹è³‡ç”£ã®é¡ã¯åŸå‰‡ã¨ã—ã¦ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["ãƒªãƒ¼ã‚¹æ–™ç·é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤ã¨è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ç­‰ã®ã„ãšã‚Œã‹ä½ã„é¡", "è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡", "ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤"],
            'correct': 1,
            'explanation': "é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒ»ãƒªãƒ¼ã‚¹ã§ã¯ã€ãƒªãƒ¼ã‚¹æ–™ç·é¡ã®ç¾åœ¨ä¾¡å€¤ã¨ã€è²¸æ‰‹ã®è³¼å…¥ä¾¡é¡ï¼ˆç¾é‡‘è³¼å…¥ä¾¡é¡ï¼‰ã®ã„ãšã‚Œã‹ä½ã„é¡ã§è³‡ç”£è¨ˆä¸Šã—ã¾ã™ã€‚"
        },
        {
            'level': 2,
            'q': "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸: é–“æ¥æ³•ã«ãŠã„ã¦ã€ç¨å¼•å‰å½“æœŸç´”åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹éš›ã€æ¸›ä¾¡å„Ÿå´è²»ã¯ã©ã†èª¿æ•´ã—ã¾ã™ã‹ï¼Ÿ",
            'options': ["åŠ ç®—ã™ã‚‹", "æ¸›ç®—ã™ã‚‹", "èª¿æ•´ã—ãªã„", "å–¶æ¥­å¤–åç›Šã¨ã—ã¦æ‰±ã†"],
            'correct': 0,
            'explanation': "æ¸›ä¾¡å„Ÿå´è²»ã¯ç¾é‡‘æ”¯å‡ºã‚’ä¼´ã‚ãªã„è²»ç”¨ï¼ˆéè³‡é‡‘æç›Šï¼‰ã§ã‚ã‚‹ãŸã‚ã€åˆ©ç›Šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‚’æ±‚ã‚ã‚‹éš›ã¯ã€ŒåŠ ç®—ã€ã—ã¦æˆ»ã—ã¾ã™ã€‚"
        },
        {
            'level': 3,
            'q': "ç¨åŠ¹æœä¼šè¨ˆ: ç¹°å»¶ç¨é‡‘è³‡ç”£ã®å›åå¯èƒ½æ€§ã‚’åˆ¤æ–­ã™ã‚‹éš›ã€ä¼šç¤¾åˆ†é¡ãŒã€Œåˆ†é¡2ã€ã®ä¼æ¥­ã«ãŠã„ã¦ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªä¸€æ™‚å·®ç•°ã¯ã„ã¤ã¾ã§è¨ˆä¸Šå¯èƒ½ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´ä»¥å†…", "5å¹´ä»¥å†…", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå…¨æœŸé–“", "è¨ˆä¸Šã§ããªã„"],
            'correct': 2,
            'explanation': "ã€Œåˆ†é¡2ï¼ˆæ¥­ç¸¾ãŒå®‰å®šã—ã¦ã„ã‚‹ä¼æ¥­ï¼‰ã€ã®å ´åˆã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½ãªå°†æ¥æ¸›ç®—ä¸€æ™‚å·®ç•°ã«ã¤ã„ã¦ã¯ã€æœŸé–“åˆ¶é™ãªãï¼ˆå…¨æœŸé–“ï¼‰å›åå¯èƒ½æ€§ãŒã‚ã‚‹ã¨åˆ¤æ–­ã•ã‚Œã¾ã™ã€‚"
        }
    ],
    'Management': [
        {
            'level': 1,
            'q': "CVPåˆ†æ: æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡", "å›ºå®šè²» Ã· å¤‰å‹•è²»ç‡", "å¤‰å‹•è²» Ã· å£²ä¸Šé«˜", "åˆ©ç›Š Ã· å£²ä¸Šé«˜"],
            'correct': 0,
            'explanation': "æç›Šåˆ†å²ç‚¹å£²ä¸Šé«˜ ï¼ å›ºå®šè²» Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ å›ºå®šè²» Ã· è²¢çŒ®åˆ©ç›Šç‡ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡ã®åˆ†é¡: ã€Œç´ ä¾¡ (Prime Cost)ã€ã‚’æ§‹æˆã™ã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç›´æ¥ææ–™è²» ï¼‹ ç›´æ¥åŠ´å‹™è²»", "ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»", "ç›´æ¥ææ–™è²» ï¼‹ è£½é€ é–“æ¥è²»", "è²©å£²è²»åŠã³ä¸€èˆ¬ç®¡ç†è²»"],
            'correct': 0,
            'explanation': "ç´ ä¾¡ï¼ˆPrime Costï¼‰ã¯ã€ç›´æ¥ææ–™è²»ã¨ç›´æ¥åŠ´å‹™è²»ã®åˆè¨ˆã§ã™ã€‚ï¼ˆåŠ å·¥è²» ï¼ ç›´æ¥åŠ´å‹™è²» ï¼‹ è£½é€ é–“æ¥è²»ï¼‰"
        },
        {
            'level': 1,
            'q': "æ¨™æº–åŸä¾¡è¨ˆç®—: å®Ÿéš›æ¶ˆè²»é‡ãŒæ¨™æº–æ¶ˆè²»é‡ã‚’ä¸Šå›ã£ãŸå ´åˆã«ç™ºç”Ÿã™ã‚‹å·®ç•°ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æœ‰åˆ©æ•°é‡å·®ç•°", "ä¸åˆ©æ•°é‡å·®ç•°", "æœ‰åˆ©ä¾¡æ ¼å·®ç•°", "ä¸åˆ©ä¾¡æ ¼å·®ç•°"],
            'correct': 1,
            'explanation': "æ¨™æº–ã‚ˆã‚Šã‚‚å¤šãã®æ•°é‡ã‚’æ¶ˆè²»ã—ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ã‚³ã‚¹ãƒˆå¢—ã¨ãªã‚‹ãŸã‚ã€Œä¸åˆ©å·®ç•°ï¼ˆUnfavorableï¼‰ã€ã¨ãªã‚Šã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›´æ¥åŸä¾¡è¨ˆç®—: å›ºå®šè£½é€ é–“æ¥è²»ã¯ã©ã®ã‚ˆã†ã«å‡¦ç†ã•ã‚Œã¾ã™ã‹ï¼Ÿ",
            'options': ["è£½å“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "æœŸé–“åŸä¾¡ã¨ã—ã¦å‡¦ç†", "è³‡ç”£ã¨ã—ã¦è¨ˆä¸Š", "è² å‚µã¨ã—ã¦è¨ˆä¸Š"],
            'correct': 1,
            'explanation': "ç›´æ¥åŸä¾¡è¨ˆç®—ã§ã¯ã€å›ºå®šè£½é€ é–“æ¥è²»ã¯ç™ºç”Ÿæ™‚ã«ã€ŒæœŸé–“åŸä¾¡ã€ã¨ã—ã¦å…¨é¡è²»ç”¨å‡¦ç†ã•ã‚Œã¾ã™ï¼ˆCVPåˆ†æã«æœ‰ç”¨ï¼‰ã€‚"
        },
        {
            'level': 1,
            'q': "åŸä¾¡è¨ˆç®—åŸºæº–: åŸä¾¡è¨ˆç®—åŸºæº–ã«ãŠã„ã¦ã€åŸä¾¡è¨ˆç®—ã®ç›®çš„ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è²¡å‹™è«¸è¡¨ã®ä½œæˆ", "åŸä¾¡ç®¡ç†", "äºˆç®—çµ±åˆ¶", "å¾“æ¥­å“¡çµ¦ä¸ã®è¨ˆç®—"],
            'correct': 3,
            'explanation': "åŸä¾¡è¨ˆç®—åŸºæº–ã«ã¯ã€è²¡å‹™è«¸è¡¨ä½œæˆã€ä¾¡æ ¼è¨ˆç®—ã€åŸä¾¡ç®¡ç†ã€äºˆç®—ç®¡ç†ã€åŸºæœ¬è¨ˆç”»ç­–å®šã®5ã¤ã®ç›®çš„ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€çµ¦ä¸è¨ˆç®—ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "ABC (æ´»å‹•åŸºæº–åŸä¾¡è¨ˆç®—): è£½é€ é–“æ¥è²»ã‚’è£½å“ã«é…è³¦ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹åŸºæº–ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            'options': ["æ“æ¥­åº¦", "ã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ (æ´»å‹•åŸä¾¡è¦å› )", "ç›´æ¥ä½œæ¥­æ™‚é–“", "æ©Ÿæ¢°ç¨¼åƒæ™‚é–“"],
            'correct': 1,
            'explanation': "ABCã§ã¯ã€è£½é€ é–“æ¥è²»ã‚’æ´»å‹•ã”ã¨ã«æŠŠæ¡ã—ã€ãã‚Œãã‚Œã®æ´»å‹•ã®ç™ºç”Ÿè¦å› ã§ã‚ã‚‹ã€Œã‚³ã‚¹ãƒˆãƒ»ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã€ã«åŸºã¥ã„ã¦è£½å“ã«é…è³¦ã—ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æŠ•è³‡ã®çµŒæ¸ˆæ€§è¨ˆç®—: ROI (æŠ•ä¸‹è³‡æœ¬åˆ©ç›Šç‡) ã‚’æ±‚ã‚ã‚‹è¨ˆç®—å¼ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["åˆ©ç›Š Ã· å£²ä¸Šé«˜", "å£²ä¸Šé«˜ Ã· æŠ•ä¸‹è³‡æœ¬", "åˆ©ç›Š Ã· æŠ•ä¸‹è³‡æœ¬", "æŠ•ä¸‹è³‡æœ¬ Ã· åˆ©ç›Š"],
            'correct': 2,
            'explanation': "ROI (Return On Investment) ã¯ã€åˆ©ç›Šã‚’æŠ•ä¸‹è³‡æœ¬ã§å‰²ã£ã¦ç®—å‡ºã—ã¾ã™ï¼ˆROI = å£²ä¸Šé«˜åˆ©ç›Šç‡ Ã— è³‡æœ¬å›è»¢ç‡ï¼‰ã€‚"
        },
        {
            'level': 2,
            'q': "CVPåˆ†æ: å›ºå®šè²»1,000ã€å¤‰å‹•è²»ç‡0.6ã€ç›®æ¨™åˆ©ç›Š200ã®å ´åˆã€ç›®æ¨™å£²ä¸Šé«˜ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["2,000", "3,000", "2,500", "1,200"],
            'correct': 1,
            'explanation': "ç›®æ¨™å£²ä¸Šé«˜ ï¼ (å›ºå®šè²» ï¼‹ ç›®æ¨™åˆ©ç›Š) Ã· (1 ï¼ å¤‰å‹•è²»ç‡) ï¼ (1000 + 200) Ã· 0.4 ï¼ 3000 ã§ã™ã€‚"
        }
    ],
    'Audit': [
        {
            'level': 1,
            'q': "ç›£æŸ»ãƒªã‚¹ã‚¯: ç›£æŸ»ãƒªã‚¹ã‚¯ãƒ»ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆè¦ç´ ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å›ºæœ‰ãƒªã‚¹ã‚¯ Ã— çµ±åˆ¶ãƒªã‚¹ã‚¯ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯", "ãƒ“ã‚¸ãƒã‚¹ãƒªã‚¹ã‚¯ Ã— ç›£æŸ»ãƒªã‚¹ã‚¯", "é‡è¦æ€§ Ã— ãƒªã‚¹ã‚¯", "æŠ½å‡ºãƒªã‚¹ã‚¯ Ã— éæŠ½å‡ºãƒªã‚¹ã‚¯"],
            'correct': 0,
            'explanation': "ç›£æŸ»ãƒªã‚¹ã‚¯ ï¼ é‡è¦ãªè™šå½è¡¨ç¤ºãƒªã‚¹ã‚¯ï¼ˆå›ºæœ‰ãƒªã‚¹ã‚¯Ã—çµ±åˆ¶ãƒªã‚¹ã‚¯ï¼‰ Ã— ç™ºè¦‹ãƒªã‚¹ã‚¯ ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç‹¬ç«‹æ€§: ã€Œå¤–è¦³çš„ç‹¬ç«‹æ€§ã€ã‚’æãªã†è¦å› ã¨ãªã‚‹ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ä¿æœ‰", "èª å®Ÿã§ã‚ã‚‹ã“ã¨", "å°‚é–€èƒ½åŠ›ã‚’æœ‰ã™ã‚‹ã“ã¨", "å€«ç†è¦å®šã®éµå®ˆ"],
            'correct': 0,
            'explanation': "è¢«ç›£æŸ»ä¼šç¤¾ã®æ ªå¼ã‚„é‡è¦ãªçµŒæ¸ˆçš„åˆ©å®³é–¢ä¿‚ã‚’æœ‰ã™ã‚‹ã“ã¨ã¯ã€å¤–è¦³çš„ç‹¬ç«‹æ€§ï¼ˆç¬¬ä¸‰è€…ã‹ã‚‰è¦‹ã¦ç‹¬ç«‹ã—ã¦ã„ã‚‹ã¨è¦‹ãˆã‚‹ã“ã¨ï¼‰ã‚’æãªã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»æ„è¦‹: è²¡å‹™è«¸è¡¨å…¨ä½“ã«é‡è¦ãªè™šå½è¡¨ç¤ºãŒã‚ã‚Šã€ã‹ã¤ãã®å½±éŸ¿ãŒåºƒç¯„ã§ã‚ã‚‹å ´åˆã«è¡¨æ˜ã•ã‚Œã‚‹æ„è¦‹ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["ç„¡é™å®šé©æ­£æ„è¦‹", "é™å®šä»˜é©æ­£æ„è¦‹", "ä¸é©æ­£æ„è¦‹", "æ„è¦‹ä¸è¡¨æ˜"],
            'correct': 2,
            'explanation': "é‡è¦ã‹ã¤åºƒç¯„ï¼ˆPervasiveï¼‰ãªè™šå½è¡¨ç¤ºãŒã‚ã‚‹å ´åˆã¯ã€ã€Œä¸é©æ­£æ„è¦‹ï¼ˆAdverse Opinionï¼‰ã€ãŒè¡¨æ˜ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "å†…éƒ¨çµ±åˆ¶: å†…éƒ¨çµ±åˆ¶ã®æ•´å‚™ãƒ»é‹ç”¨è²¬ä»»ã¯èª°ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            'options': ["ç›£æŸ»äºº", "çµŒå–¶è€…", "æ ªä¸»", "æ”¿åºœ"],
            'correct': 1,
            'explanation': "å†…éƒ¨çµ±åˆ¶ã‚’æ•´å‚™ã—é‹ç”¨ã™ã‚‹è²¬ä»»ã¯ã€ŒçµŒå–¶è€…ã€ã«ã‚ã‚Šã¾ã™ã€‚ç›£æŸ»äººã¯ãã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡ãƒ»å ±å‘Šã™ã‚‹ç«‹å ´ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»è¨¼æ‹ : ä¸€èˆ¬çš„ã«æœ€ã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã‚‹ç›£æŸ»è¨¼æ‹ ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["çµŒå–¶è€…ã¸ã®è³ªå•", "è¦³å¯Ÿ", "å¤–éƒ¨ç¢ºèª", "ç¤¾å†…æ–‡æ›¸"],
            'correct': 2,
            'explanation': "å¤–éƒ¨ã®ç¬¬ä¸‰è€…ã‹ã‚‰ç›´æ¥å…¥æ‰‹ã™ã‚‹ã€Œç¢ºèªï¼ˆExternal Confirmationï¼‰ã€ã¯ã€ä¸€èˆ¬ã«ç¤¾å†…è¨¼æ‹ ã‚ˆã‚Šã‚‚è¨¼æ˜åŠ›ãŒé«˜ã„ã¨ã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ä¸æ­£å¯¾å¿œ: ã€Œä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã€ã®3è¦ç´ ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["å‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼", "æ©Ÿä¼š", "å§¿å‹¢ãƒ»æ­£å½“åŒ–", "ç½°å‰‡"],
            'correct': 3,
            'explanation': "ä¸æ­£ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ³ã‚°ãƒ«ã¯ã€ã€Œå‹•æ©Ÿãƒ»ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã€ã€Œæ©Ÿä¼šã€ã€Œå§¿å‹¢ãƒ»æ­£å½“åŒ–ã€ã®3è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å ±å‘Šæ›¸: ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã„ã¤ã§ã‚ã‚‹ã¹ãã§ã™ã‹ï¼Ÿ",
            'options': ["æ±ºç®—æ—¥", "ç›£æŸ»äººãŒç›£æŸ»æ„è¦‹ã‚’å½¢æˆã™ã‚‹ã®ã«ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥", "æ ªä¸»ç·ä¼šé–‹å‚¬æ—¥", "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æå‡ºæ—¥"],
            'correct': 1,
            'explanation': "ç›£æŸ»å ±å‘Šæ›¸æ—¥ã¯ã€ç›£æŸ»äººãŒæ„è¦‹è¡¨æ˜ã®åŸºç¤ã¨ãªã‚‹ååˆ†ã‹ã¤é©åˆ‡ãªç›£æŸ»è¨¼æ‹ ã‚’å…¥æ‰‹ã—ãŸæ—¥ï¼ˆç›£æŸ»çµ‚äº†æ—¥ï¼‰ã¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        }
    ],
    'Company': [
        {
            'level': 1,
            'q': "è¨­ç«‹: æ ªå¼ä¼šç¤¾ã®è¨­ç«‹ã«ãŠã‘ã‚‹æœ€ä½è³‡æœ¬é‡‘ã®é¡ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
            'options': ["1,000ä¸‡å††", "300ä¸‡å††", "1å††", "0å††"],
            'correct': 2,
            'explanation': "ç¾åœ¨ã®ä¼šç¤¾æ³•ã§ã¯ã€æœ€ä½è³‡æœ¬é‡‘åˆ¶åº¦ã¯æ’¤å»ƒã•ã‚Œã¦ãŠã‚Šã€è³‡æœ¬é‡‘1å††ã‹ã‚‰è¨­ç«‹ãŒå¯èƒ½ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "è‡ªå·±æ ªå¼: æ ªå¼ä¼šç¤¾ã¯è‡ªå·±æ ªå¼ã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã‹ï¼Ÿ",
            'options': ["å®Œå…¨ã«ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹", "è²¡æºè¦åˆ¶ç­‰ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã‚‹", "è‡ªç”±ã«èªã‚ã‚‰ã‚Œã‚‹", "è§£æ•£æ™‚ã®ã¿èªã‚ã‚‰ã‚Œã‚‹"],
            'correct': 1,
            'explanation': "è‡ªå·±æ ªå¼ã®å–å¾—ã¯ã€åˆ†é…å¯èƒ½é¡ã®ç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚„æ ªä¸»ç·ä¼šæ±ºè­°ãªã©ã®è¦åˆ¶ã®ä¸‹ã§èªã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ©Ÿé–¢è¨­è¨ˆ: å–ç· å½¹ä¼šè¨­ç½®ä¼šç¤¾ã«ãŠã‘ã‚‹å–ç· å½¹ã®æœ€ä½äººæ•°ã¯ä½•äººã§ã™ã‹ï¼Ÿ",
            'options': ["1äºº", "2äºº", "3äºº", "5äºº"],
            'correct': 2,
            'explanation': "å–ç· å½¹ä¼šã‚’è¨­ç½®ã™ã‚‹å ´åˆã€å–ç· å½¹ã¯3äººä»¥ä¸Šå¿…è¦ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ç·ä¼š: ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ",
            'options': ["è­°æ±ºæ¨©ã®éåŠæ•°", "è­°æ±ºæ¨©ã®3åˆ†ã®1", "è­°æ±ºæ¨©ã®3åˆ†ã®2", "å…¨æ ªä¸»"],
            'correct': 0,
            'explanation': "ç‰¹åˆ¥æ±ºè­°ã®å®šè¶³æ•°ã¯åŸå‰‡ã¨ã—ã¦ã€Œè­°æ±ºæ¨©ã®éåŠæ•°ã€ã§ã™ï¼ˆå®šæ¬¾ã§3åˆ†ã®1ã¾ã§ç·©å’Œå¯ï¼‰ã€‚æ±ºè­°è¦ä»¶ã¯å‡ºå¸­æ ªä¸»ã®è­°æ±ºæ¨©ã®3åˆ†ã®2ä»¥ä¸Šã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "ç›£æŸ»å½¹: ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦ä½•å¹´ã§ã™ã‹ï¼Ÿ",
            'options': ["1å¹´", "2å¹´", "4å¹´", "10å¹´"],
            'correct': 2,
            'explanation': "ç›£æŸ»å½¹ã®ä»»æœŸã¯åŸå‰‡ã¨ã—ã¦4å¹´ã§ã™ã€‚å®šæ¬¾ã«ã‚ˆã£ã¦ã‚‚çŸ­ç¸®ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚"
        },
        {
            'level': 1,
            'q': "æ ªä¸»ã®æ¨©åˆ©: å˜ç‹¬æ ªä¸»æ¨©ï¼ˆ1æ ªã§ã‚‚ä¿æœ‰ã—ã¦ã„ã‚Œã°è¡Œä½¿ã§ãã‚‹æ¨©åˆ©ï¼‰ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["æ ªä¸»ç·ä¼šæ‹›é›†è«‹æ±‚æ¨©", "å¸³ç°¿é–²è¦§è«‹æ±‚æ¨©", "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©", "å–ç· å½¹è§£ä»»è«‹æ±‚æ¨©"],
            'correct': 2,
            'explanation': "å‰°ä½™é‡‘é…å½“è«‹æ±‚æ¨©ã‚„è­°æ±ºæ¨©ã¯ã€1æ ªã‹ã‚‰èªã‚ã‚‰ã‚Œã‚‹å˜ç‹¬æ ªä¸»æ¨©ã§ã™ã€‚å¸³ç°¿é–²è¦§æ¨©ãªã©ã¯ä¸€å®šã®æ ªå¼æ•°ãƒ»æœŸé–“ãŒå¿…è¦ãªå°‘æ•°æ ªä¸»æ¨©ã§ã™ã€‚"
        },
        {
            'level': 1,
            'q': "äº‹æ¥­è­²æ¸¡: æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã¨ãªã‚‹äº‹æ¥­è­²æ¸¡ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ",
            'options': ["äº‹æ¥­ã®å…¨éƒ¨ã¾ãŸã¯é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡", "é‡è¦ãªè³‡ç”£ã®å‡¦åˆ†", "å¤šé¡ã®å€Ÿè²¡", "æ”¯é…äººã®é¸ä»»"],
            'correct': 0,
            'explanation': "äº‹æ¥­ã®å…¨éƒ¨ã®è­²æ¸¡ã€ã¾ãŸã¯äº‹æ¥­ã®é‡è¦ãªä¸€éƒ¨ã®è­²æ¸¡ï¼ˆè­²æ¸¡è³‡ç”£ãŒç·è³‡ç”£ã®1/5è¶…ãªã©ï¼‰ã«ã¯ã€æ ªä¸»ç·ä¼šã®ç‰¹åˆ¥æ±ºè­°ãŒå¿…è¦ã§ã™ã€‚"
        }
    ]
}

# Load generated questions
json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
if os.path.exists(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            generated_questions = json.load(f)
            for subject, questions in generated_questions.items():
                if subject in drill_questions:
                    drill_questions[subject].extend(questions)
                else:
                    drill_questions[subject] = questions
    except Exception as e:
        st.error(f"Failed to load generated questions: {e}")

# Load Study Materials (Syllabus)
def load_study_materials():
    # Looking for 'studying' folder in 'platform' directory (moved inside)
    materials_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'studying')
    syllabus = {}
    extra_pdfs = []
    
    if not os.path.exists(materials_dir):
        return {}, []
        
    for filename in os.listdir(materials_dir):
        if filename.endswith('.xlsx') and not filename.startswith('~$'): # Ignore temp files
            try:
                # Extract subject from filename (e.g., "1-è²¡å‹™ä¼šè¨ˆè«–ã‚³ãƒ¼ã‚¹.xlsx" -> "è²¡å‹™ä¼šè¨ˆè«–")
                parts = filename.split('-')
                if len(parts) > 1:
                    subject_name = parts[1].replace('ã‚³ãƒ¼ã‚¹.xlsx', '')
                else:
                    subject_name = filename.replace('.xlsx', '')
                
                # Read Excel
                file_path = os.path.join(materials_dir, filename)
                df = pd.read_excel(file_path, header=1)
                
                # Fill merged cells (NaN) with previous value
                if 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚«ãƒ†ã‚´ãƒª'].ffill()
                if 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª' in df.columns:
                    df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'] = df['ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª'].ffill()
                
                # Filter relevant columns
                if 'è¬›åº§å' in df.columns:
                    items = []
                    for _, row in df.iterrows():
                        if pd.notna(row['è¬›åº§å']):
                            items.append({
                                'category': row.get('ã‚«ãƒ†ã‚´ãƒª', ''),
                                'subcategory': row.get('ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª', ''),
                                'title': row['è¬›åº§å'],
                                'duration': row.get('å†ç”Ÿæ™‚é–“/æ¨™æº–æ™‚é–“', '')
                            })
                    
                    # Find corresponding PDF
                    pdf_path = os.path.join(materials_dir, filename.replace('.xlsx', '.pdf'))
                    has_pdf = os.path.exists(pdf_path)
                    
                    syllabus[subject_name] = {
                        'items': items,
                        'pdf_path': pdf_path if has_pdf else None,
                        'excel_path': file_path
                    }
            except Exception as e:
                print(f"Error loading {filename}: {e}")
    
    # Load extra PDFs from 'PDF' subdirectory
    pdf_dir = os.path.join(materials_dir, 'PDF')
    if os.path.exists(pdf_dir):
        for f in os.listdir(pdf_dir):
            if f.lower().endswith('.pdf'):
                extra_pdfs.append({
                    'name': f,
                    'path': os.path.join(pdf_dir, f)
                })
                
    # Also load standalone PDFs in the root of 'studying' that are not paired with an Excel file
    # Get list of PDF paths already associated with courses
    paired_pdfs = set()
    for subject_data in syllabus.values():
        if subject_data['pdf_path']:
            paired_pdfs.add(os.path.normpath(subject_data['pdf_path']))
            
    for filename in os.listdir(materials_dir):
        if filename.lower().endswith('.pdf'):
            full_path = os.path.join(materials_dir, filename)
            if os.path.normpath(full_path) not in paired_pdfs:
                extra_pdfs.append({
                    'name': filename,
                    'path': full_path
                })
                
    return syllabus, extra_pdfs

study_materials, extra_pdfs = load_study_materials()

roadmap_md = """
# CPA 1.5 Year Strategy Roadmap

## Phase 0: Foundation (2026)
* **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics.
* **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
* **Jul - Sep**: **CRITICAL** Start Tax Law & Electives.
* **Oct - Dec**: **Dec Short Exam Challenge**. Aim to pass!

## Phase 1: Short Exam Mastery (Jan - May 2027)
* **Jan - Mar**: Solidify basics. 75%+ in drills.
* **Apr - May**: Peak conditioning. Rote memorization.

## Phase 2: Essay Sprint (Jun - Aug 2027)
* **Jun**: Revive Tax/Elective knowledge.
* **Jul**: Output training (Writing).
* **Aug**: Final adjustments.
"""

# Navigation
st.sidebar.title("CPA Platform 2027")

# User Profile in Sidebar
with st.sidebar.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        st.markdown("### ğŸ“")
    with col2:
        curr_level = st.session_state.data.get('level', 1)
        st.write(f"**Level {curr_level}**")
    
    curr_xp = st.session_state.data.get('xp', 0)
    next_level_xp = curr_level * 100
    progress = min(curr_xp / next_level_xp, 1.0)
    st.progress(progress)
    st.caption(f"XP: {curr_xp} / {next_level_xp}")

st.sidebar.markdown("---")

# Quick Links
st.sidebar.markdown("""
    <style>
    .big-rocket-button {
        display: inline-block;
        width: 100%;
        padding: 12px;
        background: linear-gradient(135deg, #FF4B4B 0%, #FF0000 100%);
        color: white !important;
        text-align: center;
        font-size: 18px;
        font-weight: 900;
        border-radius: 12px;
        text-decoration: none !important;
        box-shadow: 0 4px 15px rgba(255, 0, 0, 0.4);
        transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
        border: 2px solid rgba(255, 255, 255, 0.2);
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .big-rocket-button:hover {
        background: linear-gradient(135deg, #FF0000 0%, #D00000 100%);
        transform: translateY(-2px) scale(1.02);
        box-shadow: 0 6px 20px rgba(255, 0, 0, 0.6);
        border-color: rgba(255, 255, 255, 0.5);
    }
    .big-rocket-button:active {
        transform: translateY(1px);
        box-shadow: 0 2px 10px rgba(255, 0, 0, 0.3);
    }
    </style>
    <a href="https://member.studying.jp/top/" target="_blank" class="big-rocket-button">
        ğŸš€ STUDYING
    </a>
    """, unsafe_allow_html=True)

st.sidebar.markdown("---")
page = st.sidebar.radio("Navigation", ["Dashboard ğŸ“Š", "My Syllabus ğŸ“š", "Vocabulary ğŸ“–", "Formulas ğŸ“", "Old Exams ğŸ“„", "Study Timer â±ï¸", "Mock Exams ğŸ“", "Scores ğŸ“ˆ", "Drills ğŸ”§", "Survival Mode âš¡", "Roadmap ğŸ—ºï¸", "Big 4 Job Hunting ğŸ’¼", "Company Directory ğŸ¢", "Future ğŸš€"])

if page == "Dashboard ğŸ“Š":
    st.header("Dashboard ğŸš€")
    
    # --- Top Metrics Row ---
    st.subheader("ğŸ“Š At a Glance")
    today = date.today()
    
    # Calculate Metrics
    # 1. Study Time Today
    logs_df = pd.DataFrame(st.session_state.data.get("logs", []))
    minutes_today = 0
    if not logs_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_logs = logs_df[logs_df['date'] == today_str]
        minutes_today = today_logs['duration'].sum()
    
    # 2. Quizzes Today
    scores_df = pd.DataFrame(st.session_state.data.get("scores", []))
    quizzes_today = 0
    avg_score_today = 0
    if not scores_df.empty:
        today_str = today.strftime("%Y-%m-%d")
        today_scores = scores_df[scores_df['date'] == today_str]
        quizzes_today = len(today_scores)
        if quizzes_today > 0:
            avg_score_today = today_scores['val'].mean()

    # 3. Total XP
    total_xp = st.session_state.data.get('xp', 0)

    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Study Time (Today)", f"{minutes_today} min", delta=f"{minutes_today/60:.1f} hrs")
    m2.metric("Quizzes Completed", f"{quizzes_today}", delta=f"Avg: {avg_score_today:.0f}%" if quizzes_today > 0 else None)
    m3.metric("Total XP", f"{total_xp}", delta="Level Up Soon?" if total_xp % 100 > 80 else None)
    
    # 4. Nearest Deadline
    target_short = date(2026, 12, 13)
    days_short = (target_short - today).days
    m4.metric("Next Exam (Dec Short)", f"{days_short} Days", delta="-1 Day", delta_color="inverse")
    
    st.markdown("---")

    # --- Main Content Grid ---
    c_main_1, c_main_2 = st.columns([2, 1])
    
    with c_main_1:
        st.subheader("ğŸ—“ï¸ Exam Countdown")
        
        # Enhanced Countdown Cards
        cd1, cd2, cd3 = st.columns(3)
        
        with cd1:
            target = date(2026, 12, 13)
            diff = (target - today).days
            st.info(f"**Dec 2026 Short**\n\n# {max(0, diff)} Days\n\n*Target: 60%*")
            
        with cd2:
            target = date(2027, 5, 23)
            diff = (target - today).days
            st.warning(f"**May 2027 Short**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")
            
        with cd3:
            target = date(2027, 8, 20)
            diff = (target - today).days
            st.error(f"**Aug 2027 Essay**\n\n# {max(0, diff)} Days\n\n*Target: PASS*")

        # Weakness Analysis
        st.subheader("ğŸ§  Weak Areas Analysis")
        if not scores_df.empty:
            # Group by subject and calculate mean
            subject_perf = scores_df.groupby('subject')['val'].mean().sort_values()
            weakest_subject = subject_perf.index[0]
            weakest_score = subject_perf.iloc[0]
            
            st.markdown(f"""
            <div style="padding: 15px; border-radius: 10px; background-color: #fff3cd; border: 1px solid #ffeeba; color: #856404;">
                <h4>âš ï¸ Focus Area: {weakest_subject} ({weakest_score:.1f}%)</h4>
                <p>Your performance in <b>{weakest_subject}</b> is lower than other subjects. Consider doing a targeted drill.</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button(f"ğŸ”¥ Start {weakest_subject} Drill Now"):
                # Redirect logic (simulated by setting session state)
                # Note: Direct page switching in Streamlit is tricky without rerun, 
                # but we can set the quiz state to active for this subject
                # Ideally, user goes to Drills tab, but we can hint them.
                st.toast(f"Go to 'Drills' tab and select {weakest_subject}!", icon="ğŸ‘‰")
        else:
            st.info("Complete some drills to identify your weak areas.")

        # Recent Activity Chart (Last 7 Days)
        st.subheader("ğŸ“ˆ Study Consistency (Last 7 Days)")
        if not logs_df.empty:
            # Filter last 7 days
            logs_df['date'] = pd.to_datetime(logs_df['date']).dt.date
            last_7_days = [today - pd.Timedelta(days=i) for i in range(6, -1, -1)]
            
            daily_minutes = []
            for d in last_7_days:
                day_logs = logs_df[logs_df['date'] == d]
                daily_minutes.append(day_logs['duration'].sum())
            
            chart_data = pd.DataFrame({
                "Date": last_7_days,
                "Minutes": daily_minutes
            })
            
            fig_activity = px.bar(chart_data, x="Date", y="Minutes", title="Daily Study Time")
            st.plotly_chart(fig_activity, use_container_width=True)
        else:
            st.info("Log your study sessions to see your consistency chart.")


    with c_main_2:
        # Skill Radar
        st.subheader("Skills")
        subjects = ['Financial', 'Management', 'Audit', 'Company', 'Tax', 'Elective']
        radar_scores = [30] * 6 # Default
        
        if not scores_df.empty:
            avg_scores = []
            for sub in subjects:
                sub_df = scores_df[scores_df['subject'] == sub]
                if not sub_df.empty:
                    avg_scores.append(sub_df['val'].mean())
                else:
                    avg_scores.append(30) # Default baseline
            radar_scores = avg_scores
            
        fig = go.Figure(data=go.Scatterpolar(
            r=radar_scores,
            theta=subjects,
            fill='toself',
            name='Current Skill'
        ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])), 
            showlegend=False,
            margin=dict(l=20, r=20, t=20, b=20),
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Daily Tip Card
        st.subheader("ğŸ’¡ Daily Tip")
        tips = [
            "Consistency is key. 30 minutes every day is better than 5 hours once a week.",
            "Focus on 'why', not just 'how'. Understanding the logic helps in applied questions.",
            "Don't ignore the theory. It's 40-50% of the exam.",
            "Review your mistakes. The 'incorrect' options are learning opportunities.",
            "Sleep is part of studying. Memory consolidation happens during sleep.",
            "Use the 'Survival Mode' to build speed and accuracy under pressure!",
            "Audit isn't just memorization; imagine you are the auditor in that situation."
        ]
        import random
        st.info(random.choice(tips))
        
        # Progress
        st.subheader("Phase 0 Progress")
        st.progress(15)
        st.caption("Goal: Foundation Mastery")

elif page == "My Syllabus ğŸ“š":
    st.header("My Study Syllabus ğŸ“š")
    st.info("Based on your uploaded materials in 'studying' folder.")
    
    if not study_materials and not extra_pdfs:
        st.warning("No study materials found in 'studying' folder.")
    else:
        # Progress Tracking
        if 'syllabus_progress' not in st.session_state.data:
            st.session_state.data['syllabus_progress'] = []
            
        completed_items = set(st.session_state.data['syllabus_progress'])
        
        # Callback for checkbox
        def toggle_syllabus(key):
            if key in st.session_state.data['syllabus_progress']:
                st.session_state.data['syllabus_progress'].remove(key)
            else:
                st.session_state.data['syllabus_progress'].append(key)
                # Add XP for completing a lecture!
                st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + 50
                st.toast("Lecture Completed! +50 XP", icon="ğŸ“")
            save_data(st.session_state.data)

        # Tabs for subjects
        if study_materials:
            subjects = list(study_materials.keys())
            tabs = st.tabs(subjects)
            
            for i, subject in enumerate(subjects):
                with tabs[i]:
                    data = study_materials[subject]
                    items = data['items']
                    pdf_path = data['pdf_path']
                    excel_path = data['excel_path']
                    
                    # Header Actions
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        st.subheader(f"{subject} ({len(items)} Lectures)")
                    with c2:
                        if pdf_path:
                            if st.button(f"ğŸ“„ Open PDF", key=f"pdf_{subject}"):
                                try:
                                    os.startfile(pdf_path)
                                    st.toast(f"Opening {subject} PDF...", icon="ğŸš€")
                                except Exception as e:
                                    st.error(f"Cannot open PDF: {e}")
                        
                        if st.button(f"ğŸ“Š Open Excel", key=f"excel_{subject}"):
                            try:
                                os.startfile(excel_path)
                                st.toast(f"Opening {subject} Excel...", icon="ğŸ“Š")
                            except Exception as e:
                                st.error(f"Cannot open Excel: {e}")

                    
                    # Progress Bar for Subject
                    subject_completed = [item['title'] for item in items if f"{subject}|{item['title']}" in completed_items]
                    prog = len(subject_completed) / len(items) if items else 0
                    st.progress(prog)
                    st.caption(f"Progress: {len(subject_completed)} / {len(items)} ({prog:.1%})")
                    
                    # Group by Category/Subcategory
                    df = pd.DataFrame(items)
                    if not df.empty and 'category' in df.columns:
                        for cat, group in df.groupby('category'):
                            with st.expander(f"ğŸ“‚ {cat}", expanded=True):
                                for idx, row in group.iterrows():
                                    title = row['title']
                                    unique_key = f"{subject}|{title}"
                                    is_done = unique_key in completed_items
                                    
                                    c_chk, c_txt, c_time = st.columns([0.5, 4, 1.5])
                                    with c_chk:
                                        # Use subject and index to ensure widget key uniqueness
                                        st.checkbox("", value=is_done, key=f"chk_{subject}_{idx}", on_change=toggle_syllabus, kwargs={'key': unique_key})
                                    
                                    with c_txt:
                                        if is_done:
                                            st.markdown(f"~~{title}~~")
                                        else:
                                            st.markdown(f"**{title}**")
                                            if row['subcategory']:
                                                st.caption(f"â”” {row['subcategory']}")
                                                
                                    with c_time:
                                        st.caption(f"â±ï¸ {row['duration']}")

        # Supplemental Resources (Extra PDFs)
        if extra_pdfs:
            st.markdown("---")
            st.subheader("ğŸ“š Supplemental Resources")
            for i, pdf in enumerate(extra_pdfs):
                c1, c2 = st.columns([4, 1])
                with c1:
                    st.markdown(f"ğŸ“„ **{pdf['name']}**")
                with c2:
                    if st.button("Open", key=f"extra_pdf_{i}_{pdf['name']}"):
                        try:
                            os.startfile(pdf['path'])
                            st.toast(f"Opening {pdf['name']}...", icon="ğŸš€")
                        except Exception as e:
                            st.error(f"Cannot open PDF: {e}")

elif page == "Vocabulary ğŸ“–":
    st.header("Vocabulary Mastery ğŸ“–")
    st.info("Master the essential accounting terminology in Japanese and English.")

    # Create Tabs
    tab1, tab2 = st.tabs(["ğŸ“š Word List", "âš¡ Tap & Study (Flashcards)"])

    # --- TAB 1: Word List ---
    with tab1:
        st.subheader("Bilingual Terminology List")
        
        # Subject Selection
        subjects = list(vocab_data.keys())
        selected_subject = st.selectbox("Select Subject", subjects, key="vocab_list_subject")
        
        if selected_subject:
            terms = vocab_data[selected_subject]
            st.write(f"Found {len(terms)} terms for **{selected_subject}**.")
            
            for term in terms:
                with st.expander(f"**{term['term']}** ({term['jp']})"):
                    st.markdown(f"**ğŸ‡¯ğŸ‡µ Definition:** {term['desc']}")
                    st.markdown(f"**ğŸ‡ºğŸ‡¸ Definition:** {term.get('desc_en', 'No English definition available.')}")

    # --- TAB 2: Flashcards ---
    with tab2:
        st.subheader("âš¡ Flashcard Mode")
        st.markdown("Tap to flip the card, swipe (click next) to move to the next word.")
        
        # Initialize Session State for Flashcards
        if 'flashcard_active' not in st.session_state:
            st.session_state.flashcard_active = False
            st.session_state.flashcard_subject = subjects[0]
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False

        # Subject Selection for Flashcards
        fc_subject = st.selectbox("Select Subject for Study", subjects, key="fc_subject_selector")
        
        # Start/Reset Button
        if st.button("Start / Restart Session", type="primary"):
            st.session_state.flashcard_active = True
            st.session_state.flashcard_subject = fc_subject
            st.session_state.flashcard_index = 0
            st.session_state.flashcard_flipped = False
            st.rerun()

        if st.session_state.flashcard_active:
            current_terms = vocab_data.get(st.session_state.flashcard_subject, [])
            total_cards = len(current_terms)
            
            if total_cards == 0:
                st.warning("No words available for this subject.")
            else:
                current_idx = st.session_state.flashcard_index
                
                # Check if session is finished
                if current_idx >= total_cards:
                    st.balloons()
                    st.success(f"ğŸ‰ You've completed all {total_cards} words for {st.session_state.flashcard_subject}!")
                    if st.button("Start Over"):
                        st.session_state.flashcard_index = 0
                        st.session_state.flashcard_flipped = False
                        st.rerun()
                else:
                    word_data = current_terms[current_idx]
                    
                    # Progress Bar
                    progress = (current_idx + 1) / total_cards
                    st.progress(progress)
                    st.caption(f"Card {current_idx + 1} of {total_cards}")

                    # Card Container
                    card_container = st.container()
                    
                    # Card Logic
                    with card_container:
                        # Styling
                        st.markdown("""
                        <style>
                        .flashcard {
                            border: 2px solid #e0e0e0;
                            border-radius: 15px;
                            padding: 40px;
                            text-align: center;
                            background-color: white;
                            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                            min-height: 200px;
                            display: flex;
                            flex-direction: column;
                            justify-content: center;
                            align-items: center;
                            margin-bottom: 20px;
                        }
                        .flashcard-term { font-size: 28px; font-weight: bold; color: #1e88e5; }
                        .flashcard-jp { font-size: 24px; font-weight: bold; color: #d32f2f; margin-top: 10px;}
                        .flashcard-desc { font-size: 16px; color: #424242; margin-top: 15px; }
                        </style>
                        """, unsafe_allow_html=True)

                        if not st.session_state.flashcard_flipped:
                            # FRONT SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div style="color: #9e9e9e; margin-top: 20px;">(Tap 'Flip' to see meaning)</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            if st.button("ğŸ”„ Flip Card", use_container_width=True):
                                st.session_state.flashcard_flipped = True
                                st.rerun()
                                
                        else:
                            # BACK SIDE
                            st.markdown(f"""
                            <div class="flashcard">
                                <div class="flashcard-term">{word_data['term']}</div>
                                <div class="flashcard-jp">{word_data['jp']}</div>
                                <div class="flashcard-desc">ğŸ‡¯ğŸ‡µ {word_data['desc']}</div>
                                <div class="flashcard-desc">ğŸ‡ºğŸ‡¸ {word_data.get('desc_en', '')}</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            col_prev, col_next = st.columns(2)
                            with col_prev:
                                if st.button("â¬…ï¸ Previous", use_container_width=True):
                                    if st.session_state.flashcard_index > 0:
                                        st.session_state.flashcard_index -= 1
                                        st.session_state.flashcard_flipped = False
                                        st.rerun()
                            
                            with col_next:
                                if st.button("Next â¡ï¸", use_container_width=True):
                                    st.session_state.flashcard_index += 1
                                    st.session_state.flashcard_flipped = False
                                    st.rerun()

elif page == "Formulas ğŸ“":
    st.header("Formulas ğŸ“")
    if not formulas_data:
        st.warning("No formulas found.")
    else:
        cats = sorted({str(f.get("category", "General")) for f in formulas_data})
        cat_sel = st.multiselect("Category", options=cats, default=[])
        q = st.text_input("Search")
        df_f = pd.DataFrame(formulas_data)
        if not df_f.empty:
            if cat_sel:
                df_f = df_f[df_f["category"].isin(cat_sel)]
            if q:
                ql = q.lower()
                def _has(r):
                    return (ql in str(r.get("name", "")).lower() or
                            ql in str(r.get("formula", "")).lower() or
                            ql in str(r.get("explanation", "")).lower() or
                            ql in str(r.get("variables", "")).lower())
                df_f = df_f[df_f.apply(_has, axis=1)]
        st.write(f"Found {len(df_f)} formulas.")
        for _, row in df_f.iterrows():
            title = row.get("name", "")
            cat = row.get("category", "")
            if cat:
                title = f"{title} [{cat}]"
            with st.expander(title):
                ftxt = row.get("formula", "")
                if ftxt:
                    st.markdown(f"**Formula:** {ftxt}")
                vtxt = row.get("variables", "")
                if vtxt:
                    st.markdown(f"**Variables:** {vtxt}")
                etxt = row.get("explanation", "")
                if etxt:
                    st.markdown(etxt)
elif page == "Old Exams ğŸ“„":
    st.header("Old Exam Papers ğŸ“„")
    
    # Path to EXAM folder
    # platform/app.py -> platform/EXAM
    base_dir = os.path.dirname(os.path.abspath(__file__))
    exam_dir = os.path.join(base_dir, 'EXAM')
    metadata_file = os.path.join(base_dir, 'exam_metadata.json')
    
    metadata = {}
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
        except Exception as e:
            st.error(f"Error loading metadata: {e}")

    with st.expander("ğŸ“ Exam Infoï¼ˆåˆæ ¼ãƒœãƒ¼ãƒ€ãƒ¼ R4ã€œR6ï¼‰", expanded=True):
        st.markdown("""
        ### çŸ­ç­”å¼ï¼ˆç›¸å¯¾è©•ä¾¡ï¼‰
        - åˆæ ¼åŸºæº–: ç·ç‚¹æ•°ã®70ï¼…ã‚’åŸºæº–ã¨ã—ã¦ã€å¯©æŸ»ä¼šãŒç›¸å½“ã¨èªã‚ãŸå¾—ç‚¹æ¯”ç‡
        - è¶³åˆ‡ã‚Š: 1ç§‘ç›®ã§ã‚‚æº€ç‚¹ã®40ï¼…æœªæº€ãŒã‚ã‚‹å ´åˆã€ä¸åˆæ ¼ã®å¯èƒ½æ€§ã‚ã‚Š
        
        å‚è€ƒï¼šè¿‘å¹´ã®ãƒœãƒ¼ãƒ€ãƒ¼ï¼ˆäºˆå‚™æ ¡ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢é›†è¨ˆï¼‰
        
        | å®Ÿæ–½å¹´ | ç¬¬Iå›ï¼ˆ12æœˆï¼‰ | ç¬¬IIå›ï¼ˆ5æœˆï¼‰ | å‚™è€ƒ |
        |---|---:|---:|---|
        | ä»¤å’Œ6å¹´ (2024) | 68.0% | 78.0% | æ˜“åŒ–ã§é«˜æ°´æº– |
        | ä»¤å’Œ5å¹´ (2023) | 71.0% | 70.2% | 70%å‰å¾Œ |
        | ä»¤å’Œ4å¹´ (2022) | 68.0% | 73.0% | å¤‰å‹•å¤§ |
        
        - å‡ºå…¸ï¼ˆå‚è€ƒå€¤ãƒ»è§£èª¬è¨˜äº‹ï¼‰:
          - ãƒã‚¤ãƒŠãƒ“ä¼šè¨ˆå£«ã€Œç¬¬â…¡å›çŸ­ç­”å¼è©¦é¨“ çµæœé€Ÿå ±ã€: https://cpa.mynavi.jp/column_mt/2024/06/967.html
          - çŸ­ç­”å¼ã®åˆæ ¼åŸºæº–ï¼ˆå…¬å¼ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/kijuntou/05.html
        
        ---
        ### è«–æ–‡å¼ï¼ˆåå·®å€¤æ–¹å¼ï¼‰
        - åˆæ ¼åŸºæº–: ç·ç‚¹æ•°ã®60ï¼…ã‚’åŸºæº–ã¨ã—ã¦ã€å¯©æŸ»ä¼šãŒç›¸å½“ã¨èªã‚ãŸå¾—ç‚¹æ¯”ç‡
        - è¶³åˆ‡ã‚Š: 1ç§‘ç›®ã§ã‚‚å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰ãŒ40ï¼…æœªæº€ã®ã‚‚ã®ãŒã‚ã‚‹å ´åˆã¯ä¸åˆæ ¼
        - å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰ã®ä¸€èˆ¬å¼: 50 + 10 Ã— (å€‹äººã®å¾—ç‚¹ âˆ’ å¹³å‡ç‚¹) / æ¨™æº–åå·®
        
        è¿‘å¹´ã®åˆæ ¼ç‚¹ï¼ˆå…¬è¡¨è³‡æ–™/å ±é“ãƒ™ãƒ¼ã‚¹ï¼‰
        - ä»¤å’Œ6å¹´ (2024): ç´„52.0å‰å¾Œï¼ˆæ¯å¹´å¾®èª¿æ•´ï¼‰
        - ä»¤å’Œ5å¹´ (2023): ç´„51.8å‰å¾Œï¼ˆå¾®èª¿æ•´ï¼‰
        - ä»¤å’Œ4å¹´ (2022): ç´„52.0å‰å¾Œï¼ˆåŸºæº–ã«è¿‘ã„ï¼‰
        
        - å‡ºå…¸ï¼ˆå…¬å¼ï¼‰:
          - åˆæ ¼åŸºæº–ã«ã¤ã„ã¦ï¼ˆçŸ­ç­”å¼/è«–æ–‡å¼ã®å…¬å¼åŸºæº–ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/kijuntou/05.html
          - ä»¤å’Œ7å¹´ è«–æ–‡å¼ åˆæ ¼ç‚¹ã®å…¬è¡¨ä¾‹ï¼ˆPDFã€åå·®å€¤æ³•ã®èª¬æ˜å«ã‚€ï¼‰: https://www.fsa.go.jp/cpaaob/kouninkaikeishi-shiken/r7shiken/ronbungoukaku_r07/02.pdf
        """)
        # R4-R6 short-answer border mini chart
        try:
            df_borders = pd.DataFrame([
                {"Year": "R4 (2022)", "Session": "I (Dec)", "Border": 68.0},
                {"Year": "R4 (2022)", "Session": "II (May)", "Border": 73.0},
                {"Year": "R5 (2023)", "Session": "I (Dec)", "Border": 71.0},
                {"Year": "R5 (2023)", "Session": "II (May)", "Border": 70.2},
                {"Year": "R6 (2024)", "Session": "I (Dec)", "Border": 68.0},
                {"Year": "R6 (2024)", "Session": "II (May)", "Border": 78.0},
            ])
            fig_border = px.bar(
                df_borders, x="Year", y="Border", color="Session", barmode="group",
                title="çŸ­ç­”å¼ åˆæ ¼ãƒœãƒ¼ãƒ€ãƒ¼ï¼ˆå‚è€ƒå€¤ï¼‰R4ã€œR6", range_y=[60, 80],
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            fig_border.update_layout(legend_title_text="Session", yaxis_title="Border (%)")
            st.plotly_chart(fig_border, use_container_width=True)
            st.caption("æ³¨: å‚è€ƒå€¤ï¼ˆäºˆå‚™æ ¡ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢é›†è¨ˆãƒ™ãƒ¼ã‚¹ï¼‰ã€‚å…¬å¼ã®ç›¸å¯¾åŸºæº–ã¯ãƒªãƒ³ã‚¯å‚ç…§ã€‚")
        except Exception:
            pass
    
    with st.expander("ğŸ¯ çŸ­ç­” å¿…è¦å¾—ç‚¹è¨ˆç®—æ©Ÿ", expanded=False):
        # Target presets
        p1, p2, p3 = st.columns(3)
        with p1:
            if st.button("Target 70%"):
                st.session_state["tanto_target_pct"] = 70
                st.rerun()
        with p2:
            if st.button("Target 72%"):
                st.session_state["tanto_target_pct"] = 72
                st.rerun()
        with p3:
            if st.button("Target 78%"):
                st.session_state["tanto_target_pct"] = 78
                st.rerun()

        # Target slider
        col_t1, col_t2 = st.columns(2)
        with col_t1:
            default_target = st.session_state.get("tanto_target_pct", 72)
            target_pct = st.slider("ç›®æ¨™å¾—ç‚¹ç‡(%)", min_value=60, max_value=85, value=default_target, step=1, key="tanto_target_slider")
            target_points = int(500 * target_pct / 100)
            st.metric("å¿…è¦åˆè¨ˆç‚¹(500ç‚¹æº€ç‚¹)", f"{target_points} ç‚¹", f"{target_pct}%")
        with col_t2:
            st.caption("é…ç‚¹: ä¼æ¥­æ³•100ãƒ»ç®¡ç†100ãƒ»ç›£æŸ»100ãƒ»è²¡å‹™200")
        
        # Preset buttons for subject shares
        b1, b2, b3 = st.columns(3)
        with b1:
            if st.button("Preset: Balanced 70/70/70/70"):
                st.session_state["tanto_corp_pct"] = 70
                st.session_state["tanto_mgmt_pct"] = 70
                st.session_state["tanto_audit_pct"] = 70
                st.session_state["tanto_fin_pct"] = 70
                st.rerun()
        with b2:
            if st.button("Preset: Fin-Heavy 65/65/65/78"):
                st.session_state["tanto_corp_pct"] = 65
                st.session_state["tanto_mgmt_pct"] = 65
                st.session_state["tanto_audit_pct"] = 65
                st.session_state["tanto_fin_pct"] = 78
                st.rerun()
        with b3:
            if st.button("Preset: Safety 75/70/70/75"):
                st.session_state["tanto_corp_pct"] = 75
                st.session_state["tanto_mgmt_pct"] = 70
                st.session_state["tanto_audit_pct"] = 70
                st.session_state["tanto_fin_pct"] = 75
                st.rerun()

        # Inputs with keys to allow presets
        if "tanto_corp_pct" not in st.session_state:
            st.session_state["tanto_corp_pct"] = 70
        if "tanto_mgmt_pct" not in st.session_state:
            st.session_state["tanto_mgmt_pct"] = 70
        if "tanto_audit_pct" not in st.session_state:
            st.session_state["tanto_audit_pct"] = 70
        if "tanto_fin_pct" not in st.session_state:
            st.session_state["tanto_fin_pct"] = 70

        c1, c2 = st.columns(2)
        with c1:
            corp_pct = st.number_input("ä¼æ¥­æ³•(%)", min_value=0, max_value=100, value=st.session_state["tanto_corp_pct"], step=1, key="tanto_corp_pct")
            mgmt_pct = st.number_input("ç®¡ç†ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_mgmt_pct"], step=1, key="tanto_mgmt_pct")
        with c2:
            audit_pct = st.number_input("ç›£æŸ»è«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_audit_pct"], step=1, key="tanto_audit_pct")
            fin_pct = st.number_input("è²¡å‹™ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=st.session_state["tanto_fin_pct"], step=1, key="tanto_fin_pct")
        total_points = int(corp_pct/100*100 + mgmt_pct/100*100 + audit_pct/100*100 + fin_pct/100*200)
        total_pct = round(total_points / 500 * 100, 1)
        col_r1, col_r2, col_r3 = st.columns(3)
        with col_r1:
            st.metric("åˆè¨ˆå¾—ç‚¹ç‡", f"{total_pct}%")
        with col_r2:
            st.metric("åˆè¨ˆç‚¹", f"{total_points} ç‚¹")
        with col_r3:
            ok = (corp_pct >= 40) and (mgmt_pct >= 40) and (audit_pct >= 40) and (fin_pct >= 40)
            status = "OK" if (total_pct >= target_pct and ok) else "è¦æ”¹å–„"
            st.metric("é”æˆçŠ¶æ³", status)
        if not ok:
            st.warning("è¶³åˆ‡ã‚Šæ³¨æ„: ã„ãšã‚Œã‹ã®ç§‘ç›®ãŒ40%æœªæº€ã§ã™ã€‚")
        elif total_pct < target_pct:
            st.info("åˆè¨ˆãŒç›®æ¨™ã«å±Šã„ã¦ã„ã¾ã›ã‚“ã€‚å¼·åŒ–ç§‘ç›®ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.success("ç›®æ¨™é”æˆãƒ©ã‚¤ãƒ³ã§ã™ã€‚")
    
    with st.expander("ğŸ§® è«–æ–‡ åå·®å€¤è¨ˆç®—æ©Ÿ", expanded=False):
        col_e1, col_e2, col_e3 = st.columns(3)
        with col_e1:
            personal = st.number_input("å€‹äººã®å¾—ç‚¹", min_value=0.0, value=60.0, step=0.1)
        with col_e2:
            mean = st.number_input("å¹³å‡ç‚¹", min_value=0.0, value=55.0, step=0.1)
        with col_e3:
            std = st.number_input("æ¨™æº–åå·®", min_value=0.1, value=7.0, step=0.1)
        deviation = round(50 + 10 * (personal - mean) / std, 2)
        st.metric("å¾—ç‚¹æ¯”ç‡ï¼ˆåå·®å€¤ï¼‰", f"{deviation}")
        if deviation < 40:
            st.warning("è¶³åˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã«æ³¨æ„ï¼ˆ40æœªæº€ï¼‰ã€‚")
        elif deviation < 52:
            st.info("åŸºæº–ç›®å®‰ 52 ã«æœªé”ã€‚å­¦ç¿’å¼·åŒ–ãŒå¿…è¦ã§ã™ã€‚")
        else:
            st.success("åˆæ ¼åŸºæº–ç›®å®‰ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")
    
    with st.expander("ğŸ“ åŸºæœ¬å¼ / Basic Formulas", expanded=False):
        st.markdown("""
        - çŸ­ç­” åˆè¨ˆç‚¹: åˆè¨ˆç‚¹ = 100Ã—ä¼æ¥­æ³•% + 100Ã—ç®¡ç†% + 100Ã—ç›£æŸ»% + 200Ã—è²¡å‹™%
        - çŸ­ç­” åˆè¨ˆå¾—ç‚¹ç‡: åˆè¨ˆå¾—ç‚¹ç‡(%) = åˆè¨ˆç‚¹ Ã· 500 Ã— 100
        - çŸ­ç­” åˆæ ¼æ¡ä»¶(ç›®å®‰): å…¨ç§‘ç›®40%ä»¥ä¸Š ã‹ã¤ åˆè¨ˆå¾—ç‚¹ç‡ â‰¥ ç›®æ¨™%
        - é€†ç®—ï¼ˆå¿…è¦ãªè²¡å‹™%ï¼‰: è²¡å‹™% = { (ç›®æ¨™%Ã—500/100) âˆ’ [100Ã—(ä¼æ¥­æ³•%+ç®¡ç†%+ç›£æŸ»%)] } Ã· 200 Ã— 100
        - è«–æ–‡ åå·®å€¤: D = 50 + 10 Ã— (x âˆ’ Î¼)/Ïƒ
        - è«–æ–‡ å¿…è¦å¾—ç‚¹: x = Î¼ + Ïƒ Ã— (D âˆ’ 50)/10
        """)
        col_rev1, col_rev2 = st.columns(2)
        with col_rev1:
            st.subheader("çŸ­ç­” é€†ç®—ï¼ˆå¿…è¦è²¡å‹™%ï¼‰")
            t_pct = st.number_input("ç›®æ¨™å¾—ç‚¹ç‡(%)", min_value=60, max_value=85, value=72, step=1, key="rev_target")
            rc = st.number_input("ä¼æ¥­æ³•(%)", min_value=0, max_value=100, value=70, step=1, key="rev_corp")
            rm = st.number_input("ç®¡ç†ä¼šè¨ˆè«–(%)", min_value=0, max_value=100, value=70, step=1, key="rev_mgmt")
            ra = st.number_input("ç›£æŸ»è«–(%)", min_value=0, max_value=100, value=70, step=1, key="rev_audit")
            need_fin = ((t_pct/100*500) - (100*(rc+rm+ra))) / 200 * 100
            need_fin_disp = round(need_fin, 1)
            feas = 0 <= need_fin <= 100
            st.metric("å¿…è¦ è²¡å‹™ä¼šè¨ˆè«–(%)", f"{need_fin_disp}%")
            if not feas:
                st.warning("ã“ã®æ¡ä»¶ã§ã¯é”æˆä¸å¯èƒ½ã§ã™ï¼ˆ0ã€œ100%ã®ç¯„å›²å¤–ï¼‰ã€‚")
        with col_rev2:
            st.subheader("è«–æ–‡ å¿…è¦å¾—ç‚¹ï¼ˆé€†ç®—ï¼‰")
            d_target = st.number_input("ç›®æ¨™åå·®å€¤ D", min_value=35.0, max_value=70.0, value=52.0, step=0.1, key="rev_d")
            mu = st.number_input("å¹³å‡ç‚¹ Î¼", min_value=0.0, value=55.0, step=0.1, key="rev_mu")
            sigma = st.number_input("æ¨™æº–åå·® Ïƒ", min_value=0.1, value=7.0, step=0.1, key="rev_sigma")
            need_x = mu + sigma * (d_target - 50) / 10
            st.metric("å¿…è¦å¾—ç‚¹ x", f"{round(need_x, 2)}")

    if not os.path.exists(exam_dir):
        st.error(f"EXAM directory not found at: {exam_dir}")
    else:
        # --- Vocab Analysis Section ---
        vocab_file = os.path.join(base_dir, 'exam_vocab.json')
        if os.path.exists(vocab_file):
            with st.expander("ğŸ“Š Exam Vocabulary Analysis (Tangocho)", expanded=False):
                st.info("Top frequent words extracted from actual exam papers. Master these!")
                
                try:
                    with open(vocab_file, "r", encoding="utf-8") as f:
                        exam_vocab = json.load(f)
                    
                    # Subject selector
                    subjects = list(exam_vocab.keys())
                    if subjects:
                        selected_subject = st.selectbox("Select Subject for Vocabulary", subjects)
                        
                        if selected_subject:
                            words = exam_vocab[selected_subject]
                            
                            # Display as a dataframe or cloud
                            # Create a nice dataframe
                            df_vocab = pd.DataFrame(words)
                            df_vocab.columns = ["Word", "Frequency"]
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                st.dataframe(df_vocab, use_container_width=True, height=400)
                                
                            with col2:
                                if not df_vocab.empty:
                                    st.markdown("### Top Keywords")
                                    # Create a bar chart
                                    fig = px.bar(
                                        df_vocab.head(20), 
                                        x='Frequency', 
                                        y='Word', 
                                        orientation='h',
                                        title=f"Top 20 Words in {selected_subject}",
                                        color='Frequency',
                                        color_continuous_scale='Viridis'
                                    )
                                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"Error loading vocabulary: {e}")
        
        st.divider()

        files = [f for f in os.listdir(exam_dir) if f.lower().endswith('.pdf')]
        
        if not files:
            st.warning("No PDF exam papers found.")
        else:
            st.write(f"Found {len(files)} exam papers.")
            
            # Sort by filename to keep subjects grouped (01, 02, ...)
            for f in sorted(files):
                info = metadata.get(f, {})
                display_title = f"**{f}**"
                sub_info = ""
                
                if info:
                    # Construct nice title
                    # e.g. R7 Short-Answer (Tanto) I - Corporate Law (ä¼æ¥­æ³•)
                    year = info.get('year', '')
                    exam_type = info.get('type', '')
                    subject = info.get('subject', '')
                    
                    # Create a clean badge-like string
                    display_title = f"**{subject}** - {year} {exam_type}"
                    sub_info = f"Filename: {f}"
                
                with st.container():
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(f"ğŸ“„ {display_title}")
                        if sub_info:
                            st.caption(sub_info)
                    with col2:
                        if st.button("Open", key=f"open_exam_{f}"):
                            try:
                                file_path = os.path.join(exam_dir, f)
                                if os.name == 'nt':
                                    os.startfile(file_path)
                                    st.toast(f"Opening {f}...", icon="ğŸš€")
                                else:
                                    st.warning("File opening is only supported on Windows locally.")
                            except Exception as e:
                                st.error(f"Error opening file: {e}")
                    st.divider()
            
            st.info("ğŸ’¡ Tip: Use these papers to practice time management.")

elif page == "Study Timer â±ï¸":
    st.header("Study Timer")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Log Study Session")
        with st.form("timer_form"):
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective"])
            duration = st.number_input("Duration (minutes)", min_value=1, value=60)
            date_val = st.date_input("Date", value=date.today())
            submitted = st.form_submit_button("Log Session")
            
            if submitted:
                new_log = {
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'duration': duration
                }
                st.session_state.data["logs"].append(new_log)
                save_data(st.session_state.data)
                st.success("Session logged!")
                
    with col2:
        st.subheader("Recent Logs")
        if st.session_state.data["logs"]:
            df_logs = pd.DataFrame(st.session_state.data["logs"])
            st.dataframe(df_logs.sort_values('date', ascending=False))
            
            total_mins = df_logs['duration'].sum()
            hours = total_mins // 60
            mins = total_mins % 60
            st.metric("Total Study Time", f"{hours}h {mins}m")
        else:
            st.info("No logs yet.")

elif page == "Mock Exams ğŸ“":
    st.header("Mock Exam Schedule")
    df_exams = pd.DataFrame(mock_exams)
    st.table(df_exams)

elif page == "Scores ğŸ“ˆ":
    st.header("Score Tracker")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        with st.form("score_form"):
            name = st.text_input("Exam/Drill Name")
            date_val = st.date_input("Date", value=date.today())
            subject = st.selectbox("Subject", ["Financial", "Management", "Audit", "Company", "Tax", "Elective", "Total"])
            val = st.number_input("Score (%)", min_value=0, max_value=100, value=70)
            submitted = st.form_submit_button("Save Score")
            
            if submitted:
                new_score = {
                    'name': name,
                    'date': date_val.strftime("%Y-%m-%d"),
                    'subject': subject,
                    'val': val
                }
                st.session_state.data["scores"].append(new_score)
                save_data(st.session_state.data)
                st.success("Score saved!")
                
    with col2:
        if st.session_state.data["scores"]:
            df = pd.DataFrame(st.session_state.data["scores"])
            st.subheader("History")
            st.dataframe(df.sort_values('date', ascending=False))
            
            # Line Chart
            st.subheader("Trend")
            fig = go.Figure()
            for sub in df['subject'].unique():
                sub_df = df[df['subject'] == sub].sort_values('date')
                fig.add_trace(go.Scatter(x=sub_df['date'], y=sub_df['val'], mode='lines+markers', name=sub))
            fig.update_layout(yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No scores recorded yet.")

elif page == "Drills ğŸ”§":
    st.header("Drills âœï¸")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("Select Topic")
        subject = st.radio("Subject", ["Financial", "Management", "Audit", "Company"])
        
        st.subheader("Select Level")
        level = st.radio("Level", ["Level 1 (Basic)", "Level 2 (Standard)", "Level 3 (Advanced)", "Vocabulary (Important Words)"])
        level_map = {
            "Level 1 (Basic)": 1, 
            "Level 2 (Standard)": 2, 
            "Level 3 (Advanced)": 3,
            "Vocabulary (Important Words)": "vocab"
        }
        selected_level = level_map[level]
        
        if selected_level == "vocab":
            st.info("ğŸ’¡ Hint: These are key English terms often found in global accounting standards (IFRS/US GAAP).")
            
            # Add Tangocyo List View
            with st.expander("ğŸ“– View Vocabulary List (Tangocyo)"):
                vocab_list_view = vocab_data.get(subject, [])
                if vocab_list_view:
                    for v in vocab_list_view:
                        st.markdown(f"**{v['term']}** ({v['jp']})")
                        st.markdown(f"- ğŸ‡¯ğŸ‡µ {v['desc']}")
                        st.markdown(f"- ğŸ‡ºğŸ‡¸ {v.get('desc_en', '')}")
                        st.divider()
                else:
                    st.warning("No vocabulary data available.")
    
        # Load generated questions if available and not already loaded
        if 'generated_questions' not in st.session_state:
            try:
                with open('questions.json', 'r', encoding='utf-8') as f:
                    st.session_state.generated_questions = json.load(f)
            except FileNotFoundError:
                st.session_state.generated_questions = {}

        if st.button("Start / Restart Quiz"):
            import random
            st.session_state.quiz_state['active'] = True
            st.session_state.quiz_state['subject'] = subject
            st.session_state.quiz_state['level'] = selected_level
            st.session_state.quiz_state['q_index'] = 0
            st.session_state.quiz_state['score'] = 0
            st.session_state.quiz_state['show_feedback'] = False
            st.session_state.quiz_state['selected_option'] = None
            
            # Select questions based on level
            if selected_level == "vocab":
                vocab_list = vocab_data.get(subject, [])
                if vocab_list:
                    vocab_questions = []
                    for v in vocab_list:
                        vocab_questions.append({
                            'q': f"ã€é‡è¦èªå¥ã€‘ ã€Œ{v['term']}ã€ ã®æ„å‘³ã¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã¯ï¼Ÿ",
                            'options': [v['desc'], "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é€†ã®æ„å‘³ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: ç„¡é–¢ä¿‚ãªå®šç¾©ï¼‰", "ï¼ˆèª¤ã‚Šã®é¸æŠè‚¢: é¡ä¼¼ç”¨èªã®å®šç¾©ï¼‰"],
                            'correct': 0,
                            'explanation': f"**{v['term']} ({v['jp']})**\n\n**ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª:** {v['desc']}\n\n**ğŸ‡ºğŸ‡¸ English:** {v.get('desc_en', 'No English description available.')}",
                            'type': 'vocab'
                        })
                    # Shuffle options for each question
                    for q in vocab_questions:
                        correct_opt = q['options'][0]
                        random.shuffle(q['options'])
                        q['correct'] = q['options'].index(correct_opt)
                    
                    st.session_state.quiz_state['questions'] = vocab_questions
                else:
                    st.warning(f"No vocabulary data for {subject} yet.")
                    st.session_state.quiz_state['active'] = False
            
            elif selected_level == 2 or selected_level == 3:
                # Use generated questions for Level 2/3
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level_gen_qs = [q for q in gen_qs if q.get('level') == selected_level]
                
                if level_gen_qs:
                     # Pick 10 random questions
                    if len(level_gen_qs) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(level_gen_qs, 10)
                    else:
                        st.session_state.quiz_state['questions'] = level_gen_qs
                else:
                    st.warning(f"No generated questions for {subject} Level {selected_level} yet.")
                    st.session_state.quiz_state['active'] = False

            else:
                # Level 1 (Static questions + Generated Level 0)
                raw_questions = drill_questions.get(subject, [])
                # Filter for Level 1 or undefined (legacy)
                static_level1 = [q for q in raw_questions if q.get('level', 1) == 1]
                
                # Fetch Level 0 from generated questions
                gen_qs = st.session_state.generated_questions.get(subject, [])
                level0_gen_qs = [q for q in gen_qs if q.get('level') == 0]
                
                # Merge
                all_level1_questions = static_level1 + level0_gen_qs
                
                if all_level1_questions:
                    # Random sample if too many
                    if len(all_level1_questions) > 10:
                        st.session_state.quiz_state['questions'] = random.sample(all_level1_questions, 10)
                    else:
                        st.session_state.quiz_state['questions'] = all_level1_questions
                else:
                    st.warning(f"No questions found for {subject} Level 1.")
                    st.session_state.quiz_state['active'] = False
                
    with col2:
        qs = st.session_state.quiz_state
        if qs['active']:
            current_q = qs['questions'][qs['q_index']]
            total_q = len(qs['questions'])
            
            st.subheader(f"Question {qs['q_index'] + 1} / {total_q}")
            st.markdown(f"**{current_q['q']}**")
            
            # Options
            options = current_q['options']
            
            # If feedback is shown, disable interaction or show result
            if qs['show_feedback']:
                for idx, opt in enumerate(options):
                    if idx == current_q['correct']:
                        st.markdown(f"<div class='correct-answer'>{opt} (Correct)</div>", unsafe_allow_html=True)
                    elif idx == qs['selected_option']:
                        st.markdown(f"<div class='incorrect-answer'>{opt} (Your Answer)</div>", unsafe_allow_html=True)
                    else:
                        st.text(opt)
                
                st.markdown("### Explanation")
                st.info(current_q['explanation'])
                
                if qs['q_index'] < total_q - 1:
                    if st.button("Next Question"):
                        qs['q_index'] += 1
                        qs['show_feedback'] = False
                        qs['selected_option'] = None
                        st.rerun()
                else:
                    score = qs['score']
                    st.success(f"Quiz Completed! Score: {score} / {total_q}")
                    
                    if st.button("Finish & Claim XP"):
                        # XP Logic
                        earned_xp = score * 10
                        current_xp = st.session_state.data.get('xp', 0)
                        current_level = st.session_state.data.get('level', 1)
                        
                        new_xp = current_xp + earned_xp
                        required_xp = current_level * 100
                        
                        leveled_up = False
                        while new_xp >= required_xp:
                            new_xp -= required_xp
                            current_level += 1
                            required_xp = current_level * 100
                            leveled_up = True
                        
                        st.session_state.data['xp'] = new_xp
                        st.session_state.data['level'] = current_level
                        
                        # Save score history
                        st.session_state.data["scores"].append({
                            'name': f"Drill: {qs.get('subject', 'General')} Lv{qs.get('level', '?')}",
                            'date': date.today().strftime("%Y-%m-%d"),
                            'subject': qs.get('subject', 'General'),
                            'val': (score / total_q) * 100 if total_q > 0 else 0
                        })
                        save_data(st.session_state.data)
                        
                        if leveled_up:
                            st.balloons()
                            st.success(f"LEVEL UP! You are now Level {current_level}!")
                        else:
                            st.success(f"Earned {earned_xp} XP!")
                            
                        qs['active'] = False
                        st.rerun()
                        
            else:
                choice = st.radio("Choose Answer:", options, index=None, key=f"q_{qs['q_index']}")
                if st.button("Submit Answer"):
                    if choice:
                        selected_idx = options.index(choice)
                        qs['selected_option'] = selected_idx
                        qs['show_feedback'] = True
                        if selected_idx == current_q['correct']:
                            qs['score'] += 1
                        st.rerun()
                    else:
                        st.warning("Please select an option.")
        else:
            st.info("Select a subject and level from the sidebar to start.")

elif page == "Survival Mode âš¡":
    st.header("âš¡ Survival Mode")
    st.markdown("### Challenge your limits! 3 Strikes and you're out.")
    
    # Initialize State
    if 'survival' not in st.session_state:
        st.session_state.survival = {
            'active': False,
            'lives': 3,
            'streak': 0,
            'score': 0,
            'q': None,
            'feedback': False,
            'user_ans': None,
            'target_streak': "Unlimited"
        }
    
    ss = st.session_state.survival
    
    # Load Questions Logic
    if 'all_questions' not in st.session_state:
        all_qs = []
        # Static
        for sub, qs in drill_questions.items():
            for q in qs:
                # Create a copy to avoid modifying original
                q_copy = q.copy()
                q_copy['subject'] = sub
                all_qs.append(q_copy)
        # Generated
        json_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'questions.json')
        if os.path.exists(json_path):
             try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gen_qs = json.load(f)
                    for sub, qs in gen_qs.items():
                        for q in qs:
                            q_copy = q.copy()
                            q_copy['subject'] = sub
                            all_qs.append(q_copy)
             except:
                 pass
        st.session_state.all_questions = all_qs
    
    if not ss['active']:
        st.subheader("Select Challenge Mode")
        streak_target = st.radio("Target Streak", ["Unlimited", 1, 5, 10], horizontal=True, format_func=lambda x: "âˆ Unlimited" if x == "Unlimited" else f"Target: {x} ğŸ”¥")

        if st.button("ğŸš€ Start Challenge", use_container_width=True):
            ss['active'] = True
            ss['lives'] = 3
            ss['streak'] = 0
            ss['score'] = 0
            ss['q'] = None
            ss['feedback'] = False
            ss['target_streak'] = streak_target
            st.rerun()
            
    else:
        # Metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("Lives", "â¤ï¸" * ss['lives'])
        target_display = "âˆ" if ss.get('target_streak', "Unlimited") == "Unlimited" else ss['target_streak']
        c2.metric("Streak", f"ğŸ”¥ {ss['streak']} / {target_display}")
        c3.metric("Score", ss['score'])
        
        target = ss.get('target_streak', "Unlimited")
        is_win = target != "Unlimited" and ss['streak'] >= target

        if ss['lives'] <= 0 or is_win:
            if is_win:
                st.balloons()
                st.success(f"ğŸ‰ MISSION ACCOMPLISHED! You reached a {ss['streak']} streak!")
            else:
                st.error("ğŸ’€ GAME OVER")
            
            st.markdown(f"### Final Score: {ss['score']}")
            
            # Save High Score
            if ss['score'] > 0:
                st.session_state.data["scores"].append({
                    'name': f"Survival Mode âš¡ (Target {target})",
                    'date': date.today().strftime("%Y-%m-%d"),
                    'subject': 'Survival',
                    'val': ss['score'] # Just storing score
                })
                save_data(st.session_state.data)
            
            if st.button("Try Again", use_container_width=True):
                ss['active'] = False
                st.rerun()
        else:
            # Get Question
            if ss['q'] is None:
                import random
                if st.session_state.all_questions:
                    q_data = random.choice(st.session_state.all_questions)
                    # Shuffle options
                    opts = q_data['options'].copy()
                    correct_text = q_data['options'][q_data['correct']]
                    random.shuffle(opts)
                    
                    ss['q'] = {
                        'q': q_data['q'],
                        'options': opts,
                        'correct_idx': opts.index(correct_text),
                        'explanation': q_data['explanation'],
                        'subject': q_data.get('subject', 'General')
                    }
                else:
                    st.error("No questions found!")
                    st.stop()
            
            q = ss['q']
            
            st.markdown(f"**[{q['subject']}]** {q['q']}")
            
            if not ss['feedback']:
                # Use a form to prevent reload on radio selection
                with st.form(key=f"surv_form_{ss['score']}_{ss['lives']}"):
                    ans = st.radio("Select Answer:", q['options'])
                    submit = st.form_submit_button("Submit Answer")
                    
                    if submit:
                        ss['user_ans'] = q['options'].index(ans)
                        ss['feedback'] = True
                        
                        if ss['user_ans'] == q['correct_idx']:
                            # Bonus XP for streak
                            bonus = ss['streak'] * 2
                            points = 10 + bonus
                            ss['score'] += points
                            ss['streak'] += 1
                            st.session_state.data['xp'] = st.session_state.data.get('xp', 0) + points
                            st.toast(f"Correct! +{points} XP", icon="âœ…")
                            
                            # Check Win
                            target = ss.get('target_streak', "Unlimited")
                            if target != "Unlimited" and ss['streak'] >= target:
                                st.rerun()
                        else:
                            ss['lives'] -= 1
                            ss['streak'] = 0
                            st.toast("Wrong Answer!", icon="âŒ")
                        
                        st.rerun()
            else:
                # Show Feedback
                if ss['user_ans'] == q['correct_idx']:
                    st.success("âœ… Correct!")
                else:
                    st.error(f"âŒ Wrong! Correct: {q['options'][q['correct_idx']]}")
                
                st.info(f"**Explanation:**\n\n{q['explanation']}")
                
                if st.button("Next Question â¡", use_container_width=True):
                    ss['q'] = None
                    ss['feedback'] = False
                    st.rerun()

elif page == "Roadmap ğŸ—ºï¸":
    st.header("ğŸ—ºï¸ CPA Exam Strategy Roadmap (2026-2027)")
    
    # 1. Countdown Section
    today = date.today()
    tanto_date = date(2027, 5, 23) # Estimated
    ronbun_date = date(2027, 8, 20) # Estimated
    
    days_tanto = (tanto_date - today).days
    days_ronbun = (ronbun_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Days to May Short Exam", f"{days_tanto} Days", "Target: Pass")
    col2.metric("Days to Aug Essay Exam", f"{days_ronbun} Days", "Final Goal")
    col3.metric("Current Phase", "Foundation (2026)", "Build Habits")
    
    st.divider()

    # 2. Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Visual Schedule (Gantt)", "ğŸ—“ï¸ Monthly Strategy", "â° Daily Routine"])
    
    with tab1:
        st.subheader("Strategic Timeline")
        # Gantt Chart Data
        df_gantt = pd.DataFrame([
            dict(Task="Foundation (Fin/Mgmt)", Start='2026-02-01', Finish='2026-06-30', Phase='Phase 0: Foundation'),
            dict(Task="Audit & Company Law", Start='2026-04-01', Finish='2026-09-30', Phase='Phase 0: Foundation'),
            dict(Task="Tax Law & Electives", Start='2026-07-01', Finish='2026-12-31', Phase='Phase 0: Foundation'),
            dict(Task="Dec Short (Practice)", Start='2026-10-01', Finish='2026-12-13', Phase='Phase 0: Foundation'),
            dict(Task="Short Exam Mastery", Start='2027-01-01', Finish='2027-05-23', Phase='Phase 1: Short Exam'),
            dict(Task="Essay Sprint", Start='2027-05-24', Finish='2027-08-20', Phase='Phase 2: Essay Sprint'),
        ])
        
        # Create Gantt
        fig = px.timeline(df_gantt, x_start="Start", x_end="Finish", y="Task", color="Phase", 
                          title="CPA Exam 1.5 Year Plan",
                          color_discrete_sequence=px.colors.qualitative.Prism)
        fig.update_yaxes(autorange="reversed") # Task order top-to-bottom
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("ğŸ’¡ **Golden Route**: Pass May Short -> Pass August Essay in one go.")

    with tab2:
        st.subheader("Detailed Monthly Strategy")
        
        with st.expander("Phase 0: Foundation (2026)", expanded=True):
            st.markdown("""
            *   **Feb - Mar**: Build study habits. Focus on Fin/Mgmt Accounting basics (Calculations).
            *   **Apr - Jun**: Start Applied theory. Begin Audit & Company Law.
            *   **Jul - Sep**: **CRITICAL** Start Tax Law & Electives (Management/Statistics).
            *   **Oct - Dec**: **Dec Short Exam Challenge**. Aim for 60%+ even if you fail.
            """)
            
        with st.expander("Phase 1: Short Exam Mastery (Jan - May 2027)"):
            st.markdown("""
            *   **Jan - Mar**: Solidify basics. Aim for 75%+ in drills. Focus on weak areas.
            *   **Apr**: Mock Exams (TAC/Ohara). Analyze errors thoroughly.
            *   **May**: Peak conditioning. Rote memorization of text (Audit/Company Law). **PASS EXAM**.
            """)
            
        with st.expander("Phase 2: Essay Sprint (Jun - Aug 2027)"):
            st.markdown("""
            *   **Jun**: Revive Tax/Elective knowledge (often forgotten during Short prep).
            *   **Jul**: Output training (Writing). Learn "Key Phrases" for theory questions.
            *   **Aug**: Final adjustments. Health management is key. **PASS EXAM**.
            """)

    with tab3:
        st.subheader("â° Ideal Daily Routine (Student/Full-time Study)")
        
        schedule_data = [
            {"Time": "07:00 - 08:00", "Activity": "Wake up / Light Breakfast / Review Vocab"},
            {"Time": "08:00 - 11:00", "Activity": "ğŸ§  **Deep Work 1**: Financial Accounting (Calc) - 3h"},
            {"Time": "11:00 - 12:00", "Activity": "Lunch / Nap (20m)"},
            {"Time": "12:00 - 15:00", "Activity": "ğŸ§  **Deep Work 2**: Management Accounting / Theory - 3h"},
            {"Time": "15:00 - 16:00", "Activity": "Gym / Walk / Break"},
            {"Time": "16:00 - 19:00", "Activity": "ğŸ§  **Deep Work 3**: Corporate Law / Audit - 3h"},
            {"Time": "19:00 - 20:00", "Activity": "Dinner / Relax"},
            {"Time": "20:00 - 22:00", "Activity": "ğŸ“– **Review**: Weak areas / Next day planning - 2h"},
            {"Time": "22:00 - 23:00", "Activity": "Wind down / Sleep"},
        ]
        st.table(pd.DataFrame(schedule_data))
        st.success("Target: **10+ Hours/Day** of high-quality study.")

elif page == "Big 4 Job Hunting ğŸ’¼":
    st.header("ğŸ¢ Big 4 CPA Job Hunting Strategy")
    st.markdown("Strategy guide and comparison for the major audit firms in Japan.")

    tab1, tab2, tab_depts, tab3, tab4, tab5 = st.tabs(["Strategy & Timeline", "Big 4 Comparison", "Departments (FAS/Tax/...) ğŸ¢", "Tech & Data Science Advantage ğŸ¤–", "Boston Career Forum ğŸ‡ºğŸ‡¸", "Interview & Case Prep ğŸ“"])

    with tab1:
        st.subheader("ğŸ“… Job Hunting Timeline (Typical)")
        st.info("The job hunting season for CPA candidates peaks immediately after the August Essay Exam.")
        
        timeline_data = [
            {"Period": "August (Late)", "Activity": "Essay Exam Ends", "Details": "Rest for a few days, then prepare for briefings."},
            {"Period": "September", "Activity": "Firm Briefings (Setsumeikai)", "Details": "Attend online/offline sessions. Key for networking."},
            {"Period": "October", "Activity": "Entry Sheet (ES) Submission", "Details": "Prepare resumes. Focus on 'Why this firm?'"},
            {"Period": "November (Mid)", "Activity": "Results Announcement", "Details": "Official passing results released."},
            {"Period": "November (Late)", "Activity": "Interviews & Offers", "Details": "Intensive interview period (1-2 weeks). Offers issued quickly."}
        ]
        st.table(pd.DataFrame(timeline_data))

        st.subheader("ğŸ’¡ Key Strategies")
        st.markdown("""
        *   **Start Early**: Don't wait for the results. Attend briefings in September.
        *   **Differentiate**: All Big 4 do audit. Focus on culture, specific clients (e.g., Tech, Auto), or non-audit opportunities (IPO, Advisory).
        *   **Networking**: Use alumni connections (OB/OG Visits) if possible.
        """)

    with tab2:
        st.subheader("ğŸ“Š Big 4 Audit Firms vs. Tech Giants Comparison")
        
        # Personalized Ranking Section
        st.markdown("### ğŸ† Personalized Ranking for You (ML/DS Master's Student)")
        st.info("""
        Based on your **CPA Goal** + **ML/Data Science Strength**, here is your recommended priority:
        
        1.  ğŸ¥‡ **PwC Aarata / EY ShinNihon**: Best balance of **Digital Audit** innovation and **CPA License** support. Both have dedicated "Digital" tracks for auditors.
        2.  ğŸ¥ˆ **Deloitte Tohmatsu**: Massive scale and data access. Great for "Audit Analytics" but slightly more traditional hierarchy.
        3.  ğŸ¥‰ **Accenture / IBM**: **Top Tier for Tech**, but âš ï¸ **WARNING**: You likely **cannot** complete the CPA practical experience (Jitsumu Hoshu) requirement here. Great for *after* getting your CPA, or if you pivot to Consulting.
        """)

        # Radar Chart
        st.subheader("Visual Comparison (Illustrative)")
        categories = ['Tech/AI Focus', 'Global Network', 'Domestic Scale', 'IPO/Venture', 'Work-Life Balance']

        fig = go.Figure()

        # Tohmatsu (Deloitte)
        fig.add_trace(go.Scatterpolar(
            r=[4, 5, 5, 5, 3],
            theta=categories,
            fill='toself',
            name='Tohmatsu (Deloitte)'
        ))
        # AZSA (KPMG)
        fig.add_trace(go.Scatterpolar(
            r=[3, 4, 5, 3, 4],
            theta=categories,
            fill='toself',
            name='AZSA (KPMG)'
        ))
        # EY ShinNihon
        fig.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 3, 3],
            theta=categories,
            fill='toself',
            name='EY ShinNihon'
        ))
        # PwC Aarata
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 3, 2, 4],
            theta=categories,
            fill='toself',
            name='PwC Aarata'
        ))
        # Accenture (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 2, 2],
            theta=categories,
            fill='toself',
            name='Accenture (Ref)'
        ))
        # IBM (Comparison)
        fig.add_trace(go.Scatterpolar(
            r=[5, 5, 4, 1, 4],
            theta=categories,
            fill='toself',
            name='IBM (Ref)'
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5]
                )),
            showlegend=True,
            height=500,
            margin=dict(l=40, r=40, t=20, b=20)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("ğŸ¢ Firm Details")
        firms_data = [
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»»ç›£æŸ»æ³•äººãƒˆãƒ¼ãƒãƒ„ (Tohmatsu)",
                "Network": "Deloitte",
                "Key Strengths": "Largest scale, aggressive growth, strong in IPOs and Venture support.",
                "Culture": "Meritocratic, Sports-oriented, High energy.",
                "Link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"
            },
            {
                "Firm Name (JP)": "æœ‰é™è²¬ä»» ã‚ãšã•ç›£æŸ»æ³•äºº (AZSA)",
                "Network": "KPMG",
                "Key Strengths": "Balanced portfolio, strong domestic manufacturing clients.",
                "Culture": "Conservative, Collaborative, 'Gentlemanly'.",
                "Link": "https://home.kpmg/jp/ja/home/careers.html"
            },
            {
                "Firm Name (JP)": "EYæ–°æ—¥æœ¬æœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (EY ShinNihon)",
                "Network": "EY",
                "Key Strengths": "Long history, large number of listed clients, strong Digital Audit focus.",
                "Culture": "Traditional yet transforming, Diversity focus.",
                "Link": "https://www.ey.com/ja_jp/careers/audit"
            },
            {
                "Firm Name (JP)": "PwCã‚ã‚‰ãŸæœ‰é™è²¬ä»»ç›£æŸ»æ³•äºº (PwC Aarata)",
                "Network": "PwC",
                "Key Strengths": "Global integration, strong advisory connection, newer organizational style.",
                "Culture": "Global, Flat hierarchy, Innovative.",
                "Link": "https://www.pwc.com/jp/ja/careers/audit.html"
            },
            {
                "Firm Name (JP)": "ã‚¢ã‚¯ã‚»ãƒ³ãƒãƒ¥ã‚¢ (Accenture)",
                "Network": "Accenture",
                "Key Strengths": "Absolute leader in DX/IT Consulting. High salary.",
                "Culture": "Up or Out (Evolving), High performance, Tech-first.",
                "Link": "https://www.accenture.com/jp-ja/careers"
            },
            {
                "Firm Name (JP)": "æ—¥æœ¬IBM (IBM Japan)",
                "Network": "IBM",
                "Key Strengths": "Deep research (Watson), Hybrid Cloud, Legacy stability.",
                "Culture": "Engineering-driven, Mature, Good work-life balance.",
                "Link": "https://www.ibm.com/jp-ja/employment"
            }
        ]
        
        # Display as a styled table or cards
        for firm in firms_data:
            with st.expander(f"{firm['Firm Name (JP)']} ({firm['Network']})", expanded=True):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**Strengths:** {firm['Key Strengths']}")
                    st.markdown(f"**Culture:** {firm['Culture']}")
                with col2:
                    st.link_button("Recruit Page", firm['Link'])

    with tab_depts:
        st.subheader("ğŸ¢ Service Lines & Business Units")
        st.markdown("Beyond Audit: Understanding the different career paths within Big 4.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ” Audit & Assurance (ç›£æŸ»ãƒ»ä¿è¨¼)")
            st.info("""
            **The Core Business.**
            *   **Role:** Examining financial statements to ensure accuracy and compliance.
            *   **Pros:** Stability, clear career path, high demand for CPAs.
            *   **Cons:** Can be repetitive, busy season is intense.
            *   **For You:** "Digital Audit" roles are growing fast here.
            """)
            
            st.markdown("### ğŸ’° Financial Advisory (FAS)")
            st.warning("""
            **The "Deal" Makers.**
            *   **Role:** M&A support, Valuations, Due Diligence, Forensic investigations.
            *   **Pros:** High compensation, dynamic work, exposure to high-level strategy.
            *   **Cons:** Very high pressure, long hours, up-or-out culture.
            *   **For You:** **Forensic Technology** (Fraud Detection) is a perfect fit for Data Science skills.
            """)

        with col2:
            st.markdown("### âš–ï¸ Tax (ç¨å‹™)")
            st.info("""
            **The Specialists.**
            *   **Role:** Corporate tax compliance, Transfer Pricing, International Tax.
            *   **Pros:** Deep expertise, high autonomy, stable.
            *   **Cons:** Highly specialized (niche), constant regulatory changes.
            *   **For You:** "Tax Technology" is emerging, but less common for new grads than Audit.
            """)
            
            st.markdown("### ğŸš€ Consulting (ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°)")
            st.success("""
            **The Problem Solvers.**
            *   **Role:** Strategy, IT Implementation, Operations improvement.
            *   **Note:** Usually a separate entity (e.g., Deloitte Tohmatsu Consulting vs. Deloitte Tohmatsu Audit).
            *   **Pros:** Variety of projects, high pay.
            *   **Cons:** Travel, unstable workload, "Jack of all trades" risk.
            """)

    with tab3:
        st.subheader("ğŸ¤– Leveraging Data Science & ML in CPA Job Hunting")
        st.markdown("""
        **Profile:** Double Degree Master's Student (Keio ğŸ‡¯ğŸ‡µ & Leibniz Hannover ğŸ‡©ğŸ‡ª) | **Major:** Mechanical Engineering
        
        **Your Technical Arsenal:**
        *   **Advanced ML:** Graph Neural Networks (GNNs), PyTorch, Bayesian Inference (MCMC/TMCMC).
        *   **Engineering:** Finite Element Analysis (FEA), Structural Health Monitoring.
        *   **Languages:** Python, MATLAB, TypeScript.
        
        Your background is a **massive differentiator** in the modern audit industry. All Big 4 firms are heavily investing in "Audit Transformation" and "Digital Audit".
        """)

        st.markdown("---")
        st.markdown("### ğŸ“š Recommended Reading")
        st.markdown("""
        > **[The State of Generative AI in the Enterprise (Deloitte)](https://www.deloitte.com/global/en/issues/generative-ai/state-of-ai-in-enterprise.html)**  
        > *This report highlights how enterprises are adopting GenAI. Essential reading for interviews to show commercial awareness.*
        """)
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ¯ Target Roles")
            st.success("**1. Digital Audit Specialist**")
            st.markdown("Work at the intersection of Audit and Tech. Use Python/SQL to analyze full population data instead of sampling.")
            
            st.success("**2. AI Governance / Algorithm Assurance**")
            st.markdown("Audit AI models! With your GNN/Bayesian background, you can audit complex *algorithms* themselves, not just the financial numbers.")
            
            st.success("**3. Financial Advisory (FAS) - Forensics**")
            st.markdown("Your experience in 'Defect Localization' translates perfectly to **Fraud Detection** (finding anomalies in massive datasets).")

        with col2:
            st.markdown("### ğŸ’¡ Strategic Actions")
            st.info("**Resume / Entry Sheet (ES)**")
            st.markdown("*   **Highlight Research**: Explicitly mention your GNN work for Aerospace/CFRP. It shows you can handle *complex, unstructured data*.")
            st.markdown("*   **Keywords**: `PyTorch`, `Bayesian Inference`, `Uncertainty Quantification`, `End-to-End Pipelines`.")
            
            st.info("**Interview Questions to Ask**")
            st.markdown("*   *\"How can I apply Bayesian methods to audit risk assessment?\"*\n*   *\"Does your firm analyze unstructured data (like contracts/images) using GNNs or NLP?\"*")
            
            st.info("**Firm-Specific Tech Vibes**")
            st.markdown("""
            *   **EY**: Very strong brand in "Digital Audit". Has "EY Digital" specific recruiting tracks.
            *   **PwC**: Strong on "Tech-enablement". "Digital Upskilling" for all staff is a key slogan.
            *   **Deloitte**: "Audit Analytics" is a core part of their massive scale.
            *   **KPMG**: "Digital Innovation" focus, often collaborative with their consulting arm.
            """)

    with tab4:
        st.subheader("ğŸ‡ºğŸ‡¸ Boston Career Forum (BCF)")
        st.markdown("The world's largest job fair for Japanese-English bilinguals. **Crucial for Master's students.**")
        
        st.info("ğŸ’¡ **Why BCF for You?**\n*   **Speed**: Offers (Naitei) often given in 3 days (Fri-Sun).\n*   **Positions**: Big 4 hires for **Advisory/Consulting** heavily here, not just Audit.\n*   **Timing**: Held in November, aligning perfectly with post-essay exam period.")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ“… Timeline")
            st.markdown("""
            *   **Aug-Sep**: Registration & Resume Upload.
            *   **Sep-Oct**: Online Applications & Skype Interviews (Pre-event).
            *   **Nov (Event)**: Walk-ins (Risky) vs. Scheduled Interviews (Safe).
            """)
        with col2:
            st.markdown("### ğŸ¯ Strategy")
            st.markdown("""
            *   **Pre-Event is King**: Secure interviews *before* flying to Boston.
            *   **Target**: Big 4 (US & Japan offices), Consulting (MBB/Accenture), Tech.
            *   **Dinner Invitations**: If you do well, you get invited to dinner. This is effectively the final interview.
            """)
        st.link_button("BCF Official Site", "https://careerforum.net/en/event/bos/")

    with tab5:
        st.subheader("ğŸ“ Interview & Case Prep: The 'Master' Level")
        
        st.info("ğŸ’¡ **Goal**: Move beyond 'prepared answers'. Show **Intellectual Curiosity** and **Professional Maturity**.")

        # --- Interactive Mock Interview ---
        st.markdown("### ğŸ¤– Mock Interview Simulator")
        mock_mode = st.radio("Select Mode:", ["Behavioral (HR/Partner)", "Technical (Audit/Accounting)", "Case/Logic (Consulting)"], horizontal=True)
        
        if st.button("ğŸ² Generate Question"):
            import random
            
            if "Behavioral" in mock_mode:
                q_bank = [
                    {"q": "Why do you want to be a CPA instead of an Engineer?", "hint": "Connect 'Reliability' in Engineering to 'Assurance' in Audit."},
                    {"q": "Why our firm specifically? (Why not others?)", "hint": "Mention specific culture, clients (Tech/Auto), or digital initiatives."},
                    {"q": "Tell me about a time you failed.", "hint": "Focus on the **Lesson Learned** and **Improvement**, not the failure itself."},
                    {"q": "How do you handle disagreement with a team member?", "hint": "Emphasize **Listening**, **Data-driven discussion**, and **Shared Goals**."},
                    {"q": "What is your career plan for the next 5-10 years?", "hint": "Be ambitious but realistic. 'Digital Audit Specialist' -> 'Project Manager'."},
                    {"q": "Describe your research in simple terms to a 10-year-old.", "hint": "Tests communication skills. Avoid jargon. Use analogies."}
                ]
            elif "Technical" in mock_mode:
                q_bank = [
                    {"q": "What is the difference between 'Audit' and 'Advisory'?", "hint": "Audit = Assurance (Past/Present). Advisory = Consulting (Future/Improvement)."},
                    {"q": "Explain 'Materiality' in Audit.", "hint": "The threshold above which a misstatement would influence decision making."},
                    {"q": "How would you audit a company with massive data volumes?", "hint": "ITAC (IT Application Controls) + Data Analytics (Full population testing)."},
                    {"q": "What are the risks of using AI in financial reporting?", "hint": "Black box logic, Bias, Hallucinations, Lack of audit trail."},
                    {"q": "Explain the concept of 'Going Concern'.", "hint": "The assumption that a company will continue operating in the foreseeable future."}
                ]
            else: # Case
                q_bank = [
                    {"q": "Estimate the number of smartphones sold in Japan annually.", "hint": "Pop (125M) x Penetration (80%) / Replacement Cycle (3 years)."},
                    {"q": "A client's profit is down 20%. How do you analyze it?", "hint": "Revenue vs Cost. Price x Vol. Fixed vs Variable. External vs Internal."},
                    {"q": "Should a Japanese auto-maker enter the EV market in India?", "hint": "Market Size, Competition, Regulation, Infrastructure, Capabilities."},
                    {"q": "How would you use AI to improve audit efficiency?", "hint": "Automated document review, Anomaly detection in journals, Chatbot for inquiries."}
                ]
            
            selected = random.choice(q_bank)
            st.session_state['mock_q'] = selected
            st.session_state['show_hint'] = False
        
        if 'mock_q' in st.session_state:
            st.markdown(f"#### â“ Q: {st.session_state['mock_q']['q']}")
            
            if st.button("Show Hint / Direction"):
                st.session_state['show_hint'] = not st.session_state.get('show_hint', False)
                
            if st.session_state.get('show_hint', False):
                st.success(f"ğŸ’¡ **Direction**: {st.session_state['mock_q']['hint']}")
        
        st.divider()

        # --- Detailed Guide ---
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ—£ï¸ Core Competency Questions (STAR Method)")
            with st.expander("1. Self-Introduction & Why CPA?", expanded=True):
                st.markdown("""
                **The 'Engineer to Auditor' Narrative**:
                *   "I research **Defect Localization** in aerospace structures using **AI**. My job is to find 'hidden cracks' before they cause failure."
                *   "I realized **Audit** is the same concept but for **Business Structures**. I want to use my tech skills to find 'financial cracks' and ensure stability."
                *   **Why**: "Engineering is precise. Accounting is the language of business. I want to combine **Precision + Business Logic**."
                """)
            
            with st.expander("2. Handling Conflict / Teamwork"):
                st.markdown("""
                *   **Situation**: "In a joint research project with 3 others..."
                *   **Task**: "We disagreed on the simulation method (Speed vs Accuracy)."
                *   **Action**: "I didn't argue opinion. I proposed a **small-scale benchmark test** to compare data."
                *   **Result**: "Data showed my method was 2x faster with 99% accuracy. Team agreed based on evidence."
                *   **Key**: You are **Data-Driven** and **Collaborative**.
                """)

        with col2:
            st.markdown("### ğŸ™‹â€â™‚ï¸ Reverse Questions (Gyakushitsumon)")
            st.info("Asking good questions is more important than giving good answers.")
            
            with st.expander("Level 1: The 'Safe' Questions"):
                st.markdown("""
                *   "What does a typical day look like for a first-year associate?"
                *   "How is the team structure for a typical audit engagement?"
                *   "What kind of training support is available for CPA exam (Jitsumu Hoshu)?"
                """)
                
            with st.expander("Level 2: The 'Interest' Questions"):
                st.markdown("""
                *   "I am interested in the Digital Audit sector. How early can I get involved in data analytics projects?"
                *   "What differentiates a 'High Performer' from an average one in your firm?"
                *   "Can you tell me about the most challenging project you've worked on recently?"
                """)
                
            with st.expander("Level 3: The 'Killer' Questions (Partner Level)"):
                st.markdown("""
                *   "With the rise of AI, how do you see the **business model of Audit** changing in 5 years? Will it shift from 'Time-Charge' to 'Value-Based'?"
                *   "How is the firm preparing for the auditing of **Non-Financial Information** (ESG/Sustainability)? I believe my engineering background could be useful there."
                *   "I want to be a bridge between the Tech team and the Audit team. Is there a career path for a 'Hybrid' professional?"
                """)


elif page == "Company Directory ğŸ¢":
    st.header("ğŸ¢ Company Directory for CPA Candidates")
    st.markdown("A curated list of potential employers in Japan for CPA holders, ranging from Audit to Tech.")

    tab1, tab2, tab3 = st.tabs(["Audit (Big 4 & Mid)", "Consulting & FAS", "Tech & Enterprise"])

    with tab1:
        st.subheader("Big 4 Audit Firms (The Standard Path)")
        big4 = [
            {"name": "Deloitte Touche Tohmatsu", "desc": "Largest scale, aggressive growth. Strong in IPO support.", "link": "https://www2.deloitte.com/jp/ja/pages/audit/topics/recruit-index.html"},
            {"name": "KPMG AZSA", "desc": "Balanced portfolio, strong manufacturing clients. 'Gentleman' culture.", "link": "https://home.kpmg/jp/ja/home/careers.html"},
            {"name": "EY ShinNihon", "desc": "Longest history, most listed clients. Strong Digital Audit focus.", "link": "https://www.ey.com/ja_jp/careers/audit"},
            {"name": "PwC Aarata / Kyoto", "desc": "Global integration, innovative. PwC Kyoto is famous for high profitability.", "link": "https://www.pwc.com/jp/ja/careers/audit.html"}
        ]
        for c in big4:
            with st.expander(f"ğŸ¦ {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

        st.divider()
        st.subheader("Mid-Tier Audit Firms (å‡†å¤§æ‰‹)")
        st.info("ğŸ’¡ **Why Mid-Tier?** Faster promotion, broader experience (you do everything), better work-life balance.")
        mid_tier = [
            {"name": "Grant Thornton Taiyo (å¤ªé™½)", "desc": "Largest mid-tier. Very growing. Good alternative to Big 4.", "link": "https://www.grantthornton.jp/recruit/"},
            {"name": "Crowe Toyo (æ±é™½)", "desc": "Strong in domestic IPOs. Traditional but stable.", "link": "https://www.toyo-audit.or.jp/recruit/"},
            {"name": "BDO Sanyu (ä¸‰å„ª)", "desc": "Friendly culture. Good international network via BDO.", "link": "https://www.bdo.or.jp/sanyu/recruit/"},
            {"name": "RSM Seiwa (æ¸…å’Œ)", "desc": "Mid-sized, focus on healthcare and mid-cap clients.", "link": "https://www.seiwa-audit.or.jp/recruit/"}
        ]
        for c in mid_tier:
            with st.expander(f"ğŸ¯ {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab2:
        st.subheader("FAS (Financial Advisory Services)")
        st.info("ğŸ’¡ **High Expertise**: M&A, Valuation, Forensics. Often requires CPA + English/Tech.")
        fas = [
            {"name": "Deloitte Tohmatsu Financial Advisory (DTFA)", "link": "https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/dtfa/dtfa-recruit.html"},
            {"name": "KPMG FAS", "link": "https://home.kpmg/jp/ja/home/careers/fas.html"},
            {"name": "PwC Advisory", "link": "https://www.pwc.com/jp/ja/careers/advisory.html"},
            {"name": "EY Strategy and Transactions", "link": "https://www.ey.com/ja_jp/careers/strategy-and-transactions"}
        ]
        for c in fas:
            st.link_button(f"ğŸ’¼ {c['name']}", c['link'])

        st.divider()
        st.subheader("Consulting Firms")
        st.markdown("Finance transformation, ERP implementation, Strategy.")
        consulting = [
            {"name": "Accenture (Strategy & Consulting)", "desc": "Top tier for DX/IT. High salary, hard work.", "link": "https://www.accenture.com/jp-ja/careers"},
            {"name": "BayCurrent Consulting", "desc": "Rapidly growing Japanese firm. High salary.", "link": "https://www.baycurrent.co.jp/recruit/"},
            {"name": "Nomura Research Institute (NRI)", "desc": "Stable, high salary, strong domestic presence.", "link": "https://www.nri.com/jp/career"},
            {"name": "ABeam Consulting", "desc": "Strong in SAP/ERP. Good for CPAs liking systems.", "link": "https://www.abeam.com/jp/ja/careers"}
        ]
        for c in consulting:
            with st.expander(f"ğŸ§  {c['name']}"):
                st.write(c['desc'])
                st.link_button("Recruit Page", c['link'])

    with tab3:
        st.subheader("Tech & Enterprise (CFO Track)")
        st.info("ğŸ’¡ **Business Side**: FP&A, Accounting Manager, IPO Prep.")
        
        tech = [
            {"name": "Google / Amazon / MS (Japan)", "desc": "FP&A roles. Very high English requirement. Competitive.", "link": "https://careers.google.com/"},
            {"name": "Rakuten Group", "desc": "English official language. Massive FinTech ecosystem.", "link": "https://corp.rakuten.co.jp/careers/"},
            {"name": "Line Yahoo", "desc": "Major domestic tech player. Strong benefits.", "link": "https://www.lycorp.co.jp/ja/recruit/"},
            {"name": "Mercari", "desc": "Modern tech culture. Good for ambitious finance pros.", "link": "https://careers.mercari.com/"}
        ]
        st.markdown("#### Tech / Global")
        for c in tech:
            st.markdown(f"**{c['name']}**: {c['desc']} [Link]({c['link']})")

        st.divider()
        st.markdown("#### Trading Companies (Sogo Shosha)")
        shosha = ["Mitsubishi Corp", "Mitsui & Co", "Itochu", "Sumitomo Corp", "Marubeni"]
        st.write(", ".join(shosha))
        st.caption("Extremely competitive. High salary. Global rotations.")


elif page == "Future ğŸš€":
    st.header("ğŸš€ 100-Year Life & Career Plan: The 'Founder' Trajectory")
    st.markdown("Your roadmap from **Master's Student** to **Tech CEO**. A comprehensive simulation of career, wealth, and life milestones.")

    # Top Status Board
    st.subheader("ğŸ“ Current Status")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Current Age", "24", "Phase: Foundation")
    c2.metric("Next Big Milestone", "CPA Exam Pass", "2027 (Age 25)")
    c3.metric("Career Goal", "Audit Tech Founder", "Launch @ Age 35")
    c4.metric("Financial Freedom", "Target: Age 45", "Asset Goal: 500M JPY")
    
    st.divider()

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["â³ 100-Year Timeline", "ğŸ§  Skill Evolution", "ğŸ’° Wealth (Monte Carlo)", "ğŸ¦„ Entrepreneurship Blueprint", "ğŸ’ Life & Family"])

    with tab1:
        st.subheader("The Century Plan (Age 24 - 100)")
        
        timeline_events = [
            {"Age": 24, "Year": 2026, "Phase": "Foundation", "Event": "Master's (Germany/Japan) + CPA Study Start", "Status": "Current", "Importance": 3},
            {"Age": 25, "Year": 2027, "Phase": "Foundation", "Event": "Pass CPA Exam (May/Aug) ğŸ†", "Status": "Goal", "Importance": 5},
            {"Age": 26, "Year": 2028, "Phase": "Foundation", "Event": "Graduation & Join Big 4 (Digital Audit/FAS)", "Status": "Planned", "Importance": 4},
            {"Age": 29, "Year": 2031, "Phase": "Growth", "Event": "Promoted to Senior Associate. Lead ML Projects.", "Status": "Planned", "Importance": 3},
            {"Age": 30, "Year": 2032, "Phase": "Life", "Event": "Marriage ğŸ’ (Target)", "Status": "Life", "Importance": 5},
            {"Age": 32, "Year": 2034, "Phase": "Growth", "Event": "Manager Promotion. Deep expertise in AI Governance.", "Status": "Planned", "Importance": 3},
            {"Age": 35, "Year": 2037, "Phase": "Launch", "Event": "ğŸš€ FOUND YOUR COMPANY (AI Audit Firm). Disruption.", "Status": "Dream", "Importance": 5},
            {"Age": 40, "Year": 2042, "Phase": "Scale", "Event": "Global Expansion. AI-First Assurance.", "Status": "Dream", "Importance": 4},
            {"Age": 45, "Year": 2047, "Phase": "Exit", "Event": "IPO or Strategic Partnership. Financial Freedom.", "Status": "Dream", "Importance": 5},
            {"Age": 50, "Year": 2052, "Phase": "Invest", "Event": "Angel Investor for Deep Tech. University Lecturer.", "Status": "Vision", "Importance": 3},
            {"Age": 60, "Year": 2062, "Phase": "Legacy", "Event": "Establish Scholarship Foundation.", "Status": "Vision", "Importance": 3},
            {"Age": 80, "Year": 2082, "Phase": "Wisdom", "Event": "Write Memoirs. Mentor next gen.", "Status": "Vision", "Importance": 2},
            {"Age": 100, "Year": 2102, "Phase": "Complete", "Event": "Die Empty. No regrets.", "Status": "Final", "Importance": 5}
        ]
        
        df_timeline = pd.DataFrame(timeline_events)
        
        # Visual Timeline - Improved
        fig_timeline = px.scatter(
            df_timeline, 
            x="Year", 
            y="Age", 
            color="Phase", 
            size="Importance",
            hover_name="Event",
            text="Event", 
            title="Life Trajectory Map", 
            size_max=40,
            template="plotly_white"
        )
        fig_timeline.update_traces(textposition='top center', marker=dict(line=dict(width=2, color='DarkSlateGrey')))
        fig_timeline.update_layout(
            height=600,
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True, title="Age"),
            showlegend=True
        )
        # Add connecting line
        fig_timeline.add_trace(go.Scatter(
            x=df_timeline["Year"], 
            y=df_timeline["Age"], 
            mode='lines', 
            line=dict(color='lightgrey', width=1, dash='dot'),
            showlegend=False,
            hoverinfo='skip'
        ))
        
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        with st.expander("Show Data Table"):
            st.dataframe(df_timeline, use_container_width=True)

    with tab2:
        st.subheader("ğŸ§  Skill Evolution: The 'T-Shaped' Professional")
        st.markdown("Visualizing your growth from a CPA specialist to a Tech CEO.")
        
        categories = ['Accounting/Audit', 'Coding/AI', 'English/Global', 'Leadership', 'Risk Taking']
        
        fig_radar = go.Figure()
        
        fig_radar.add_trace(go.Scatterpolar(
            r=[4, 2, 3, 2, 2],
            theta=categories,
            fill='toself',
            name='Current (Age 24)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 4, 4, 4, 3],
            theta=categories,
            fill='toself',
            name='Manager (Age 32)'
        ))
        fig_radar.add_trace(go.Scatterpolar(
            r=[5, 5, 5, 5, 5],
            theta=categories,
            fill='toself',
            name='Founder/CEO (Age 40)'
        ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                visible=True,
                range=[0, 5]
                )),
            showlegend=True,
            title="Skill Radar Chart"
        )
        
        col_r1, col_r2 = st.columns([2, 1])
        with col_r1:
            st.plotly_chart(fig_radar, use_container_width=True)
        with col_r2:
            st.info("ğŸ’¡ **Key Insight**")
            st.markdown("""
            *   **Accounting**: Must be perfect early on (CPA).
            *   **Coding/AI**: Your differentiator. Grow this during your Associate years.
            *   **Risk Taking**: The biggest shift required to become a Founder.
            """)

    with tab3:
        st.subheader("ğŸ’° Financial Simulation: Monte Carlo Analysis")
        st.markdown("A Quant-style simulation of your future wealth. **Life is probabilistic, not deterministic.**")
        
        # --- Interactive Sliders ---
        col_ctrl1, col_ctrl2 = st.columns(2)
        with col_ctrl1:
            st.markdown("**Income & Savings**")
            initial_salary = st.slider("Starting Salary (Million JPY)", 4.0, 10.0, 6.0, 0.5)
            savings_rate = st.slider("Savings Rate (%)", 10, 70, 30, 5) / 100.0
            investment_return_mean = st.slider("Expected Return (%)", 1.0, 15.0, 5.0, 0.5) / 100.0
            investment_volatility = st.slider("Volatility (Risk) (%)", 5.0, 30.0, 15.0, 1.0) / 100.0
            
        with col_ctrl2:
            st.markdown("**Startup Variables**")
            launch_age = st.slider("Launch Age", 28, 45, 35)
            exit_age = st.slider("Exit Age", launch_age + 3, 60, 45)
            exit_valuation = st.slider("Exit Valuation (Million JPY)", 100, 10000, 500, 100)
            exit_prob = st.slider("Exit Success Probability (%)", 10, 90, 30, 5) / 100.0
            
        st.divider()

        if st.button("Run Monte Carlo Simulation (100 Scenarios)"):
            with st.spinner("Running 100 simulations..."):
                # Simulation Data
                years = list(range(2026, 2060))
                ages = list(range(24, 58))
                n_sims = 100
                
                # Store all paths
                all_paths = []
                
                for i in range(n_sims):
                    path = []
                    current_asset = 1.0
                    
                    # Startup outcome for this simulation
                    is_successful_exit = np.random.random() < exit_prob
                    
                    for age in ages:
                        # Salary Logic
                        if age < launch_age:
                            # Corporate Phase
                            if age < 26: sal = 0
                            elif age < 30: sal = initial_salary
                            elif age < 35: sal = initial_salary * 1.5
                            elif age < 40: sal = initial_salary * 2.0
                            else: sal = initial_salary * 2.5
                            
                            current_asset += (sal * savings_rate)
                            
                        elif age == launch_age:
                            # Launch Cost
                            current_asset -= 5.0
                            if current_asset < 0: current_asset = 0
                            
                        elif age < exit_age:
                            # Founder Phase (Lean)
                            sal = 4.0
                            current_asset += (sal * 0.1)
                            
                        elif age == exit_age:
                            # Exit Event
                            if is_successful_exit:
                                current_asset += exit_valuation
                            else:
                                current_asset += 0 # Failed exit
                                
                        else:
                            # Post-Exit / Investor
                            pass

                        # Investment Return (Stochastic)
                        # Geometric Brownian Motion component: exp((mu - 0.5*sigma^2) + sigma*Z)
                        # Simplified: return ~ N(mean, vol)
                        r = np.random.normal(investment_return_mean, investment_volatility)
                        current_asset *= (1 + r)
                        
                        path.append(current_asset)
                    
                    all_paths.append(path)
                
                # Calculate Percentiles
                all_paths_np = np.array(all_paths) # shape (n_sims, n_years)
                p10 = np.percentile(all_paths_np, 10, axis=0)
                p50 = np.percentile(all_paths_np, 50, axis=0)
                p90 = np.percentile(all_paths_np, 90, axis=0)
                
                # Plot
                df_mc = pd.DataFrame({
                    "Age": ages,
                    "P10 (Pessimistic)": p10,
                    "P50 (Median)": p50,
                    "P90 (Optimistic)": p90
                })
                
                fig_mc = go.Figure()
                fig_mc.add_trace(go.Scatter(x=ages, y=p90, mode='lines', name='90th Percentile (Lucky)', line=dict(width=0), showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p10, mode='lines', name='10th Percentile (Unlucky)', line=dict(width=0), fill='tonexty', fillcolor='rgba(0,100,80,0.2)', showlegend=False))
                fig_mc.add_trace(go.Scatter(x=ages, y=p50, mode='lines', name='Median Outcome', line=dict(color='rgb(0,100,80)')))
                
                fig_mc.update_layout(title="Monte Carlo Wealth Projection (90% Confidence Interval)", yaxis_title="Net Assets (Million JPY)", hovermode="x")
                st.plotly_chart(fig_mc, use_container_width=True)
                
                st.success(f"Simulation Complete. Median Asset at Age {ages[-1]}: **{p50[-1]:.1f}M JPY**")
                if p90[-1] > 1000:
                    st.balloons()
        else:
            st.info("Click the button above to run the Monte Carlo simulation.")

    with tab4:
        st.subheader("ğŸ¦„ Entrepreneurship Blueprint: 'Next-Gen AI Audit Firm'")
        
        # Business Stats
        m1, m2, m3 = st.columns(3)
        m1.metric("TAM (Total Addressable Market)", "Â¥500 Billion", "Audit Market in Japan")
        m2.metric("Target Market", "Â¥50 Billion", "Mid-Cap Listed Companies")
        m3.metric("Your Edge", "Tech + License", "Unbeatable Combo")
        
        st.markdown("---")
        
        st.info("ğŸ’¡ **Why AI Audit Firm > SaaS?**")
        st.markdown("""
        *   **SaaS Weakness**: High churn, low barrier to entry, "race to the bottom" pricing. Anyone can build a tool.
        *   **Audit Strength**: **Regulatory Moat**. Only licensed firms can sign off on financial statements. High switching costs.
        *   **The Opportunity**: Build a **Tech-Enabled Audit Firm** (Service + Tech) that operates at 10x efficiency of Big 4, undercutting their fees while maintaining higher margins.
        """)

        st.markdown("""
        **Vision**: Replace the "Army of Associates" with **Autonomous AI Agents**. Focus on high-level judgement and client relationships.
        
        **Phase 1: The "Insider" (Age 26-34)**
        *   **Goal**: Become a domain expert (CPA License is the Key). Understand *exactly* where the inefficiencies are in Big 4.
        *   **Action**: Lead "Digital Transformation" projects. Learn the *regulatory constraints* inside out.
        
        **Phase 2: The "Prototype" (Age 34-35)**
        *   **Goal**: Build the "AI Auditor" (Internal Tool).
        *   **Tech**: RAG (Retrieval Augmented Generation) for accounting standards, GNNs for transaction anomaly detection.
        *   **Team**: You (CTO/CEO) + Experienced Audit Partner (for credibility/signing).
        
        **Phase 3: The "Disruption" (Age 35+)**
        *   **Target**: Mid-cap public companies (tired of high Big 4 fees).
        *   **Product**: **"AI-First Statutory Audit"**. 
        *   **Value Prop**: "Faster audit, lower fees, deeper insights." Not just a software tool, but the *full service*.
        """)

    with tab5:
        st.subheader("ğŸ’ Life, Family & Happiness")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Family Goals")
            st.write("*   **Age 30**: Marriage (Partner who understands the startup grind).")
            st.write("*   **Age 32**: First Child.")
            st.write("*   **Age 35**: Second Child (Coincides with Startup Launch - Tough!).")
            st.write("*   **Policy**: Weekends are for family. No work on Sundays.")
            
        with col2:
            st.markdown("### âœˆï¸ Experiences")
            st.write("*   **20s**: Backpacking Europe/Asia (Cheap travel).")
            st.write("*   **30s**: Family trips to Hawaii/Okinawa.")
            st.write("*   **40s**: World Cruise (Post-Exit).")
            st.write("*   **Hobbies**: Hiking, Coding, Wine Tasting.")

